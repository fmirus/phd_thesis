% Encoding: UTF-8

@Online{BlueBrain-proj,
  author    = {{\'{E}cole Polytechnique F\'{e}d\'{e}rale de Lausanne}`},
  title     = {{B}lue {B}rain project webpage},
  url       = {http://bluebrain.epfl.ch},
  urldate   = {2017-12-20},
  comment   = {started in May 2005},
  groups    = {Projects},
  owner     = {flo},
  timestamp = {2016.03.22},
  year      = {2017},
}

@InProceedings{Gensim2010,
  author    = {Radim {\v{R}}eh{\r{u}}{\v{r}}ek and Petr Sojka},
  title     = {{Software Framework for Topic Modelling with Large Corpora}},
  booktitle = {{Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks}},
  date      = {2010-05-22},
  language  = {English},
  publisher = {ELRA},
  pages     = {45--50},
  url       = {https://radimrehurek.com/gensim},
  comment   = {gensim

http://is.muni.cz/publication/884893/en},
  day       = {22},
  file      = {:pdf-files/Gensim2010 - Software Framework for Topic Modelling with Large Corpora.pdf:PDF},
  groups    = {Word Embedding, Software and Tools},
  owner     = {flo},
  timestamp = {2017.06.29},
}

@InProceedings{Abadi2016,
  author    = {Abadi, Mart{\'i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh and Monga, Rajat and Moore, Sherry and Murray, Derek G. and Steiner, Benoit and Tucker, Paul and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
  title     = {Tensor{F}low: A System for Large-scale Machine Learning},
  booktitle = {Proceedings of the 12th USENIX Conference on Operating Systems Design and Implementation},
  date      = {2016},
  series    = {OSDI'16},
  publisher = {USENIX Association},
  location  = {Savannah, GA, USA},
  isbn      = {978-1-931971-33-1},
  pages     = {265--283},
  url       = {http://dl.acm.org/citation.cfm?id=3026877.3026899},
  acmid     = {3026899},
  address   = {Berkeley, CA, USA},
  file      = {:pdf-files/Abadi2016 - TensorFlow_ a System for Large Scale Machine Learning.pdf:PDF},
  groups    = {Software and Tools},
  numpages  = {19},
  owner     = {flo},
  timestamp = {2017.04.26},
}

@Article{Abbott2016,
  author       = {Abbott, L. F. and Depasquale, Brian and Memmesheimer, Raoul-Martin},
  title        = {Building functional networks of spiking model neurons},
  journaltitle = {Nature Neuroscience},
  date         = {2016},
  volume       = {19},
  number       = {3},
  pages        = {350--355},
  issn         = {1097-6256},
  file         = {:pdf-files/Abbott2016 - Building Functional Networks of Spiking Model Neurons.pdf:PDF},
  groups       = {Neural Modelling, Spiking Neural Networks},
  owner        = {flo},
  timestamp    = {2016.03.07},
}

@InProceedings{Abdalla2005,
  author    = {H. Abdalla and T.K. Horiuchi},
  title     = {An Ultrasonic Filterbank with Spiking Neurons},
  booktitle = {2005 {IEEE} International Symposium on Circuits and Systems},
  date      = {2005},
  volume    = {5},
  publisher = {{IEEE}},
  pages     = {4201--4204},
  doi       = {10.1109/iscas.2005.1465557},
  file      = {:pdf-files/Abdalla2005 - An Ultrasonic Filterbank with Spiking Neurons.pdf:PDF},
  keywords  = {CMOS analogue integrated circuits;Q-factor;acoustic signal processing;bioacoustics;channel bank filters;current-mode circuits;integrated circuit design;mechanoception;0.425 mW;0.5 micron;5 V;CMOS process;bat echolocation modeling;binaural filter bank;capacitively-coupled feedback;cochlea-like filter bank;current-mode;moderate Q-factor;moderate quality factor;spiking neurons;ultrasonic filterbank;Band pass filters;Biological system modeling;Current measurement;Filter bank;Filtering;Frequency measurement;Gain measurement;Neurons;Q measurement;Tuning},
  owner     = {flo},
  timestamp = {2015.12.16},
}

@Article{Aeberhard2015,
  author       = {M. Aeberhard and S. Rauch and M. Bahram and G. Tanzmeister and J. Thomas and Y. Pilat and F. Homm and W. Huber and N. Kaempchen},
  title        = {Experience, {R}esults and {L}essons {L}earned from {A}utomated {D}riving on {G}ermany's {H}ighways},
  journaltitle = {IEEE Intelligent Transportation Systems Magazine},
  date         = {2015},
  volume       = {7},
  number       = {1},
  pages        = {42--57},
  issn         = {1939-1390},
  doi          = {10.1109/MITS.2014.2360306},
  abstract     = {The BMW Group Research and Technology has been testing automated vehicles on Germany's highways since Spring 2011. Since then, thousands of kilometers have been driven on the highways around Munich, Germany. Throughout this project, fundamental technologies, such as environment perception, localization, driving strategy and vehicle control, were developed in order to safely operate prototype automated vehicles in real traffic with speeds up to 130 km/h. The goal of this project was to learn what technologies are necessary for automated driving. This paper presents the architecture and algorithms developed during this project, results from real driving scenarios, the lessons learned throughout the project and a quick introduction into the latest developments for improving the system.},
  file         = {:pdf-files/Aeberhard2015 - Experience, Results and Lessons Learned from Automated Driving on Germany's Highways.pdf:PDF},
  groups       = {Autonomous Driving},
  keywords     = {driver information systems;intelligent transportation systems;road traffic control;traffic engineering computing;Germany highway;automated driving;automated vehicle testing;driving strategy;environment perception;localization;prototype automated vehicle;vehicle control;Automation;Autonomous vehicles;Intelligent sensors;Laser radar;Road traffic;Vehicle dynamics},
  owner        = {flo},
  timestamp    = {2016.08.25},
}

@Article{Afshar2014,
  author       = {Afshar, Saeed and George, Libin and Tapson, Jonathan and van Schaik, Andr{\'e} and Hamilton, Tara Julia},
  title        = {Racing to Learn: Statistical Inference and Learning in a Single Spiking Neuron with Adaptive Kernels},
  journaltitle = {Frontiers in Neuroscience},
  date         = {2014},
  volume       = {8},
  number       = {377},
  issn         = {1662-453X},
  doi          = {10.3389/fnins.2014.00377},
  abstract     = {This paper describes the Synapto-dendritic Kernel Adapting Neuron (SKAN), a simple spiking neuron model that performs statistical inference and unsupervised learning of spatiotemporal spike patterns. SKAN is the first proposed neuron model to investigate the effects of dynamic synapto-dendritic kernels and demonstrate their computational power even at the single neuron scale. The rule-set defining the neuron is simple: there are no complex mathematical operations such as normalization, exponentiation or even multiplication. The functionalities of SKAN emerge from the real-time interaction of simple additive and binary processes. Like a biological neuron, SKAN is robust to signal and parameter noise, and can utilize both in its operations. At the network scale neurons are locked in a race with each other with the fastest neuron to spike effectively "hiding" its learnt pattern from its neighbors. The robustness to noise, high speed, and simple building blocks not only make SKAN an interesting neuron model in computational neuroscience, but also make it ideal for implementation in digital and analog neuromorphic systems which is demonstrated through an implementation in a Field Programmable Gate Array (FPGA). Matlab, Python, and Verilog implementations of SKAN are available at: http://www.uws.edu.au/bioelectronics_neuroscience/bens/reproducible_research.},
  file         = {:pdf-files/Afshar2014 - Racing to Learn_ Statistical Inference and Learning in a Single Spiking Neuron with Adaptive Kernels.pdf:PDF},
  groups       = {Neuromorphic Computing},
  owner        = {flo},
  timestamp    = {2016.02.03},
}

@Article{Akopyan2015,
  author       = {Filipp Akopyan and Jun Sawada and Andrew Cassidy and Rodrigo Alvarez-Icaza and John Arthur and Paul Merolla and Nabil Imam and Yutaka Nakamura and Pallab Datta and Gi-Joon Nam and Brian Taba and Michael Beakes and Bernard Brezzo and Jente B. Kuang and Rajit Manohar and William P. Risk and Bryan Jackson and Dharmendra S. Modha},
  title        = {{TrueNorth}: Design and Tool Flow of a 65 {mW} 1 Million Neuron Programmable Neurosynaptic Chip},
  journaltitle = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
  date         = {2015},
  volume       = {34},
  number       = {10},
  pages        = {1537--1557},
  issn         = {0278-0070},
  doi          = {10.1109/TCAD.2015.2474396},
  abstract     = {The new era of cognitive computing brings forth the grand challenge of developing systems capable of processing massive amounts of noisy multisensory data. This type of intelligent computing poses a set of constraints, including real-time operation, low-power consumption and scalability, which require a radical departure from conventional system design. Brain-inspired architectures offer tremendous promise in this area. To this end, we developed TrueNorth, a 65 mW real-time neurosynaptic processor that implements a non-von Neumann, low-power, highly-parallel, scalable, and defect-tolerant architecture. With 4096 neurosynaptic cores, the TrueNorth chip contains 1 million digital neurons and 256 million synapses tightly interconnected by an event-driven routing infrastructure. The fully digital 5.4 billion transistor implementation leverages existing CMOS scaling trends, while ensuring one-to-one correspondence between hardware and software. With such aggressive design metrics and the TrueNorth architecture breaking path with prevailing architectures, it is clear that conventional computer-aided design (CAD) tools could not be used for the design. As a result, we developed a novel design methodology that includes mixed asynchronous-synchronous circuits and a complete tool flow for building an event-driven, low-power neurosynaptic chip. The TrueNorth chip is fully configurable in terms of connectivity and neural parameters to allow custom configurations for a wide range of cognitive and sensory perception applications. To reduce the system's communication energy, we have adapted existing application-agnostic very large-scale integration CAD placement tools for mapping logical neural networks to the physical neurosynaptic core locations on the TrueNorth chips. With that, we have successfully demonstrated the use of TrueNorth-based systems in multiple applications, including visual object recognition, with higher performance and orders of magnitude lower power consumpt- on than the same algorithms run on von Neumann architectures. The TrueNorth chip and its tool flow serve as building blocks for future cognitive systems, and give designers an opportunity to develop novel brain-inspired architectures and systems based on the knowledge obtained from this paper.},
  file         = {:pdf-files/Akopyan2015 - True North_ Design and Tool Flow of a 65 MW 1 Million Neuron Programmable Neurosynaptic Chip.pdf:PDF},
  groups       = {Neuromorphic Hardware, TrueNorth},
  journal      = {{IEEE} Transactions on Computer-Aided Design of Integrated Circuits and Systems},
  keywords     = {CMOS digital integrated circuits;low-power electronics;real-time systems;CAD tools;CMOS scaling trends;TrueNorth;TrueNorth architecture;asynchronous-synchronous circuits;cognitive perception applications;conventional computer-aided design tools;defect-tolerant architec- ture;event-driven routing infrastructure;intelligent computing;large-scale integration CAD placement;low-power architecture;low-power consumption;neuron programmable neurosynaptic chip;noisy multisensory data;non-von Neumann architecture;power 65 mW;real-time operation;sensory perception applications;Architecture;Biological neural networks;Computer architecture;Nerve fibers;Real-time systems;Synchronization;Asynchronous circuits;asynchronous communication;design automation;design methodology;image recognition;logic design;low-power electronics;neural network hardware;neural networks;neuromorphics;parallel architectures;real-time systems;synchronous circuits;very large-scale integration},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  year         = {2015},
}

@InProceedings{Alahi2016,
  author    = {A. Alahi and K. Goel and V. Ramanathan and A. Robicquet and L. Fei-Fei and S. Savarese},
  title     = {Social {LSTM}: {H}uman {T}rajectory {P}rediction in {C}rowded {S}paces},
  booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  date      = {2016},
  pages     = {961--971},
  doi       = {10.1109/CVPR.2016.110},
  abstract  = {Pedestrians follow different trajectories to avoid obstacles and accommodate fellow pedestrians. Any autonomous vehicle navigating such a scene should be able to foresee the future positions of pedestrians and accordingly adjust its path to avoid collisions. This problem of trajectory prediction can be viewed as a sequence generation task, where we are interested in predicting the future trajectory of people based on their past positions. Following the recent success of Recurrent Neural Network (RNN) models for sequence prediction tasks, we propose an LSTM model which can learn general human movement and predict their future trajectories. This is in contrast to traditional approaches which use hand-crafted functions such as Social forces. We demonstrate the performance of our method on several public datasets. Our model outperforms state-of-the-art methods on some of these datasets. We also analyze the trajectories predicted by our model to demonstrate the motion behaviour learned by our model.},
  file      = {:pdf-files/Alahi2016 - Social LSTM_ Human Trajectory Prediction in Crowded Spaces.pdf:PDF},
  groups    = {Behaviour analysis},
  keywords  = {behavioural sciences computing;collision avoidance;mobile robots;motion compensation;navigation;pedestrians;recurrent neural nets;social sciences computing;RNN;autonomous vehicle navigation;collision avoidance;crowded spaces;hand-crafted functions;human trajectory prediction;motion behaviour;obstacle avoidance;pedestrians;recurrent neural network;social LSTM;Atmospheric modeling;Forecasting;Navigation;Predictive models;Recurrent neural networks;Trajectory;Videos},
  owner     = {flo},
  timestamp = {2017.09.20},
}

@Article{Alamdari2007,
  author       = {Amir Reza Saffari Azar Alamdari},
  date         = {2007},
  journaltitle = {International Journal of Computer, Electrical, Automation, Control and Information Engineering},
  title        = {Unknown Environment Representation for Mobile Robot Using Spiking Neural Networks},
  number       = {6},
  pages        = {1748--1751},
  url          = {http://waset.org/Publications?p=6},
  volume       = {1},
  abstract     = {In this paper, a model of self-organizing spiking neural networks is introduced and applied to mobile robot environment representation and path planning problem. A network of spike-response-model neurons with a recurrent architecture is used to create robot-s internal representation from surrounding environment. The overall activity of network simulates a self-organizing system with unsupervised learning. A modified A* algorithm is used to find the best path using this internal representation between starting and goal points. This method can be used with good performance for both known and unknown environments.},
  email        = {amir@ymer.org},
  file         = {:pdf-files/Alamdari2007 - Unknown Environment Representation for Mobile Robot Using Spiking Neural Networks.pdf:PDF},
  groups       = {Neuromorphic Robotics, Spiking Neural Networks},
  owner        = {flo},
  publisher    = {World Academy of Science, Engineering and Technology},
  timestamp    = {2016.04.19},
}

@Article{Alghamdi2012,
  author       = {Wael Alghamdi and Elhadi Shakshuki and Tarek R.Sheltami},
  title        = {Context-Aware Driver Assistance System},
  journaltitle = {Procedia Computer Science},
  date         = {2012},
  volume       = {10},
  number       = {Supplement C},
  pages        = {785--794},
  note         = {ANT 2012 and MobiWIS 2012},
  issn         = {1877-0509},
  doi          = {10.1016/j.procs.2012.06.100},
  url          = {http://www.sciencedirect.com/science/article/pii/S1877050912004577},
  abstract     = {Abstract In the last few years, significant improvements have been made in the area of vehicular communication systems. In fact, vehicle-to-vehicle communication and vehicle-to-infrastructure are considered a key concept for keeping roads safe. An efficient implementation of these systems is necessary to ensure the safety and to reduce the car collision rates. This paper proposes a Context-Aware Driver Assistance System that links drivers with the physical environment surrounding them. This is achieved by developing a vehicular warning system that assists drivers to avoid collisions and improve their response times. The proposed system architecture consists of a set of components to process the user's request, and provide responses and advices when needed. These components include communication, knowledge exchange, knowledge update, and context-history. Also, it includes other processes such as context-history manipulation, hazard detection, and hazard detection control. Over all, the main goal of the system is to reduce the number of car accidents and improve driver's decisions. To demonstrate the feasibility of the proposed system, it is developed and demonstrated on NXT Robots environment.},
  file         = {:pdf-files/Alghamdi2012 - Context Aware Driver Assistance System.pdf:PDF},
  groups       = {Autonomous Driving},
  keywords     = {Context-aware, V2V, Hazard Detection, Context History Minapulation ;Lego Mindstorms NXT Robots},
  owner        = {flo},
  timestamp    = {2017.11.15},
}

@Article{Al-Rfou2016,
  author        = {Rami Al-Rfou and Guillaume Alain and Amjad Almahairi and Christof Angermueller and Dzmitry Bahdanau and Nicolas Ballas and Fr{\'e}d{\'}eric Bastien and Justin Bayer and Anatoly Belikov and Alexander Belopolsky and Yoshua Bengio and Arnaud Bergeron and James Bergstra and Valentin Bisson and Josh {Bleecher Snyder} and Nicolas Bouchard and Nicolas Boulanger-Lewandowski and Xavier Bouthillier and Alexandre de Br{\'e}bisson and Olivier Breuleux and Pierre-Luc Carrier and Kyunghyun Cho and Jan Chorowski and Paul Christiano and Tim Cooijmans and Marc-Alexandre C{\^o}t{\'e} and Myriam C{\^o}t{\'e} and Aaron Courville and Yann N. Dauphin and Olivier Delalleau and Julien Demouth and Guillaume Desjardins and Sander Dieleman and Laurent Dinh and M{\'e}lanie Ducoffe and Vincent Dumoulin and Samira {Ebrahimi Kahou} and Dumitru Erhan and Ziye Fan and Orhan Firat and Mathieu Germain and Xavier Glorot and Ian Goodfellow and Matt Graham and Caglar Gulcehre and Philippe Hamel and Iban Harlouchet and Jean-Philippe Heng and Bal{\'a}zs Hidasi and Sina Honari and Arjun Jain and S{\'e}bastien Jean and Kai Jia and Mikhail Korobov and Vivek Kulkarni and Alex Lamb and Pascal Lamblin and Eric Larsen and C{\'e}sar Laurent and Sean Lee and Simon Lefrancois and Simon Lemieux and Nicholas L{\'e}onard and Zhouhan Lin and Jesse A. Livezey and Cory Lorenz and Jeremiah Lowin and Qianli Ma and Pierre-Antoine Manzagol and Olivier Mastropietro and Robert T. McGibbon and Roland Memisevic and Bart van Merri{\"e}nboer and Vincent Michalski and Mehdi Mirza and Alberto Orlandi and Christopher Pal and Razvan Pascanu and Mohammad Pezeshki and Colin Raffel and Daniel Renshaw and Matthew Rocklin and Adriana Romero and Markus Roth and Peter Sadowski and John Salvatier and Fran\c{c}ois Savard and Jan Schl{\"u}ter and John Schulman and Gabriel Schwartz and Iulian Vlad Serban and Dmitriy Serdyuk and Samira Shabanian and {\'E}tienne Simon and Sigurd Spieckermann and S. Ramana Subramanyam and Jakub Sygnowski and J{\'e}r{\'e}mie Tanguay and Gijs van Tulder and Joseph Turian and Sebastian Urban and Pascal Vincent and Francesco Visin and Harm de Vries and David Warde-Farley and Dustin J. Webb and Matthew Willson and Kelvin Xu and Lijun Xue and Li Yao and Saizheng Zhang and Ying Zhang},
  title         = {{Theano: A {Python} framework for fast computation of mathematical expressions}},
  journaltitle  = {arXiv e-prints},
  date          = {2016},
  volume        = {abs/1605.02688},
  eprintclass   = {cs.SC},
  url           = {http://arxiv.org/abs/1605.02688},
  collaboration = {Theano Development Team},
  file          = {:pdf-files/Al-Rfou2016 - Theano_ a Python Framework for Fast Computation of Mathematical Expressions.pdf:PDF},
  groups        = {Software and Tools},
  keywords      = {Computer Science - Symbolic Computation, Computer Science - Learning, Computer Science - Mathematical Software},
  owner         = {flo},
  timestamp     = {2016.06.10},
}

@InProceedings{Altche2018,
  author    = {Florent Altche and Arnaud de La Fortelle},
  title     = {An {LSTM} network for highway trajectory prediction},
  booktitle = {2017 IEEE 20th International Conference on Intelligent Transportation Systems (ITSC)},
  date      = {2017},
  publisher = {{IEEE}},
  pages     = {353-359},
  doi       = {10.1109/itsc.2017.8317913},
  abstract  = {In order to drive safely and efficiently on public roads, autonomous vehicles will have to understand the intentions of surrounding vehicles, and adapt their own behavior accordingly. If experienced human drivers are generally good at inferring other vehicles' motion up to a few seconds in the future, most current Advanced Driving Assistance Systems (ADAS) are unable to perform such medium-term forecasts, and are usually limited to high-likelihood situations such as emergency braking. In this article, we present a first step towards consistent trajectory prediction by introducing a long short-term memory (LSTM) neural network, which is capable of accurately predicting future longitudinal and lateral trajectories for vehicles on highway. Unlike previous work focusing on a low number of trajectories collected from a few drivers, our network was trained and validated on the NGSIM US-101 dataset, which contains a total of 800 hours of recorded trajectories in various traffic densities, representing more than 6000 individual drivers.},
  file      = {:pdf-files/Altche2018 - An LSTM Network for Highway Trajectory Prediction.pdf:PDF},
  groups    = {Behaviour analysis},
  issn      = {2153-0017},
  keywords  = {driver information systems;neural nets;road traffic;road vehicles;ADAS;medium-term forecasts;high-likelihood situations;emergency braking;consistent trajectory prediction;short-term memory neural network;future longitudinal trajectories;lateral trajectories;NGSIM US-101 dataset;LSTM network;highway trajectory prediction;public roads;autonomous vehicles;experienced human drivers;advanced driving assistance systems;Trajectory;Road transportation;Conferences;Neural networks;Automobiles;Autonomous vehicles, Computer Science - Robotics, Computer Science - Learning},
  owner     = {flo},
  timestamp = {2018.03.09},
  year      = {2017},
}

@Article{Althaus2013,
  author       = {N. Althaus and D. Mareschal},
  title        = {Modeling {C}ross-{M}odal {I}nteractions in {E}arly {W}ord {L}earning},
  journaltitle = {IEEE Transactions on Autonomous Mental Development},
  date         = {2013},
  volume       = {5},
  number       = {4},
  pages        = {288--297},
  issn         = {1943-0604},
  doi          = {10.1109/TAMD.2013.2264858},
  abstract     = {Infancy research demonstrating a facilitation of visual category formation in the presence of verbal labels suggests that infants' object categories and words develop interactively. This contrasts with the notion that words are simply mapped "onto" previously existing categories. To investigate the computational foundations of a system in which word and object categories develop simultaneously and in an interactive fashion, we present a model of word learning based on interacting self-organizing maps that represent the auditory and visual modalities, respectively. While other models of lexical development have employed similar dual-map architectures, our model uses active Hebbian connections to propagate activation between the visual and auditory maps during learning. Our results show that categorical perception emerges from these early audio-visual interactions in both domains. We argue that the learning mechanism introduced in our model could play a role in the facilitation of infants' categorization through verbal labeling.},
  file         = {:pdf-files/Althaus2013 - Modeling Cross Modal Interactions in Early Word Learning.pdf:PDF},
  groups       = {Neuroscience},
  keywords     = {Hebbian learning;audio-visual systems;interactive systems;natural language processing;self-organising feature maps;word processing;Hebbian connection;activation propagation;audio-visual interaction;auditory map;auditory modality representation;cross-modal interaction modeling;dual map architecture;dual map propagation;early word learning;infant object category;lexical development;self-organizing maps;verbal labeling;visual category formation;visual map;visual modality representation;Computational modeling;Learning systems;Self-organizing networks;Speech processing;Text processing;Categorization;computational modeling;cross-modal interactions;self-organizing maps;word learning},
  owner        = {flo},
  timestamp    = {2017.03.24},
}

@Article{Alvarez2011,
  author       = {J. M. {\'A}. Alvarez and A. M. Lopez},
  title        = {Road {D}etection {B}ased on {I}lluminant {I}nvariance},
  journaltitle = {IEEE Transactions on Intelligent Transportation Systems},
  date         = {2011},
  volume       = {12},
  number       = {1},
  pages        = {184--193},
  issn         = {1524-9050},
  doi          = {10.1109/TITS.2010.2076349},
  abstract     = {By using an onboard camera, it is possible to detect the free road surface ahead of the ego-vehicle. Road detection is of high relevance for autonomous driving, road departure warning, and supporting driver-assistance systems such as vehicle and pedestrian detection. The key for vision-based road detection is the ability to classify image pixels as belonging or not to the road surface. Identifying road pixels is a major challenge due to the intraclass variability caused by lighting conditions. A particularly difficult scenario appears when the road surface has both shadowed and nonshadowed areas. Accordingly, we propose a novel approach to vision-based road detection that is robust to shadows. The novelty of our approach relies on using a shadow-invariant feature space combined with a model-based classifier. The model is built online to improve the adaptability of the algorithm to the current lighting and the presence of other vehicles in the scene. The proposed algorithm works in still images and does not depend on either road shape or temporal restrictions. Quantitative and qualitative experiments on real-world road sequences with heavy traffic and shadows show that the method is robust to shadows and lighting variations. Moreover, the proposed method provides the highest performance when compared with hue-saturation-intensity (HSI)-based algorithms.},
  file         = {:pdf-files/Alvarez2011 - Road Detection Based on Illuminant Invariance.pdf:PDF},
  groups       = {Environment Model},
  keywords     = {driver information systems;image resolution;object detection;pattern classification;road vehicles;driver-assistance systems;illuminant invariance;image pixels;model-based classifier;vision-based road detection;Driving-assistance system;illuminant invariance;road detection;shadows},
  owner        = {flo},
  timestamp    = {2017.02.08},
}

@InBook{Alvarez2012,
  author    = {Alvarez, Jose M. and Gevers, Theo and LeCun, Yann and Lopez, Antonio M.},
  title     = {Road {S}cene {S}egmentation from a {S}ingle {I}mage},
  booktitle = {Computer Vision -- ECCV 2012: 12th European Conference on Computer Vision, Florence, Italy, October 7-13, 2012, Proceedings, Part VII},
  date      = {2012},
  editor    = {Fitzgibbon, Andrew and Lazebnik, Svetlana and Perona, Pietro and Sato, Yoichi and Schmid, Cordelia},
  publisher = {Springer Berlin Heidelberg},
  location  = {Berlin, Heidelberg},
  isbn      = {978-3-642-33786-4},
  pages     = {376--389},
  doi       = {10.1007/978-3-642-33786-4_28},
  file      = {:pdf-files/Alvarez2012 - Road Scene Segmentation from a Single Image.pdf:PDF},
  groups    = {Environment Model, Deep Neural Networks},
  owner     = {flo},
  timestamp = {2016.06.10},
}

@InProceedings{Amir2013,
  author    = {Arnon Amir and Pallab Datta and William P. Risk and Andrew S. Cassidy and Jeffrey A. Kusnitz and Steven K. Esser and Alexander Andreopoulos and Theodore M. Wong and Myron Flickner and Rodrigo Alvarez{-}Icaza and Emmett McQuinn and Ben Shaw and Norm Pass and Dharmendra S. Modha},
  title     = {Cognitive computing programming paradigm: {A} Corelet Language for composing networks of neurosynaptic cores},
  booktitle = {The 2013 International Joint Conference on Neural Networks, {IJCNN} 2013, Dallas, TX, USA, August 4-9, 2013},
  date      = {2013},
  pages     = {1--10},
  doi       = {10.1109/IJCNN.2013.6707078},
  file      = {:pdf-files/Amir2013 - Cognitive Computing Programming Paradigm_ a Corelet Language for Composing Networks of Neurosynaptic Cores.pdf:PDF},
  groups    = {TrueNorth, Neural Modelling},
  owner     = {flo},
  timestamp = {2015.12.14},
}

@Online{Nengo,
  author    = {{Applied Brain Research Inc.}},
  title     = {The Nengo neural simulator},
  date      = {2018},
  url       = {https://www.nengo.ai/},
  urldate   = {2018-04-05},
  groups    = {Nengo},
  owner     = {flo},
  timestamp = {2018.04.05},
  year      = {2018},
}

@InProceedings{Arthur2012,
  author    = {J. V. Arthur and P. A. Merolla and F. Akopyan and R. Alvarez and A. Cassidy and S. Chandra and S. K. Esser and N. Imam and W. Risk and D. B. D. Rubin and R. Manohar and D. S. Modha},
  title     = {Building block of a programmable neuromorphic substrate: {A} digital neurosynaptic core},
  booktitle = {The 2012 International Joint Conference on Neural Networks (IJCNN)},
  date      = {2012},
  pages     = {1--8},
  doi       = {10.1109/IJCNN.2012.6252637},
  abstract  = {The grand challenge of neuromorphic computation is to develop a flexible brain-inspired architecture capable of a wide array of real-time applications, while striving towards the ultra-low power consumption and compact size of biological neural systems. Toward this end, we fabricated a building block of a modular neuromorphic architecture, a neurosynaptic core. Our implementation consists of 256 integrate-and-fire neurons and a 1,024$\times$256 SRAM crossbar memory for synapses that fits in 4.2mm2 using a 45nm SOI process and consumes just 45pJ per spike. The core is fully configurable in terms of neuron parameters, axon types, and synapse states and its fully digital implementation achieves one-to-one correspondence with software simulation models. One-to-one correspondence allows us to introduce an abstract neural programming model for our chip, a contract guaranteeing that any application developed in software functions identically in hardware. This contract allows us to rapidly test and map applications from control, machine vision, and classification. To demonstrate, we present four test cases (i) a robot driving in a virtual environment, (ii) the classic game of pong, (iii) visual digit recognition and (iv) an autoassociative memory.},
  file      = {:pdf-files/Arthur2012 - Building Block of a Programmable Neuromorphic Substrate_ a Digital Neurosynaptic Core.pdf:PDF},
  issn      = {2161-4393},
  keywords  = {SRAM chips;computer vision;content-addressable storage;game theory;image classification;neural nets;power consumption;programmable circuits;real-time systems;robots;silicon-on-insulator;SOI process;SRAM crossbar memory;abstract neural programming model;autoassociative memory;axon types;biological neural systems;classic game of pong;digital neurosynaptic core;flexible brain-inspired architecture;integrate-and-fire neurons;machine vision;map applications;modular neuromorphic architecture;neuron parameters;programmable neuromorphic substrate;real-time applications;robot driving;software functions;software simulation models;synapse states;ultra-low power consumption;virtual environment;visual digit recognition;Hardware;Mobile robots;Nerve fibers;Software;Visualization},
  owner     = {flo},
  timestamp = {2016.05.24},
}

@Article{Avalos2014,
  author       = {Diego Avalos and Fernando Ramirez},
  title        = {{A}n {I}ntroduction to {U}sing {S}piking {N}eural {N}etworks for {T}raffic {S}ign {R}ecognition},
  journaltitle = {Sistemas Inteligentes: Reportes Finales Ene-Mayo 2014},
  date         = {2014},
  file         = {:pdf-files/Avalos2014 - An Introduction to Using Spiking Neural Networks for Traffic Sign Recognition.pdf:PDF},
  groups       = {Neuromorphic Vision, Spiking Neural Networks},
  institution  = {Tecnologico de Monterrey, Campus Guadalajara},
  owner        = {flo},
  timestamp    = {2016.01.21},
}

@Article{Averbeck2006,
  author       = {Averbeck, Bruno B. and Latham, Peter E. and Pouget, Alexandre},
  title        = {Neural correlations, population coding and computation},
  journaltitle = {Nature Reviews Neuroscience},
  date         = {2006},
  volume       = {7},
  number       = {5},
  pages        = {358--366},
  issn         = {1471-003X},
  doi          = {10.1038/nrn1888},
  comment      = {10.1038/nrn1888},
  file         = {:pdf-files/Averbeck2006 - Neural Correlations, Population Coding and Computation.pdf:PDF},
  groups       = {Neural Modelling},
  owner        = {flo},
  timestamp    = {2016.04.13},
}

@PhdThesis{Axenie2016a,
  author      = {Cristian Axenie},
  title       = {Synthesis of {D}istributed {C}ognitive {S}ystems: {I}nteracting {C}omputational {M}aps for {M}ultisensory {F}usion},
  institution = {Technical University of Munich},
  date        = {2016},
  file        = {:pdf-files/Axenie2016a - Synthesis of Distributed Cognitive Systems_ Interacting Computational Maps for Multisensory Fusion.pdf:PDF},
  groups      = {Neuromorphic Computing},
  owner       = {flo},
  timestamp   = {2016.08.22},
}

@Article{Axenie2015,
  author       = {Axenie, Cristian and Conradt, J{\"o}rg},
  title        = {{Cortically Inspired Sensor Fusion Network for Mobile Robot Egomotion Estimation}},
  journaltitle = {Robotics and Autonomous Systems},
  date         = {2015},
  volume       = {71},
  number       = {C},
  pages        = {69--82},
  issn         = {0921-8890},
  file         = {:pdf-files/Axenie2015 - Cortically Inspired Sensor Fusion Network for Mobile Robot Egomotion Estimation.pdf:PDF},
  groups       = {Neuromorphic Robotics, Spiking Neural Networks},
  issue_date   = {September 2015},
  keywords     = {Cortically inspired network, Egomotion estimation, Mobile robots, Sensor fusion},
  location     = {Amsterdam, The Netherlands, The Netherlands},
  numpages     = {14},
  owner        = {flo},
  publisher    = {North-Holland Publishing Co.},
  timestamp    = {2016.03.09},
}

@Article{Axenie2016,
  author       = {Axenie, Cristian and Richter, Christoph and Conradt, J{\"o}rg},
  title        = {A {S}elf-{S}ynthesis {A}pproach to {P}erceptual {L}earning for {M}ultisensory {F}usion in {R}obotics},
  journaltitle = {Sensors},
  date         = {2016},
  volume       = {16},
  number       = {10},
  issn         = {1424-8220},
  doi          = {10.3390/s16101751},
  url          = {http://www.mdpi.com/1424-8220/16/10/1751},
  abstract     = {Biological and technical systems operate in a rich multimodal environment. Due to the diversity of incoming sensory streams a system perceives and the variety of motor capabilities a system exhibits there is no single representation and no singular unambiguous interpretation of such a complex scene. In this work we propose a novel sensory processing architecture, inspired by the distributed macro-architecture of the mammalian cortex. The underlying computation is performed by a network of computational maps, each representing a different sensory quantity. All the different sensory streams enter the system through multiple parallel channels. The system autonomously associates and combines them into a coherent representation, given incoming observations. These processes are adaptive and involve learning. The proposed framework introduces mechanisms for self-creation and learning of the functional relations between the computational maps, encoding sensorimotor streams, directly from the data. Its intrinsic scalability, parallelisation, and automatic adaptation to unforeseen sensory perturbations make our approach a promising candidate for robust multisensory fusion in robotic systems. We demonstrate this by applying our model to a 3D motion estimation on a quadrotor.},
  file         = {:pdf-files/Axenie2016 - A Self Synthesis Approach to Perceptual Learning for Multisensory Fusion in Robotics.pdf:PDF},
  groups       = {Neuromorphic Computing},
  owner        = {flo},
  timestamp    = {2017.01.24},
}

@Article{Azevedo2009,
  author       = {Azevedo, Frederico A. C. and Carvalho, Ludmila R. B. and Grinberg, Lea T. and Farfel, Jos{\'e} Marcelo and Ferretti, Renata E. L. and Leite, Renata E. P. and Filho, Wilson Jacob and Lent, Roberto and Herculano-Houzel, Suzana},
  title        = {Equal numbers of neuronal and nonneuronal cells make the human brain an isometrically scaled-up primate brain},
  journaltitle = {The Journal of Comparative Neurology},
  date         = {2009},
  volume       = {513},
  number       = {5},
  pages        = {532--541},
  abstract     = {The human brain is often considered to be the most cognitively capable among mammalian brains and to be much larger than expected for a mammal of our body size. Although the number of neurons is generally assumed to be a determinant of computational power, and despite the widespread quotes that the human brain contains 100 billion neurons and ten times more glial cells, the absolute number of neurons and glial cells in the human brain remains unknown. Here we determine these numbers by using the isotropic fractionator and compare them with the expected values for a human-sized primate. We find that the adult male human brain contains on average 86.1 +/- 8.1 billion NeuN-positive cells ("neurons") and 84.6 +/- 9.8 billion NeuN-negative ("nonneuronal") cells. With only 19\% of all neurons located in the cerebral cortex, greater cortical size (representing 82\% of total brain mass) in humans compared with other primates does not reflect an increased relative number of cortical neurons. The ratios between glial cells and neurons in the human brain structures are similar to those found in other primates, and their numbers of cells match those expected for a primate of human proportions. These findings challenge the common view that humans stand out from other primates in their brain composition and indicate that, with regard to numbers of neuronal and nonneuronal cells, the human brain is an isometrically scaled-up primate brain.},
  comment      = {Number of neurons in the human brain reference},
  file         = {:pdf-files/Azevedo2009 - Equal Numbers of Neuronal and Nonneuronal Cells Make the Human Brain an Isometrically Scaled up Primate Brain.pdf:PDF},
  groups       = {Biology},
  keywords     = {neuroscience},
  owner        = {flo},
  timestamp    = {2012-11-30T17:53:21.000+0100},
  username     = {lantiq},
}

@InProceedings{Bacha2004,
  author    = {A. Bacha and C. Reinholtz and A. Wicks and M. Fleming and A. Naik and M. Avitabile and N. Elder},
  title     = {The DARPA Grand Challenge: overview of the Virginia Tech vehicle and experience},
  booktitle = {Proceedings. The 7th International IEEE Conference on Intelligent Transportation Systems (IEEE Cat. No.04TH8749)},
  date      = {2004},
  pages     = {481--486},
  doi       = {10.1109/ITSC.2004.1398947},
  abstract  = {The DARPA Grand Challenge might be the greatest and most heralded control systems problem ever posed. The challenge was to build an autonomous vehicle that could navigate from Barstow, CA to Prim, NV, across hundreds of miles of rugged desert terrain. To win the million-dollar cash prize being offered by DARPA, the vehicle was required to traverse the course in less than ten hours with no operator intervention. Although no team came close to completing the course, the Grand Challenge opened a new era in unmanned ground vehicle navigation. From a field of more than one hundred entries, Virginia Tech was one of the fifteen teams to qualify for the final event and one of only seven teams to complete the entire pre-race qualifying course.},
  file      = {:pdf-files/Bacha2004 - The DARPA Grand Challenge_ Overview of the Virginia Tech Vehicle and Experience.pdf:PDF},
  groups    = {Autonomous Driving},
  keywords  = {mobile robots;navigation;remotely operated vehicles;Barstow;Defence Advanced Research Projects Agency;Prim;Virginia Tech Grand Challenge vehicle;autonomous vehicle;heralded control systems;million dollar cash prize;pre-race qualifying course;rugged desert terrain;unmanned ground vehicle navigation;Electric shock;Engines;Land vehicles;Mechanical engineering;Navigation;Permanent magnet motors;Remotely operated vehicles;Servomotors;Springs;Tires},
  owner     = {flo},
  timestamp = {2018.02.16},
}

@Article{Backus1978,
  author       = {Backus, John},
  title        = {Can Programming Be Liberated from the Von {N}eumann Style?: A Functional Style and Its Algebra of Programs},
  journaltitle = {Communications of the ACM},
  date         = {1978},
  volume       = {21},
  number       = {8},
  pages        = {613--641},
  issn         = {0001-0782},
  doi          = {10.1145/359576.359579},
  acmid        = {359579},
  comment      = {von Neumann bottleneck},
  file         = {:pdf-files/Backus1978 - Can Programming Be Liberated from the Von Neumann Style__ a Functional Style and Its Algebra of Programs.pdf:PDF},
  groups       = {Computing and GPU},
  issue_date   = {Aug. 1978},
  keywords     = {algebra of programs, applicative computing systems, applicative state transition systems, combining forms, functional forms, functional programming, metacomposition, models of computing systems, program correctness, program termination, program transformation, programming languages, von Neumann computers, von Neumann languages},
  location     = {New York, NY, USA},
  numpages     = {29},
  owner        = {flo},
  publisher    = {ACM},
  timestamp    = {2016.05.13},
}

@Article{Badrinarayanan2015,
  author       = {Vijay Badrinarayanan and Alex Kendall and Roberto Cipolla},
  title        = {Seg{N}et: {A} {D}eep {C}onvolutional {E}ncoder-{D}ecoder {A}rchitecture for {I}mage {S}egmentation},
  journaltitle = {Computing Research Repository (CoRR)},
  date         = {2015},
  volume       = {abs/1511.00561},
  url          = {http://arxiv.org/abs/1511.00561},
  comment      = {Code at:https://github.com/pradyu1993/segnet iPython-Notebook at: http://pradyu1993.github.io/2016/03/08/segnet-post.html},
  file         = {:pdf-files/Badrinarayanan2015 - SegNet_ a Deep Convolutional Encoder Decoder Architecture for Image Segmentation.pdf:PDF},
  groups       = {Deep Neural Networks},
  owner        = {flo},
  timestamp    = {2016.06.14},
}

@Article{Bahram2016,
  author       = {M. Bahram and C. Hubmann and A. Lawitzky and M. Aeberhard and D. Wollherr},
  title        = {A {C}ombined {M}odel- and {L}earning-{B}ased {F}ramework for {I}nteraction-{A}ware {M}aneuver {P}rediction},
  journaltitle = {IEEE Transactions on Intelligent Transportation Systems},
  date         = {2016},
  volume       = {17},
  number       = {6},
  pages        = {1538--1550},
  issn         = {1524-9050},
  doi          = {10.1109/TITS.2015.2506642},
  abstract     = {This paper presents a novel online-capable interaction-aware intention and maneuver prediction framework for dynamic environments. The main contribution is the combination of model-based interaction-aware intention estimation with maneuver-based motion prediction based on supervised learning. The advantages of this framework are twofold. On one hand, expert knowledge in the form of heuristics is integrated, which simplifies the modeling of the interaction. On the other hand, the difficulties associated with the scalability and data sparsity of the algorithm due to the so-called curse of dimensionality can be reduced, as a reduced feature space is sufficient for supervised learning. The proposed algorithm can be used for highly automated driving or as a prediction module for advanced driver assistance systems without the need of intervehicle communication. At the start of the algorithm, the motion intention of each driver in a traffic scene is predicted in an iterative manner using the game-theoretic idea of stochastic multiagent simulation. This approach provides an interpretation of what other drivers intend to do and how they interact with surrounding traffic. By incorporating this information into a Bayesian network classifier, the developed framework achieves a significant improvement in terms of reliable prediction time and precision compared with other state-of-the-art approaches. By means of experimental results in real traffic on highways, the validity of the proposed concept and its online capability is demonstrated. Furthermore, its performance is quantitatively evaluated using appropriate statistical measures.},
  file         = {:pdf-files/Bahram2016 - A Combined Model and Learning Based Framework for Interaction Aware Maneuver Prediction.pdf:PDF},
  groups       = {Behaviour analysis},
  keywords     = {Bayes methods;driver information systems;game theory;learning (artificial intelligence);pattern classification;statistical analysis;stochastic processes;Bayesian network classifier;advanced driver assistance systems;combined model-and learning-based framework;data sparsity;dimensionality curse;driver motion intention;dynamic environments;feature space reduction;game-theoretic idea;highly automated driving;interaction-aware maneuver prediction;maneuver-based motion prediction;model-based interaction-aware intention estimation;online-capable interaction-aware intention;statistical measures;stochastic multiagent simulation;supervised learning;traffic scene;Dynamics;Hidden Markov models;Predictive models;Reliability;Roads;Vehicles;Interaction-aware intention estimation;advanced driver assistance systems;highly automated driving;maneuver prediction},
  owner        = {flo},
  timestamp    = {2017.10.12},
}

@Article{Barranco2014,
  author       = {Barranco, F. and Fermuller, C. and Aloimonos, Y.},
  title        = {{C}ontour {M}otion {E}stimation for {A}synchronous {E}vent-{D}riven {C}ameras},
  journaltitle = {Proceedings of the IEEE},
  date         = {2014},
  volume       = {102},
  number       = {10},
  pages        = {1537--1556},
  issn         = {0018-9219},
  doi          = {10.1109/JPROC.2014.2347207},
  file         = {:pdf-files/Barranco2014 - Contour Motion Estimation for Asynchronous Event Driven Cameras.pdf:PDF},
  groups       = {Neuromorphic Vision},
  owner        = {flo},
  timestamp    = {2016.03.10},
}

@InBook{Bartolozzi1999,
  author    = {Bartolozzi, C. and Benosman, R. and Boahen, K. and Cauwenberghs, G. and Delbr{\"u}ck, Tobi and Indiveri, Giacomo and Liu, Shih-Chii and Furber, S. and Imam, N. and Linares-Barranco, Bernab{\'e} and Serrano-Gotarredona, Teresa and Meier, K. and Posch, C. and Valle, M. and Webster, John G.},
  title     = {Neuromorphic {S}ystems},
  booktitle = {Wiley Encyclopedia of Electrical and Electronics Engineering},
  date      = {1999},
  publisher = {John Wiley \& Sons, Inc.},
  isbn      = {9780471346081},
  doi       = {10.1002/047134608X.W8328},
  abstract  = {This article reviews a wide spectrum of state-of-the-art neuromorphic systems, ranging from its principles, sensory elements, and processing aspects to large-scale example systems and commercial outlook. It does not aim to provide a full coverage of present knowledge, but simply provide a comprehensive summary with many pointers to further readings.},
  file      = {:pdf-files/Bartolozzi1999 - Neuromorphic Systems.pdf:PDF},
  groups    = {Neuromorphic Computing},
  keywords  = {address event representation, neural processing, neural systems, sensors, spiking systems},
  owner     = {flo},
  timestamp = {2016.12.02},
}

@Article{Bekolay2014,
  author       = {Trevor Bekolay and James Bergstra and Eric Hunsberger and Travis DeWolf and Terrence C. Stewart and Daniel Rasmussen and Xuan Choo and Aaron Russell Voelker and Chris Eliasmith},
  title        = {{N}engo: {A} {P}ython tool for building large-scale functional brain models},
  journal      = {Frontiers in Neuroinformatics},
  journaltitle = {Frontiers in Neuroinformatics},
  year         = {2014},
  date         = {2014},
  volume       = {7},
  number       = {48},
  issn         = {1662-5196},
  doi          = {10.3389/fninf.2013.00048},
  abstract     = {Neuroscience currently lacks a comprehensive theory of how cognitive processes can be implemented in a biological substrate. The Neural Engineering Framework (NEF) proposes one such theory, but has not yet gathered significant empirical support, partly due to the technical challenge of building and simulating large-scale models with the NEF. Nengo is a software tool that can be used to build and simulate large-scale models based on the NEF; currently, it is the primary resource for both teaching how the NEF is used, and for doing research that generates specific NEF models to explain experimental data. Nengo 1.4, which was implemented in Java, was used to create Spaun, the world's largest functional brain model (Eliasmith et al., 2012). Simulating Spaun highlighted limitations in Nengo 1.4's ability to support model construction with simple syntax, to simulate large models quickly, and to collect large amounts of data for subsequent analysis. This paper describes Nengo 2.0, which is implemented in Python and overcomes these limitations. It uses simple and extendable syntax, simulates a benchmark model on the scale of Spaun 50 times faster than Nengo 1.4, and has a flexible mechanism for collecting simulation results.},
  file         = {:pdf-files/Bekolay2014 - Nengo_ a Python Tool for Building Large Scale Functional Brain Models.pdf:PDF},
  groups       = {Nengo},
  owner        = {flo},
  publisher    = {Frontiers Media {SA}},
  timestamp    = {2016.01.18},
}

@InProceedings{Bekolay2013,
  author       = {Bekolay, Trevor and Kolbeck, Carter and Eliasmith, Chris},
  title        = {Simultaneous unsupervised and supervised learning of cognitive functions in biologically plausible spiking neural networks},
  booktitle    = {35th Annual Conference of the Cognitive Science Society},
  date         = {2013},
  organization = {Cognitive Science Society},
  pages        = {169--174},
  abstract     = {We present a novel learning rule for learning transformations of sophisticated neural representations in a biologically plausible manner. We show that the rule can learn to transmit and bind semantic pointers. Semantic pointers have previously been used to build Spaun, which is currently the world's largest functional brain model (Eliasmith et al., 2012) and can perform several complex cognitive tasks. The learning rule combines a previously proposed supervised learning rule and a novel spiking form of the BCM unsupervised learning rule. We show that spiking BCM increases sparsity of connection weights at the cost of increased signal transmission error. We demonstrate that the combined learning rule can learn transformations as well as the supervised rule alone, and as well as the offline optimization used previously. We also demonstrate that the combined learning rule is more robust to changes in parameters and leads to better outcomes in higher dimensional spaces.},
  comment      = {Supdervised and unsupervised learning rules Nengo
PES Learning Rule reference},
  file         = {:pdf-files/Bekolay2013 - Simultaneous Unsupervised and Supervised Learning of Cognitive Functions in Biologically Plausible Spiking Neural Networks.pdf:PDF},
  groups       = {Nengo},
  owner        = {flo},
  presentation = {http://bekolay.org/cogsci2013-pres/},
  timestamp    = {2017.11.23},
}

@Article{Bekolay2015,
  author       = {Trevor Bekolay and Terrence C. Stewart and Chris Eliasmith},
  title        = {Benchmarking neuromorphic systems with Nengo},
  journaltitle = {Frontiers in Neuroscience},
  date         = {2015},
  volume       = {9},
  number       = {380},
  issn         = {1662-453X},
  doi          = {10.3389/fnins.2015.00380},
  abstract     = {Nengo is a software package for designing and simulating large-scale neural models. Nengo is architected such that the same Nengo model can be simulated on any of several Nengo backends with few to no modifications. Backends translate a model to specific platforms, which include GPUs and neuromorphic hardware. Nengo also contains a large test suite that can be run with any backend and focuses primarily on functional performance. We propose that Nengo's large test suite can be used to benchmark neuromorphic hardware's functional performance and simulation speed in an efficient, unbiased, and future-proof manner. We implement four benchmark models and show that Nengo can collect metrics across five different backends that identify situations in which some backends perform more accurately or quickly.},
  comment      = {The authors and the journal wish to retract this 19 October 2015 article. The authors requested the retraction of this article in November 2015 as data was included in this article which had been released without the permission of all collaborators involved in the research project.},
  file         = {:pdf-files/Bekolay2015 - Benchmarking Neuromorphic Systems with Nengo.pdf:PDF},
  groups       = {Machine Learning, Nengo, flo:5},
  journal      = {Frontiers in Neuroscience},
  owner        = {flo},
  publisher    = {Frontiers Media {SA}},
  timestamp    = {2016.01.18},
  year         = {2015},
}

@Article{Benjamin2014,
  author       = {Ben Varkey Benjamin and Peiran Gao and Emmett McQuinn and Swadesh Choudhary and Anand R. Chandrasekaran and Jean-Marie Bussat and Rodrigo Alvarez-Icaza and John V. Arthur and Paul A. Merolla and Kwabena Boahen},
  title        = {{Neurogrid: A Mixed-Analog-Digital Multichip System for Large-Scale Neural Simulations}},
  journaltitle = {Proceedings of the IEEE},
  date         = {2014},
  volume       = {102},
  number       = {5},
  pages        = {699--716},
  issn         = {0018-9219},
  doi          = {10.1109/jproc.2014.2313565},
  comment      = {funded by the US NIH Pioneer Award granted to Boahen in 2006},
  file         = {:pdf-files/Benjamin2014 - Neurogrid_ a Mixed Analog Digital Multichip System for Large Scale Neural Simulations.pdf:PDF},
  groups       = {Neuromorphic Hardware, Neurogrid},
  journal      = {Proceedings of the {IEEE}},
  keywords     = {analogue circuits;biology computing;digital circuits;network theory (graphs);neurophysiology;trees (mathematics);Neurogrid system;axonal arbor element;biological neural systems;dendritic tree element;electronic circuits;large-scale neural simulations;mixed-analog-digital multichip system;neural elements;neuromorphic systems;soma element;synapse element;synaptic connections;tree network;Computer architecture;Electronic circuits;Integrated circuit modeling;Nerve fibers;Neural networks;Neuroscience;Random access memory;Synchronous digital hierarchy;Analog circuits;application specific integrated circuits;asynchronous circuits;brain modeling;computational neuroscience;interconnection networks;mixed analog-digital integrated circuits;neural network hardware;neuromorphic electronic systems},
  owner        = {flo},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  timestamp    = {2016.02.18},
  year         = {2014},
}

@Article{Benosman2014,
  author       = {R. Benosman and C. Clercq and X. Lagorce and S. H. Ieng and C. Bartolozzi},
  title        = {Event-{B}ased {V}isual {F}low},
  journaltitle = {IEEE Transactions on Neural Networks and Learning Systems},
  date         = {2014},
  volume       = {25},
  number       = {2},
  pages        = {407--417},
  issn         = {2162-237X},
  doi          = {10.1109/TNNLS.2013.2273537},
  abstract     = {This paper introduces a new methodology to compute dense visual flow using the precise timings of spikes from an asynchronous event-based retina. Biological retinas, and their artificial counterparts, are totally asynchronous and data-driven and rely on a paradigm of light acquisition radically different from most of the currently used frame-grabber technologies. This paper introduces a framework to estimate visual flow from the local properties of events' spatiotemporal space. We will show that precise visual flow orientation and amplitude can be estimated using a local differential approach on the surface defined by coactive events. Experimental results are presented; they show the method adequacy with high data sparseness and temporal resolution of event-based acquisition that allows the computation of motion flow with microsecond accuracy and at very low computational cost.},
  file         = {:pdf-files/Benosman2014 - Event Based Visual Flow.pdf:PDF},
  groups       = {Neuromorphic Vision},
  keywords     = {eye;image sequences;asynchronous event-based retina;biological retinas;event-based visual flow;frame-grabber technologies;local differential approach;precise timings;precise visual flow orientation;Cameras;Real-time systems;Retina;Sensors;Timing;Visualization;Voltage control;Event-based vision;event-based visual motion flow;neuromorphic sensors;real time},
  owner        = {flo},
  timestamp    = {2016.04.14},
}

@Article{Berger2014,
  author       = {Christian Berger and Bernhard Rumpe},
  title        = {{Autonomous Driving - 5 Years after the Urban Challenge: The Anticipatory Vehicle as a Cyber-Physical System}},
  journaltitle = {Computing Research Repository (CoRR)},
  date         = {2014},
  url          = {http://arxiv.org/abs/1409.0413},
  file         = {:pdf-files/Berger2014 - Autonomous Driving 5 Years After the Urban Challenge_ the Anticipatory Vehicle As a Cyber Physical System.pdf:PDF},
  groups       = {Autonomous Driving},
  owner        = {flo},
  timestamp    = {Wed, 01 Oct 2014 15:00:05 +0200},
}

@InProceedings{Berndt2009,
  author    = {H. Berndt and K. Dietmayer},
  title     = {Driver intention inference with vehicle onboard sensors},
  booktitle = {2009 IEEE International Conference on Vehicular Electronics and Safety (ICVES)},
  date      = {2009},
  pages     = {102--107},
  doi       = {10.1109/ICVES.2009.5400203},
  abstract  = {This paper investigates methods to infer the driver's intention to leave the lane- or car-following state and start a specific manoeuvre, such as a lane change or a turn, from easily accessible vehicle onboard sensors, such as the vehicle data bus, GPS localisation, digital maps, and optionally camera-based lane detection. Pattern recognition and classification is done with Hidden Markov Models. Starting from suitable model grammars, training and evaluation processes are described with the focus on the task of early recognition during manoeuvre start. Information about imminent manoeuvres can then be used in driver assistance systems to predict trajectories or assess risk.},
  file      = {:pdf-files/Berndt2009 - Driver Intention Inference with Vehicle Onboard Sensors.pdf:PDF},
  groups    = {Behaviour analysis},
  keywords  = {hidden Markov models;pattern recognition;position control;road traffic;sensors;GPS localisation;camera based lane detection;digital maps;driver intention inference;hidden Markov models;pattern recognition;vehicle data bus;vehicle onboard sensors;Global Positioning System;Hidden Markov models;Human factors;Pattern recognition;Risk management;Signal generators;Trajectory;Vehicle detection;Vehicle driving;Vehicle dynamics},
  owner     = {flo},
  timestamp = {2017.09.20},
}

@Article{Bertozzi2000,
  author       = {Massimo Bertozzi and Alberto Broggi and Alessandra Fascioli},
  title        = {Vision-based intelligent vehicles: State of the art and perspectives},
  journaltitle = {Robotics and Autonomous Systems},
  date         = {2000},
  volume       = {32},
  number       = {1},
  pages        = {1--16},
  issn         = {0921-8890},
  doi          = {10.1016/S0921-8890(99)00125-6},
  url          = {http://www.sciencedirect.com/science/article/pii/S0921889099001256},
  abstract     = {Recently, a large emphasis has been devoted to Automatic Vehicle Guidance since the automation of driving tasks carries a large number of benefits, such as the optimization of the use of transport infrastructures, the improvement of mobility, the minimization of risks, travel time, and energy consumption. This paper surveys the most common approaches to the challenging task of Autonomous Road Following reviewing the most promising experimental solutions and prototypes developed worldwide using AI techniques to perceive the environmental situation by means of artificial vision. The most interesting results and trends in this field as well as the perspectives on the evolution of intelligent vehicles in the next decades are also sketched out.},
  file         = {:pdf-files/Bertozzi2000 - Vision Based Intelligent Vehicles_ State of the Art and Perspectives.pdf:PDF},
  groups       = {Autonomous Driving},
  keywords     = {Intelligent transportation systems (ITS), Automatic vehicle guidance, Intelligent vehicles, Machine vision},
  owner        = {flo},
  timestamp    = {2018.02.15},
}

@InProceedings{Beyeler2014,
  author    = {M. Beyeler and F. Mirus and A. Verl},
  title     = {Vision-based robust road lane detection in urban environments},
  booktitle = {2014 IEEE International Conference on Robotics and Automation (ICRA)},
  date      = {2014},
  pages     = {4920--4925},
  doi       = {10.1109/ICRA.2014.6907580},
  abstract  = {Road and lane detection play an important role in autonomous driving and commercial driver-assistance systems. Vision-based road detection is an essential step towards autonomous driving, yet a challenging task due to illumination and complexity of the visual scenery. Urban scenes may present additional challenges such as intersections, multi-lane scenarios, or clutter due to heavy traffic. This paper presents an integrative approach to ego-lane detection that aims to be as simple as possible to enable real-time computation while being able to adapt to a variety of urban and rural traffic scenarios. The approach at hand combines and extends a road segmentation method in an illumination-invariant color image, lane markings detection using a ridge operator, and road geometry estimation using RANdom SAmple Consensus (RANSAC). Employing the segmented road region as a prior for lane markings extraction significantly improves the execution time and success rate of the RANSAC algorithm, and makes the detection of weakly pronounced ridge structures computationally tractable, thus enabling ego-lane detection even in the absence of lane markings. Segmentation performance is shown to increase when moving from a color-based to a histogram correlation-based model. The power and robustness of this algorithm has been demonstrated in a car simulation system as well as in the challenging KITTI data base of real-world urban traffic scenarios.},
  file      = {:pdf-files/Beyeler2014 - Vision Based Robust Road Lane Detection in Urban Environments.pdf:PDF},
  groups    = {Environment Model},
  issn      = {1050-4729},
  keywords  = {computational geometry;computer vision;driver information systems;feature extraction;image colour analysis;image segmentation;intelligent transportation systems;iterative methods;object detection;road traffic;KITTI data base;RANSAC algorithm;autonomous driving;car simulation system;color-based model;commercial driver-assistance systems;ego-lane detection;geometry estimation;histogram correlation-based model;illumination-invariant color image;intelligent transportation systems;lane markings detection;lane markings extraction;multilane scenarios;random sample consensus;ridge operator;road segmentation method;rural traffic scenarios;urban traffic scenarios;vision-based robust road lane detection;visual scenery complexity;visual scenery illumination;Cameras;Computational modeling;Histograms;Image color analysis;Image segmentation;Roads;Robustness},
  owner     = {flo},
  timestamp = {2017.02.08},
}

@Article{Bi2001,
  author       = {Guo-Qiang Bi and Mu-Ming Poo},
  date         = {2001},
  journaltitle = {Annual Review of Neuroscience},
  title        = {Synaptic Modification by Correlated Activity: Hebb{\textquotesingle}s Postulate Revisited},
  doi          = {10.1146/annurev.neuro.24.1.139},
  number       = {1},
  pages        = {139--166},
  volume       = {24},
  abstract     = {Abstract Correlated spiking of pre- and postsynaptic neurons can result in strengthening or weakening of synapses, depending on the temporal order of spiking. Recent findings indicate that there are narrow and cell},
  file         = {:pdf-files/Bi2001 - Synaptic Modification by Correlated Activity_ Hebb's Postulate Revisited.pdf:PDF},
  groups       = {Biology, STDP},
  journal      = {Annual Review of Neuroscience},
  owner        = {flo},
  publisher    = {Annual Reviews},
  timestamp    = {2016.03.03},
  year         = {2001},
}

@Article{Bichler2012,
  author       = {Bichler, Olivier and Querlioz, Damien and Thorpe, Simon J. and Bourgoin, Jean-Philippe and Gamrat, Christian},
  title        = {Extraction of temporally correlated features from dynamic vision sensors with spike-timing-dependent plasticity.},
  journaltitle = {Neural Networks},
  date         = {2012},
  volume       = {32},
  pages        = {339--348},
  doi          = {10.1016/j.neunet.2012.02.022},
  url          = {http://dblp.uni-trier.de/db/journals/nn/nn32.html#BichlerQTBG12},
  added-at     = {2013-04-12T00:00:00.000+0200},
  biburl       = {http://www.bibsonomy.org/bibtex/2e1e6a6962f2da1fdd307622edf0bdcbe/dblp},
  file         = {:pdf-files/Bichler2012 - Extraction of Temporally Correlated Features from Dynamic Vision Sensors with Spike Timing Dependent Plasticity..pdf:PDF},
  groups       = {Neuromorphic Vision},
  interhash    = {7b174994d457177b03ee6988aa4fc68e},
  intrahash    = {e1e6a6962f2da1fdd307622edf0bdcbe},
  keywords     = {dblp},
  owner        = {flo},
  timestamp    = {2013-08-13T13:32:36.000+0200},
}

@Article{Bielza2014,
  author       = {Concha Bielza and Pedro Larra{\~{n}}aga},
  title        = {Discrete Bayesian Network Classifiers: A Survey},
  journaltitle = {ACM Computing Surveys},
  date         = {2014},
  volume       = {47},
  number       = {1},
  pages        = {1--43},
  issn         = {0360-0300},
  doi          = {10.1145/2576868},
  acmid        = {2576868},
  articleno    = {5},
  file         = {:pdf-files/Bielza2014 - Discrete Bayesian Network Classifiers_ a Survey.pdf:PDF},
  groups       = {Machine Learning, Bayesian Networks},
  issue_date   = {July 2014},
  journal      = {{ACM} Computing Surveys},
  keywords     = {Bayesian multinets, Bayesian network, Markov blanket, Supervised classification, feature subset selection, generative and discriminative classifiers, naive Bayes},
  location     = {New York, NY, USA},
  numpages     = {43},
  owner        = {flo},
  publisher    = {Association for Computing Machinery ({ACM})},
  timestamp    = {2016.02.09},
  year         = {2014},
}

@Article{Bielza2014a,
  author       = {Concha Bielza and Pedro Larra{\~{n}}aga},
  title        = {Bayesian networks in neuroscience: a survey},
  journal      = {Frontiers in Computational Neuroscience},
  journaltitle = {Frontiers in Computational Neuroscience},
  year         = {2014},
  date         = {2014},
  volume       = {8},
  number       = {131},
  issn         = {1662-5188},
  doi          = {10.3389/fncom.2014.00131},
  abstract     = {Bayesian networks are a type of probabilistic graphical models lie at the intersection between statistics and machine learning. They have been shown to be powerful tools to encode dependence relationships among the variables of a domain under uncertainty. Thanks to their generality, Bayesian networks can accommodate continuous and discrete variables, as well as temporal processes. In this paper we review Bayesian networks and how they can be learned automatically from data by means of structure learning algorithms. Also, we examine how a user can take advantage of these networks for reasoning by exact or approximate inference algorithms that propagate the given evidence through the graphical structure. Despite their applicability in many fields, they have been little used in neuroscience, where they have focused on specific problems, like functional connectivity analysis from neuroimaging data. Here we survey key research in neuroscience where Bayesian networks have been used with different aims: discover associations between variables, perform probabilistic reasoning over the model, and classify new observations with and without supervision. The networks are learned from data of any kind-morphological, electrophysiological, -omics and neuroimaging-, thereby broadening the scope-molecular, cellular, structural, functional, cognitive and medical- of the brain aspects to be studied.},
  file         = {:pdf-files/Bielza2014a - Bayesian Networks in Neuroscience_ a Survey.pdf:PDF},
  groups       = {Bayesian Inference with Spiking Neurons},
  owner        = {flo},
  publisher    = {Frontiers Media {SA}},
  timestamp    = {2016.02.09},
}

@Article{Binas2017,
  author       = {Binas, Jonathan and Niel, Daniel and Liu, Shih-Chii and Delbruck, Tobi},
  title        = {{DDD17: End-To-End DAVIS Driving Dataset}},
  journaltitle = {Computing Research Repository (CoRR)},
  date         = {2017},
  volume       = {abs/1711.01458},
  url          = {http://arxiv.org/abs/1711.01458},
  comment      = {dataset available at https://docs.google.com/document/d/1HM0CSmjO8nOpUeTvmPjopcBcVCk7KXvLUuiZFS6TWSg/pub},
  file         = {:pdf-files/Binas2017 - DDD17_ End to End DAVIS Driving Dataset.pdf:PDF},
  groups       = {Neuromorphic Vision},
  owner        = {flo},
  timestamp    = {2017.08.03},
}

@Article{Bittel2015,
  author       = {Sebastian Bittel and Vitali Kaiser and Marvin Teichmann and Martin Thoma},
  title        = {Pixel-wise {S}egmentation of {S}treet with {N}eural {N}etworks},
  journaltitle = {Computing Research Repository (CoRR)},
  date         = {2015},
  volume       = {abs/1511.00513},
  url          = {http://arxiv.org/abs/1511.00513},
  file         = {:pdf-files/Bittel2015 - Pixel Wise Segmentation of Street with Neural Networks.pdf:PDF},
  groups       = {Deep Neural Networks},
  owner        = {flo},
  timestamp    = {2016.06.10},
}

@Article{Blouw2016,
  author       = {Peter Blouw and Eugene Solodkin and Paul Thagard and Chris Eliasmith},
  title        = {Concepts as Semantic Pointers: A Framework and Computational Model},
  journaltitle = {Cognitive Science},
  date         = {2016},
  volume       = {40},
  number       = {5},
  pages        = {1128--1162},
  issn         = {1551-6709},
  doi          = {10.1111/cogs.12265},
  file         = {:pdf-files/Blouw2016 - Concepts As Semantic Pointers_ a Framework and Computational Model.pdf:PDF},
  groups       = {Nengo, Vector Symbolic Architectures},
  journal      = {Cognitive Science},
  keywords     = {Concepts, Categorization, Neural computation, Semantics, Computational modeling, Mental representation},
  owner        = {flo},
  publisher    = {Wiley},
  timestamp    = {2017.03.15},
  year         = {2015},
}

@Article{Boerlin2011,
  author       = {Martin Boerlin and Sophie Den{\`{e}}ve},
  title        = {Spike-Based Population Coding and Working Memory},
  journaltitle = {PLoS computational biology},
  date         = {2011},
  editor       = {Karl J. Friston},
  volume       = {7},
  number       = {2},
  pages        = {1--18},
  doi          = {10.1371/journal.pcbi.1001080},
  abstract     = {Compelling behavioral evidence suggests that humans can make optimal decisions despite the uncertainty inherent in perceptual or motor tasks. A key question in neuroscience is how populations of spiking neurons can implement such probabilistic computations. In this article, we develop a comprehensive framework for optimal, spike-based sensory integration and working memory in a dynamic environment. We propose that probability distributions are inferred spike-per-spike in recurrently connected networks of integrate-and-fire neurons. As a result, these networks can combine sensory cues optimally, track the state of a time-varying stimulus and memorize accumulated evidence over periods much longer than the time constant of single neurons. Importantly, we propose that population responses and persistent working memory states represent entire probability distributions and not only single stimulus values. These memories are reflected by sustained, asynchronous patterns of activity which make relevant information available to downstream neurons within their short time window of integration. Model neurons act as predictive encoders, only firing spikes which account for new information that has not yet been signaled. Thus, spike times signal deterministically a prediction error, contrary to rate codes in which spike times are considered to be random samples of an underlying firing rate. As a consequence of this coding scheme, a multitude of spike patterns can reliably encode the same information. This results in weakly correlated, Poisson-like spike trains that are sensitive to initial conditions but robust to even high levels of external neural noise. This spike train variability reproduces the one observed in cortical sensory spike trains, but cannot be equated to noise. On the contrary, it is a consequence of optimal spike-based inference. In contrast, we show that rate-based models perform poorly when implemented with stochastically spiking neurons.},
  file         = {:pdf-files/Boerlin2011 - Spike Based Population Coding and Working Memory.pdf:PDF},
  groups       = {Biology, Neural Modelling},
  journal      = {{PLoS} Computational Biology},
  owner        = {flo},
  publisher    = {Public Library of Science ({PLoS})},
  timestamp    = {2016.04.11},
  year         = {2011},
}

@Article{Bohte2004,
  author       = {Bohte, Sander M.},
  title        = {The evidence for neural information processing with precise spike-times: A survey},
  journaltitle = {Natural Computing},
  date         = {2004},
  volume       = {3},
  number       = {2},
  pages        = {195--206},
  issn         = {1572-9796},
  doi          = {10.1023/B:NACO.0000027755.02868.60},
  abstract     = {This paper surveys recent findings in neuroscience regarding the behavioral relevancy of the precise timing with which real spiking neurons emit spikes. The literature suggests that in almost any system where the processing-speed of a neural (sub)-system is required to be high, the timing of single spikes can be very precise and reliable. Additionally, new, more refined methods are finding precisely timed spikes where previously none where found. This line of evidence thus provides additional motivation for researching the computational properties of networks of artificial spiking neurons that compute with more precisely timed spikes.},
  file         = {:pdf-files/Bohte2004 - The Evidence for Neural Information Processing with Precise Spike Times_ a Survey.pdf:PDF},
  groups       = {Spiking Neural Networks},
  owner        = {flo},
  timestamp    = {2016.01.21},
}

@Article{Bohte2002,
  author       = {Bohte, S. M. and Kok, J. N. and LaPoutre, H.},
  title        = {Error-backpropagation in temporally encoded networks of spiking neurons},
  journaltitle = {Neurocomputing},
  date         = {2002},
  volume       = {48},
  pages        = {17--37},
  file         = {:pdf-files/Bohte2002 - Error Backpropagation in Temporally Encoded Networks of Spiking Neurons.pdf:PDF},
  groups       = {Spiking Neural Networks},
  owner        = {flo},
  timestamp    = {2016.03.03},
}

@Article{Bojarski2016,
  author       = {Mariusz Bojarski and Davide Del Testa and Daniel Dworakowski and Bernhard Firner and Beat Flepp and Prasoon Goyal and Lawrence D. Jackel and Mathew Monfort and Urs Muller and Jiakai Zhang and Xin Zhang and Jake Zhao and Karol Zieba},
  title        = {End to End Learning for Self-Driving Cars},
  journaltitle = {Computing Research Repository (CoRR)},
  date         = {2016},
  volume       = {abs/1604.07316},
  url          = {http://arxiv.org/abs/1604.07316},
  file         = {:pdf-files/Bojarski2016 - End to End Learning for Self Driving Cars.pdf:PDF},
  groups       = {Autonomous Driving},
  owner        = {flo},
  timestamp    = {2017.04.05},
}

@Article{Bootkrajang2013,
  author       = {Jakramate Bootkrajang and Ata Kaban},
  title        = {Boosting in the presence of label noise},
  journaltitle = {Computing Research Repository (CoRR)},
  date         = {2013},
  volume       = {abs/1309.6818},
  url          = {http://arxiv.org/abs/1309.6818},
  file         = {:pdf-files/Bootkrajang2013 - Boosting in the Presence of Label Noise.pdf:PDF},
  groups       = {Machine Learning, Boosting},
  owner        = {flo},
  timestamp    = {2016.02.09},
}

@Book{Bower1995,
  author    = {James M. Bower and David Beeman},
  title     = {The book of {GENESIS} - exploring realistic neural models with the {GE}neral {NE}ural models {S}Imulation system},
  date      = {1995},
  publisher = {Springer},
  isbn      = {978-0-387-94019-9},
  file      = {:pdf-files/Bower1995 - The Book of GENESIS Exploring Realistic Neural Models with the GEneral NEural Models SImulation System.pdf:PDF},
  groups    = {Neural Modelling},
  owner     = {flo},
  timestamp = {2016.04.11},
}

@Article{Brandli2014,
  author       = {C. Brandli and R. Berner and MinHao Yang and Shih-Chii Liu and T. Delbruck},
  title        = {A 240$\times$180 130 dB 3 $\mu$s {L}atency {G}lobal {S}hutter {S}patiotemporal {V}ision {S}ensor},
  journaltitle = {IEEE Journal of Solid-State Circuits},
  date         = {2014},
  volume       = {49},
  number       = {10},
  pages        = {2333--2341},
  issn         = {0018-9200},
  doi          = {10.1109/JSSC.2014.2342715},
  abstract     = {Event-based dynamic vision sensors (DVSs) asynchronously report log intensity changes. Their high dynamic range, sub-ms latency and sparse output make them useful in applications such as robotics and real-time tracking. However they discard absolute intensity information which is useful for object recognition and classification. This paper presents a dynamic and active pixel vision sensor (DAVIS) which addresses this deficiency by outputting asynchronous DVS events
 and synchronous global shutter frames concurrently. The active pixel sensor (APS) circuits and the DVS circuits within a pixel share a single photodiode. Measurements from a 240$\times$180 sensor array of 18.5 $\mu$m 2 pixels fabricated in a 0.18 $\mu$m 6M1P CMOS image sensor (CIS) technology show a dynamic range of 130 dB with 11\% contrast detection threshold, minimum 3 $\mu$s latency, and 3.5\% contrast matching for the DVS pathway; and a 51 dB dynamic range with 0.5\% FPN for the APS readout.},
  comment      = {DAVIS reference},
  file         = {:pdf-files/Brandli2014 - A 240$$180 130 DB 3 $$s Latency Global Shutter Spatiotemporal Vision Sensor.pdf:PDF},
  groups       = {Neuromorphic Vision, Neuromorphic Hardware},
  keywords     = {CMOS image sensors;photodetectors;photodiodes;sensor arrays;6M1P CMOS image sensor technology;APS circuit;CIS technology;DAVIS;DVS circuits;active pixel sensor circuit;asynchronously report log intensity change;dynamic and active pixel vision sensor;event-based dynamic vision sensor;gain 130 dB;gain 51 dB;latency global shutter spatiotemporal vision sensor;object classification;object recognition;photodiode;real-time tracking;robotics;sensor array;size 0.18 mum;time 3 mus;Cameras;Photoconductivity;Photodiodes;Photoreceptors;Robot sensing systems;Universal Serial Bus;Voltage control;Active pixel sensor (APS);CMOS image sensor;address event representation (AER);dynamic and active pixel vision sensor (DAVIS);dynamic vision sensor (DVS);event-based;neuromorphic engineering;spike-based},
  owner        = {flo},
  timestamp    = {2016.03.10},
}

@Article{Brette2007,
  author       = {Brette, Romain and Rudolph, Michelle and Carnevale, Ted and Hines, Michael and Beeman, David and Bower, James and Diesmann, Markus and Morrison, Abigail and Goodman, Philip and Harris, Frederick and Zirpe, Milind and Natschl{\"a}ger, Thomas and Pecevski, Dejan and Ermentrout, Bard and Djurfeldt, Mikael and Lansner, Anders and Rochel, Olivier and Vieville, Thierry and Muller, Eilif and Davison, Andrew and El Boustani, Sami and Destexhe, Alain},
  title        = {Simulation of networks of spiking neurons: A review of tools and strategies},
  journaltitle = {Journal of Computational Neuroscience},
  date         = {2007},
  volume       = {23},
  number       = {3},
  pages        = {349--398},
  file         = {:pdf-files/Brette2007 - Simulation of Networks of Spiking Neurons_ a Review of Tools and Strategies.pdf:PDF},
  groups       = {Simulators},
  owner        = {flo},
  timestamp    = {2016.02.19},
}

@InProceedings{Briochi2016,
  author    = {G. Briochi and M. Colombetti and M. D. Hina and A. Soukane and A. Ramdane-Cherif},
  title     = {Techniques for cognition of driving context for safe driving application},
  booktitle = {2016 IEEE 15th International Conference on Cognitive Informatics Cognitive Computing (ICCI*CC)},
  date      = {2016},
  pages     = {388--397},
  doi       = {10.1109/ICCI-CC.2016.7862066},
  abstract  = {In this work, given the context of the driver, of the vehicle and of the environment, our objective is to correctly recognize the traffic situation and provide the driver with the corresponding assistance by providing notification or alert about the situation or the infraction that was committed, or acting directly on the vehicle. To do so, we need to consider the signal processing related to these context parameters. We built knowledge representation using ontology, built rules related to the fusion of context parameters and the deduction corresponding to the traffic situation using Semantic Web Rule Language. We built fission component that deals with traffic situation and the corresponding action directed towards the driver or the vehicle. Ontology is used to represent driving model and road environment. This work is our contribution in the ongoing research for the prevention of vehicular traffic accident.},
  file      = {:pdf-files/Briochi2016 - Techniques for Cognition of Driving Context for Safe Driving Application.pdf:PDF},
  groups    = {Situation/Context analysis},
  keywords  = {knowledge representation;ontologies (artificial intelligence);semantic Web;traffic engineering computing;context parameters;driving context cognition;knowledge representation;ontology;safe driving application;semantic Web rule language;signal processing;traffic situation;traffic situation recognition;vehicular traffic accident;Accidents;Cognition;Context;Ontologies;Roads;Urban areas;Vehicles;Context cognition;Multimodal fusion and fission;Ontology;System modelling;Virtual reality simulation},
  owner     = {flo},
  timestamp = {2017.11.15},
}

@Book{Buehler2009,
  author    = {Buehler, Martin and Iagnemma, Karl and Singh, Sanjiv},
  title     = {{The DARPA Urban Challenge: Autonomous Vehicles in City Traffic}},
  date      = {2009},
  edition   = {1},
  publisher = {Springer Publishing Company, Incorporated},
  urldate   = {`},
  groups    = {Autonomous Driving},
  owner     = {flo},
  timestamp = {2016.04.01},
}

@Article{Calimera2013,
  author       = {Andrea Calimera and Enrico Macii and Massimo Poncino},
  title        = {The {H}uman {B}rain {P}roject and neuromorphic computing},
  journaltitle = {Functional Neurology},
  date         = {2013},
  volume       = {28},
  number       = {3},
  pages        = {191--196},
  abstract     = {Understanding how the brain manages billions of processing units connected via kilometers of fibers and trillions of synapses, while consuming a few tens of Watts could provide the key to a completely new category of hardware (neuromorphic computing sys- tems). In order to achieve this, a paradigm shift for computing as a whole is needed, which will see it moving away from current "bit precise" computing models and towards new techniques that exploit the stochastic behavior of simple, reliable, very fast, low- power computing devices embedded in intensely recursive architectures. In this paper we summarize how these objectives will be pursued in the Human Brain Project.},
  file         = {:pdf-files/Calimera2013 - The Human Brain Project and Neuromorphic Computing.pdf:PDF},
  groups       = {Neuromorphic Computing},
  owner        = {flo},
  timestamp    = {2016.01.18},
}

@Article{Campbell2010,
  author       = {Campbell, Mark and Egerstedt, Magnus and How, Jonathan P. and Murray, Richard M.},
  title        = {Autonomous driving in urban environments: approaches, lessons and challenges},
  journaltitle = {Philosophical Transactions of the Royal Society of London A: Mathematical, Physical and Engineering Sciences},
  date         = {2010},
  volume       = {368},
  number       = {1928},
  pages        = {4649--4672},
  issn         = {1364-503X},
  doi          = {10.1098/rsta.2010.0110},
  eprint       = {http://rsta.royalsocietypublishing.org/content/368/1928/4649.full.pdf},
  url          = {http://rsta.royalsocietypublishing.org/content/368/1928/4649},
  abstract     = {The development of autonomous vehicles for urban driving has seen rapid progress in the past 30 years. This paper provides a summary of the current state of the art in autonomous driving in urban environments, based primarily on the experiences of the authors in the 2007 DARPA Urban Challenge (DUC). The paper briefly summarizes the approaches that different teams used in the DUC, with the goal of describing some of the challenges that the teams faced in driving in urban environments. The paper also highlights the long-term research challenges that must be overcome in order to enable autonomous driving and points to opportunities for new technologies to be applied in improving vehicle safety, exploiting intelligent road infrastructure and enabling robotic vehicles operating in human environments.},
  file         = {:pdf-files/Campbell2010 - Autonomous Driving in Urban Environments_ Approaches, Lessons and Challenges.pdf:PDF},
  groups       = {Autonomous Driving},
  owner        = {flo},
  publisher    = {The Royal Society},
  timestamp    = {2016.08.29},
}

@InProceedings{Carlson2014,
  author    = {Kristofor D. Carlson and Michael Beyeler and Nikil Dutt and Jeffrey L. Krichmar},
  title     = {{GPGPU} accelerated simulation and parameter tuning for neuromorphic applications},
  booktitle = {2014 19th Asia and South Pacific Design Automation Conference ({ASP}-{DAC})},
  date      = {2014},
  publisher = {{IEEE}},
  pages     = {570--577},
  doi       = {10.1109/aspdac.2014.6742952},
  abstract  = {Neuromorphic engineering takes inspiration from biology to design brain-like systems that are extremely low-power, fault-tolerant, and capable of adaptation to complex environments. The design of these artificial nervous systems involves both the development of neuromorphic hardware devices and the development neuromorphic simulation tools. In this paper, we describe a simulation environment that can be used to design, construct, and run spiking neural networks (SNNs) quickly and efficiently using graphics processing units (GPUs). We then explain how the design of the simulation environment utilizes the parallel processing power of GPUs to simulate large-scale SNNs and describe recent modeling experiments performed using the simulator. Finally, we present an automated parameter tuning framework that utilizes the simulation environment and evolutionary algorithms to tune SNNs. We believe the simulation environment and associated parameter tuning framework presented here can accelerate the development of neuromorphic software and hardware applications by making the design, construction, and tuning of SNNs an easier task.},
  file      = {:pdf-files/Carlson2014 - GPGPU Accelerated Simulation and Parameter Tuning for Neuromorphic Applications.pdf:PDF},
  groups    = {Computing and GPU, Neural Modelling},
  keywords  = {biomedical electronics;graphics processing units;neural nets;GPGPU accelerated simulation;artificial nervous systems;automated parameter tuning framework;brain-like systems design;complex environments;development neuromorphic simulation tools;evolutionary algorithms;graphics processing units;large-scale SNN;neuromorphic hardware devices;neuromorphic software applications;parallel processing power;simulation environment;spiking neural networks;Brain modeling;Computational modeling;Computer architecture;Graphics processing units;Neuromorphics;Neurons;Tuning},
  owner     = {flo},
  timestamp = {2016.02.18},
  year      = {2014},
}

@Book{Carnevale2009,
  author    = {Carnevale, Nicholas T. and Hines, Michael L.},
  title     = {The NEURON Book},
  date      = {2009},
  edition   = {1},
  publisher = {Cambridge University Press},
  location  = {New York, NY, USA},
  isbn      = {9780521115636},
  groups    = {Neural Modelling, Simulators},
  owner     = {flo},
  timestamp = {2016.02.18},
}

@InCollection{Cauwenberghs1998,
  author    = {Gert Cauwenberghs},
  title     = {Neuromorphic Learning {VLSI} Systems: A Survey},
  booktitle = {The Springer International Series in Engineering and Computer Science},
  date      = {1998},
  editor    = {Lande, Tor Sverre},
  publisher = {Springer {US}},
  location  = {Boston, MA},
  isbn      = {978-0-585-28001-1},
  pages     = {381--408},
  doi       = {10.1007/978-0-585-28001-1_17},
  abstract  = {Carver Mead introduced "neuromorphic engineering" [1] as an interdisciplinary approach to the design of biologically inspired neural information processing systems, whereby neurophysiological models of perception and information processing in biological systems are mapped onto analog VLSI systems that not only emulate their functions but also resemble their structure [18]. The motivation for emulating neural function and structure in analog VLSI is the realization that challenging tasks of perception, classification, association and control successfully performed by living organisms can only be accomplished in artificial systems by using an implementation medium that matches their structure and organization.},
  file      = {:pdf-files/Cauwenberghs1998 - Neuromorphic Systems Engineering_ Neural Networks in Silicon.pdf:PDF},
  groups    = {Neuromorphic Computing},
  owner     = {flo},
  timestamp = {2016.03.09},
}

@InProceedings{Censi2014,
  author    = {Andrea Censi and Davide Scaramuzza},
  title     = {Low-latency event-based visual odometry},
  booktitle = {2014 {IEEE} International Conference on Robotics and Automation ({ICRA})},
  date      = {2014},
  publisher = {{IEEE}},
  doi       = {10.1109/icra.2014.6906931},
  url       = {http://purl.org/censi/2013/dvsd},
  abstract  = {The agility of a robotic system is ultimately limited by the speed of its processing pipeline. The use of a Dynamic Vision Sensors (DVS), a sensor producing asynchronous events as luminance changes are perceived by its pixels, makes it possible to have a sensing pipeline of a theoretical latency of a few microseconds. However, several challenges must be overcome: a DVS does not provide the grayscale value but only changes in the luminance; and because the output is composed by a sequence of events, traditional frame-based visual odometry methods are not applicable. This paper presents the first visual odometry system based on a DVS plus a normal CMOS camera to provide the absolute brightness values. The two sources of data are automatically spatiotemporally calibrated from logs taken during normal operation. We design a visual odometry method that uses the DVS events to estimate the relative displacement since the previous CMOS frame by processing each event individually. Experiments show that the rotation can be estimated with surprising accuracy, while the translation can be estimated only very noisily, because it produces few events due to very small apparent motion.},
  file      = {:pdf-files/Censi2014 - Low Latency Event Based Visual Odometry.pdf:PDF},
  groups    = {Neuromorphic Vision},
  owner     = {flo},
  timestamp = {2016.01.26},
  year      = {2014},
}

@InProceedings{Censi2013,
  author    = {Censi, Andrea and Strubel, Jonas and Brandli, Christian and Delbr{\"u}ck, Tobi and Scaramuzza, Davide},
  title     = {Low-latency localization by {A}ctive {LED} {M}arkers tracking using a {D}ynamic {V}ision {S}ensor},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  date      = {2013},
  location  = {Tokyo,Japan},
  pages     = {891--898},
  doi       = {10.1109/IROS.2013.6696456},
  abstract  = {At the current state of the art, the agility of an autonomous flying robot is limited by the speed of its sensing pipeline, as the relatively high latency and low sampling frequency limit the aggressiveness of the control strategies that can be implemented. To obtain more agile robots, we need faster sensors. A Dynamic Vision Sensor (DVS) encodes changes in the perceived brightness using an address-event representation. The latency of such sensors can be measured in the microseconds, thus offering the theoretical possibility of creating a sensing pipeline whose latency is negligible compared to the dynamics of the platform. However, to use these sensors we must rethink the way we interpret visual data. We present an approach to low-latency pose tracking using a DVS and Active Led Markers (ALMs), which are LEDs blinking at high frequency (>1 KHz). The DVS time resolution is able to distinguish different frequencies, thus avoiding the need for data association. We compare the DVS approach to traditional tracking using a CMOS camera, and we show that the DVS performance is not affected by fast motion, unlike the CMOS camera, which suffers from motion blur.},
  file      = {:pdf-files/Censi2013 - Low Latency Localization by Active LED Markers Tracking Using a Dynamic Vision Sensor.pdf:PDF},
  groups    = {Neuromorphic Vision},
  owner     = {flo},
  timestamp = {2016.03.10},
}

@InProceedings{Chen2015,
  author    = {Chenyi Chen and Ari Seff and Alain L. Kornhauser and Jianxiong Xiao},
  title     = {Deep{D}riving: {L}earning {A}ffordance for {D}irect {P}erception in {A}utonomous {D}riving},
  booktitle = {Proceedings of 15th IEEE International Conference on Computer Vision (ICCV2015)},
  date      = {2015},
  url       = {http://deepdriving.cs.princeton.edu},
  file      = {:pdf-files/Chen2015 - DeepDriving_ Learning Affordance for Direct Perception in Autonomous Driving.pdf:PDF},
  groups    = {Autonomous Driving, Deep Neural Networks},
  owner     = {flo},
  timestamp = {2016.10.26},
}

@Misc{Chollet2015keras,
  author    = {Francois Chollet},
  title     = {Keras},
  date      = {2015},
  url       = {https://github.com/keras-team/keras},
  urldate   = {2018-04-11},
  groups    = {Software and Tools},
  owner     = {flo},
  publisher = {GitHub},
  timestamp = {2016.06.10},
}

@InProceedings{Choo2013,
  author       = {Choo, Xuan and Eliasmith, Chris},
  title        = {General {I}nstruction {F}ollowing in a {L}arge-{S}cale {B}iologically {P}lausible {B}rain {M}odel},
  booktitle    = {35th Annual Conference of the Cognitive Science Society},
  date         = {2013},
  organization = {Cognitive Science Society},
  pages        = {322--327},
  abstract     = {We present a spiking neuron brain model implemented in 318,870 LIF neurons organized with distinct cortical modules, a basal ganglia, and a thalamus, that is capable of flexibly following memorized commands. Neural activity represents a structured set of rules, such as "If you see a 1, then push button A, and if you see a 2, then push button B". Synaptic connections between these neurons and the basal ganglia, thalamus, and other areas cause the system to detect when rules should be applied and to then do so. The model gives a reaction time difference of 77 ms between the simple and two-choice reaction time tasks, and requires 384 ms per item for sub-vocal counting, consistent with human experimental results. This is the first biologically realistic spiking neuron model capable of flexibly responding to complex structured instructions.},
  file         = {:pdf-files/Choo2013 - General Instruction Following in a Large Scale Biologically Plausible Brain Model.pdf:PDF},
  groups       = {Nengo},
  owner        = {flo},
  presentation = {http://compneuro.uwaterloo.ca/files/publications/choo.2013.presentation.pptx},
  timestamp    = {2017.03.24},
}

@InCollection{Choudhary2012,
  author    = {Swadesh Choudhary and Steven Sloan and Sam Fok and Alexander Neckar and Eric Trautmann and Peiran Gao and Terry Stewart and Chris Eliasmith and Kwabena Boahen},
  title     = {Silicon Neurons That Compute},
  booktitle = {Artificial Neural Networks and Machine Learning {\textendash} {ICANN} 2012},
  year      = {2012},
  date      = {2012},
  editor    = {Villa, Alessandro E. P. and Duch, W{\l}odzis{\l}aw and {\'E}rdi, P{\'e}ter and Masulli, Francesco and Palm, G{\"u}nther},
  publisher = {Springer Berlin Heidelberg},
  location  = {Berlin, Heidelberg},
  isbn      = {978-3-642-33269-2},
  pages     = {121--128},
  doi       = {10.1007/978-3-642-33269-2_16},
  abstract  = {We use neuromorphic chips to perform arbitrary mathematical computations for the first time. Static and dynamic computations are realized with heterogeneous spiking silicon neurons by programming their weighted connections. Using 4K neurons with 16M feed-forward or recurrent synaptic connections, formed by 256K local arbors, we communicate a scalar stimulus, quadratically transform its value, and compute its time integral. Our approach provides a promising alternative for extremely power-constrained embedded controllers, such as fully implantable neuroprosthetic decoders.},
  file      = {:pdf-files/Choudhary2012 - Artificial Neural Networks and Machine Learning ICANN 2012_ 22nd International Conference on Artificial Neural Networks, Lausanne, Switzerland, September 11 14, 2012, Proceedings, Part I.pdf:PDF},
  groups    = {Neuromorphic Computing},
  owner     = {flo},
  timestamp = {2016.02.16},
}

@InProceedings{Ciardelli2011,
  author    = {L. Ciardelli and L. Bixio and C. S. Regazzoni},
  title     = {Interaction modeling in automotive applications: A cognitive approach},
  booktitle = {2011 IEEE International Multi-Disciplinary Conference on Cognitive Methods in Situation Awareness and Decision Support (CogSIMA)},
  date      = {2011},
  pages     = {248--251},
  doi       = {10.1109/COGSIMA.2011.5753453},
  abstract  = {In the last decade, the design of smart tools applied to the automotive sector is becoming more and more required to support driving tasks and to increase drivers' safety. In this work, a system for the joint analysis of the on board/off board vehicle context is proposed to derive considerations on the driver's behavior and to detect possible dangerous situations. In particular, a cognitive model is exploited to provide a representation of interactions among the driver, the vehicle and the surrounding environment. Preliminary studies and results are presented concerning such a cognitive approach and the representation of occurring events for situation assessment and management towards maintenance and increasing of driver's safety.},
  file      = {:pdf-files/Ciardelli2011 - Interaction Modeling in Automotive Applications_ a Cognitive Approach.pdf:PDF},
  groups    = {Behaviour analysis},
  issn      = {2379-1667},
  keywords  = {cognition;driver information systems;intelligent sensors;automotive application;board vehicle context;cognitive model;dangerous situation;driver behavior;driver safety;interaction modeling;situation assessment;smart tool;Cameras;Context;Driver circuits;Intelligent vehicles;Safety;Sensors;Vehicles;Intelligent vehicles;interaction modeling;situation awareness;smart sensors},
  owner     = {flo},
  timestamp = {2017.11.15},
}

@Article{Ciresan2012,
  author       = {Dan C. Ciresan and Ueli Meier and Jonathan Masci and J{\"u}rgen Schmidhuber},
  title        = {Multi-column deep neural network for traffic sign classification},
  journaltitle = {Neural Networks},
  date         = {2012},
  volume       = {32},
  pages        = {333--338},
  doi          = {10.1016/j.neunet.2012.02.023},
  file         = {:pdf-files/Ciresan2012 - Multi Column Deep Neural Network for Traffic Sign Classification.pdf:PDF},
  groups       = {Object Recognition, Machine Learning, Deep Neural Networks},
  owner        = {flo},
  timestamp    = {Fri, 12 Apr 2013 14:25:42 +0200},
}

@InProceedings{Ciresan2012a,
  author    = {Dan C. Ciresan and Ueli Meier and J{\"u}rgen Schmidhuber},
  title     = {Multi-column deep neural networks for image classification},
  booktitle = {2012 {IEEE} Conference on Computer Vision and Pattern Recognition, Providence, RI, USA, June 16-21, 2012},
  date      = {2012},
  pages     = {3642--3649},
  doi       = {10.1109/CVPR.2012.6248110},
  file      = {:pdf-files/Ciresan2012a - Multi Column Deep Neural Networks for Image Classification.pdf:PDF},
  groups    = {Machine Learning, Deep Neural Networks},
  owner     = {flo},
  timestamp = {Tue, 25 Nov 2014 17:05:17 +0100},
}

@Article{Clady2014,
  author       = {Clady, Xavier and Clercq, Charles and Ieng, Sio-Hoi and Houseini, Fouzhan and Randazzo, Marco and Natale, Lorenzo and Bartolozzi, Chiara and Benosman, Ryad Benjamin},
  title        = {{Asynchronous Visual Event-based Time-to-Contact}},
  journaltitle = {Frontiers in Neuroscience},
  date         = {2014},
  volume       = {8},
  number       = {9},
  issn         = {1662-453X},
  doi          = {10.3389/fnins.2014.00009},
  abstract     = {Reliable and fast sensing of the environment is a fundamental requirement for autonomous mobile robotic platforms. Unfortunately, the frame-based acquisition paradigm at the basis of main stream artificial perceptive systems is limited by low temporal dynamics and redundant data flow, leading to high computational costs. Hence, conventional sensing and relative computation are obviously incompatible with the design of high speed sensor-based reactive control for mobile applications, that pose strict limits on energy consumption and computational load. This paper introduces a fast obstacle avoidance method based on the output of an asynchronous event-based time encoded imaging sensor. The proposed method relies on an event-based Time To Contact (TTC) computation based on visual event-based motion flows. The approach is event-based in the sense that every incoming event adds to the computation process thus allowing fast avoidance responses. The method is validated indoor on a mobile robot, comparing the event-based TTC with a laser range finder TTC, showing that event-based sensing offers new perspectives for mobile robotics sensing.},
  file         = {:pdf-files/Clady2014 - Asynchronous Visual Event Based Time to Contact.pdf:PDF},
  groups       = {Neuromorphic Vision},
  owner        = {flo},
  timestamp    = {2016.02.09},
}

@Article{Cohen2015,
  author       = {Nadav Cohen and Or Sharir and Amnon Shashua},
  title        = {{O}n the {E}xpressive {P}ower of {D}eep {L}earning: {A} {T}ensor {A}nalysis},
  journaltitle = {Computing Research Repository (CoRR)},
  date         = {2015},
  volume       = {abs/1509.05009},
  file         = {:pdf-files/Cohen2015 - On the Expressive Power of Deep Learning_ a Tensor Analysis.pdf:PDF},
  groups       = {Machine Learning, Deep Neural Networks},
  owner        = {flo},
  timestamp    = {2016.01.18},
}

@Article{Conradt2014,
  author       = {J{\"o}rg Conradt and Francesco Galluppi and Terrence C. Stewart},
  title        = {Trainable sensorimotor mapping in a neuromorphic robot},
  journaltitle = {Robotics and Autonomous Systems},
  date         = {2015},
  volume       = {71},
  pages        = {60--68},
  note         = {Emerging Spatial Competences: From Machine Perception to Sensorimotor Intelligence},
  issn         = {0921-8890},
  doi          = {10.1016/j.robot.2014.11.004},
  url          = {http://www.sciencedirect.com/science/article/pii/S0921889014002462},
  abstract     = {We present a mobile robot with sufficient computing power to simulate up to a quarter of a million neurons in real-time. We use this computing power, combined with various on-board sensory and motor systems (including silicon retinae) to implement a novel method for learning sensorimotor competences by example. That is, by temporarily manually controlling the robot, it can gather information about what sensorimotor mapping it should be performing. We show that such a learning-by-example system is well-suited to power efficient neuron-based computation (60W for all quarter of a million neurons), that it can learn quickly (a few tens of seconds), and that its learning generalizes well to novel situations.},
  file         = {:pdf-files/Conradt2014 - Trainable Sensorimotor Mapping in a Neuromorphic Robot.pdf:PDF},
  groups       = {Neuromorphic Robotics},
  keywords     = {Neuromorphic computing, SpiNNaker, Neural engineering, Nengo},
  owner        = {flo},
  timestamp    = {2016.05.30},
}

@PhdThesis{Conradt2008,
  author      = {J{\"o}rg Conradt},
  title       = {A Distributed Cognitive Map for Spatial Navigation Based on Graphically Organized Place Agents},
  institution = {Swiss Federal Institute of Technology (ETH) ZURICH},
  date        = {2008},
  abstract    = {Animals quickly acquire spatial knowledge and are thereby able to navigate over very large regions. These natural methods dramatically outperform current algorithms for robotic navigation, which are either limited to small regions (1) or require huge computational resources to maintain a globally consistent spatial map (2). We have now developed a novel system for mobile robotic navigation that like its biological counterpart decomposes explored space into a distributed graphical network of behaviorally significant places, each represented by an independent "place agent" (PA) that actively maintains the spatial and behavioral knowledge relevant for navigation in that place. Each PA operates only on its limited local information and communicates only with its directly connected graphical neighbors. Thus, there is no global supervisor and it is only necessary to maintain spatial consistency locally within the graph. This simple strategy significantly reduces computational complexity; scales well with the size of the navigable region; and permits a robot to autonomously explore, learn, and navigate large unknown office environments in real time.},
  file        = {:pdf-files/Conradt2008 - A Distributed Cognitive Map for Spatial Navigation Based on Graphically Organized Place Agents.pdf:PDF},
  groups      = {Neuromorphic Computing},
  owner       = {flo},
  timestamp   = {2016.04.06},
}

@InProceedings{Conradt2009,
  author    = {Conradt, J{\"o}rg and Cook, Matthew and Berner, Raphael and Lichtsteiner, Patrick and Douglas, Rodney J. and Delbr{\"u}ck, Tobi},
  title     = {{A} {P}encil {B}alancing {R}obot using a {P}air of {AER} {D}ynamic {V}ision {S}ensors.},
  booktitle = {ISCAS},
  date      = {2009},
  publisher = {IEEE},
  pages     = {781--784},
  doi       = {10.1109/ISCAS.2009.5117867},
  file      = {:pdf-files/Conradt2009 - A Pencil Balancing Robot Using a Pair of AER Dynamic Vision Sensors..pdf:PDF},
  groups    = {Neuromorphic Vision},
  owner     = {flo},
  timestamp = {2016.02.16},
}

@InProceedings{Cook2011,
  author    = {M. Cook and L. Gugelmann and F. Jug and C. Krautz and A. Steger},
  title     = {Interacting maps for fast visual interpretation},
  booktitle = {The 2011 International Joint Conference on Neural Networks (IJCNN)},
  date      = {2011},
  pages     = {770--776},
  doi       = {10.1109/IJCNN.2011.6033299},
  abstract  = {Biological systems process visual input using a distributed representation, with different areas encoding different aspects of the visual interpretation. While current engineering habits tempt us to think of this processing in terms of a pipelined sequence of filters and other feed-forward processing stages, cortical anatomy suggests quite a different architecture, using strong recurrent connectivity between visual areas. Here we design a network to interpret input from a neuromorphic sensor by means of recurrently interconnected areas, each of which encodes a different aspect of the visual interpretation, such as light intensity or optic flow. As each area of the network tries to be consistent with the information in neighboring areas, the visual interpretation converges towards global mutual consistency. Rather than applying input in a traditional feed-forward manner, the sensory input is only used to weakly influence the information flowing both ways through the middle of the network. Even with this seemingly weak use of input, this network of interacting maps is able to maintain its interpretation of the visual scene in real time, proving the viability of this interacting map approach to computation.},
  file      = {:pdf-files/Cook2011 - Interacting Maps for Fast Visual Interpretation.pdf:PDF},
  groups    = {Neural Modelling},
  issn      = {2161-4393},
  keywords  = {biology computing;cartography;filtering theory;image sequences;biological systems;cortical anatomy;distributed representation;feed-forward processing stages;global mutual consistency;interacting maps;light intensity;neuromorphic sensor;optic flow;visual interpretation;Adaptive optics;Cameras;Equations;Optical imaging;Optical network units;Optical sensors;Visualization},
  owner     = {flo},
  timestamp = {2016.11.03},
}

@Article{Cordts2016,
  author       = {Marius Cordts and Mohamed Omran and Sebastian Ramos and Timo Rehfeld and Markus Enzweiler and Rodrigo Benenson and Uwe Franke and Stefan Roth and Bernt Schiele},
  title        = {The {C}ityscapes {D}ataset for {S}emantic {U}rban {S}cene {U}nderstanding},
  journaltitle = {Computing Research Repository (CoRR)},
  date         = {2016},
  volume       = {abs/1604.01685},
  url          = {http://arxiv.org/abs/1604.01685},
  comment      = {helper scripts can be found online at https://github.com/mcordts/cityscapesScripts},
  file         = {:pdf-files/Cordts2016 - The Cityscapes Dataset for Semantic Urban Scene Understanding.pdf:PDF;:pdf-files/Cordts_The Cityscapes Dataset for Semantic Urban Scene Understanding_Suppl.pdf:PDF},
  groups       = {Object Recognition, Datasets},
  owner        = {flo},
  timestamp    = {2016.06.23},
}

@InProceedings{Corradi2014,
  author    = {F. Corradi and C. Eliasmith and G. Indiveri},
  title     = {Mapping arbitrary mathematical functions and dynamical systems to neuromorphic VLSI circuits for spike-based neural computation},
  booktitle = {Circuits and Systems (ISCAS), 2014 IEEE International Symposium on},
  date      = {2014},
  pages     = {269--272},
  doi       = {10.1109/ISCAS.2014.6865117},
  abstract  = {Brain-inspired, spike-based computation in electronic systems is being investigated for developing alternative, non-conventional computing technologies. The Neural Engineering Framework provides a method for programming these devices to implement computation. In this paper we apply this approach to perform arbitrary mathematical computation using a mixed signal analog/digital neuromorphic multi-neuron VLSI chip. This is achieved by means of a network of spiking neurons with multiple weighted connections. The synaptic weights are stored in a 4-bit on-chip programmable SRAM block. We propose a parallel event-based method for calibrating appropriately the synaptic weights and demonstrate the method by encoding and decoding arbitrary mathematical functions, and by implementing dynamical systems via recurrent connections.},
  file      = {:pdf-files/Corradi2014 - Mapping Arbitrary Mathematical Functions and Dynamical Systems to Neuromorphic VLSI Circuits for Spike Based Neural Computation.pdf:PDF},
  groups    = {Neural Modelling},
  keywords  = {SRAM chips;VLSI;mixed analogue-digital integrated circuits;neural chips;arbitrary mathematical function mapping;brain-inspired spike-based neural computation;decoding arbitrary mathematical functions;dynamical systems;electronic systems;encoding arbitrary mathematical functions;mixed signal analog-digital neuromorphic multineuron VLSI chip;multiple weighted connections;neural engineering framework;neuromorphic VLSI circuits;on-chip programmable SRAM block;parallel event-based method;storage capacity 4 bit;synaptic weights;Indium phosphide;Random access memory},
  owner     = {flo},
  timestamp = {2016.03.22},
}

@Article{Crawford2016,
  author       = {Crawford, Eric and Gingerich, Matthew and Eliasmith, Chris},
  title        = {Biologically {P}lausible, {H}uman-{S}cale {K}nowledge {R}epresentation},
  journaltitle = {Cognitive Science},
  date         = {2016},
  volume       = {40},
  number       = {4},
  pages        = {782--821},
  issn         = {1551-6709},
  doi          = {10.1111/cogs.12261},
  abstract     = {Several approaches to implementing symbol-like representations in neurally plausible models have been proposed. These approaches include binding through synchrony (Shastri & Ajjanagadde, ), "mesh" binding (van der Velde & de Kamps, ), and conjunctive binding (Smolensky, ). Recent theoretical work has suggested that most of these methods will not scale well, that is, that they cannot encode structured representations using any of the tens of thousands of terms in the adult lexicon without making implausible resource assumptions. Here, we empirically demonstrate that the biologically plausible structured representations employed in the Semantic Pointer Architecture (SPA) approach to modeling cognition (Eliasmith, ) do scale appropriately. Specifically, we construct a spiking neural network of about 2.5 million neurons that employs semantic pointers to successfully encode and decode the main lexical relations in WordNet, which has over 100,000 terms. In addition, we show that the same representations can be employed to construct recursively structured sentences consisting of arbitrary WordNet concepts, while preserving the original lexical structure. We argue that these results suggest that semantic pointers are uniquely well-suited to providing a biologically plausible account of the structured representations that underwrite human cognition.},
  file         = {:pdf-files/Crawford2016 - Biologically Plausible, Human Scale Knowledge Representation.pdf:PDF},
  groups       = {Neural Modelling, Vector Symbolic Architectures},
  keywords     = {Knowledge representation, Connectionism, Neural network, Biologically plausible, Vector symbolic architecture, WordNet, Scaling},
  owner        = {flo},
  timestamp    = {2016.08.24},
}

@Book{Cristianini2000,
  author    = {Cristianini, Nello and Shawe-Taylor, John},
  title     = {{An Introduction to Support Vector Machines: And Other Kernel-based Learning Methods}},
  date      = {2000},
  publisher = {Cambridge University Press},
  location  = {New York, NY, USA},
  isbn      = {0-521-78019-5},
  groups    = {Machine Learning, SVM},
  owner     = {flo},
  timestamp = {2016.02.09},
}

@InProceedings{Cutsuridis2013,
  author    = {V. Cutsuridis},
  title     = {Cognitive models of the perception-action cycle: {A} view from the brain},
  booktitle = {The 2013 International Joint Conference on Neural Networks (IJCNN)},
  date      = {2013},
  pages     = {1--8},
  doi       = {10.1109/IJCNN.2013.6706713},
  abstract  = {Perception-action cycle is the circular flow of information that takes place between an organism and its environment in the course of a sensory-guided sequence of actions towards a goal. Each action causes changes in the environment which are processed by the organism's sensory hierarchy and lead to the generation of further action by its motor effectors. These actions cause new changes that are sensory analyzed and lead to a new action, and so the cycle continues. The efficient and timely coordination of the sensory and motor structures involved will ensure the organism's survival in a dynamic environment. Two brain inspired cognitive models of the perception-action cycle are presented in this paper: (1) A cognitive model of visual saliency, overt attention and active visual search, and (2) A cognitive model of visuo-motor coordination of reaching and grasping. Both models are multi-modular. They share a number of features (visual saliency, focus of attention, recognition, expectation, resonance, value attribution), while at the same time have distinct properties.},
  file      = {:pdf-files/Cutsuridis2013 - Cognitive Models of the Perception Action Cycle_ a View from the Brain.pdf:PDF},
  groups    = {Neural Modelling, Spiking Neural Networks},
  issn      = {2161-4393},
  keywords  = {brain models;cognitive systems;visual perception;action sensory-guided sequence;active visual search;grasping;information circular flow;overt attention;perception-action cycle;reaching;two brain inspired cognitive models;visual saliency cognitive model;visuo-motor coordination;Brain models;Grasping;Neurons;Sociology;Statistics;Visualization},
  owner     = {flo},
  timestamp = {2016.08.11},
}

@Article{Cybenko1989,
  author       = {Cybenko, G.},
  title        = {Approximation by superpositions of a sigmoidal function},
  journaltitle = {Mathematics of Control, Signals and Systems},
  date         = {1989},
  volume       = {2},
  number       = {4},
  pages        = {303--314},
  issn         = {1435-568X},
  doi          = {10.1007/BF02551274},
  abstract     = {In this paper we demonstrate that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function ofn real variables with support in the unit hypercube; only mild conditions are imposed on the univariate function. Our results settle an open question about representability in the class of single hidden layer neural networks. In particular, we show that arbitrary decision regions can be arbitrarily well approximated by continuous feedforward neural networks with only a single internal, hidden layer and any continuous sigmoidal nonlinearity. The paper discusses approximation properties of other possible types of nonlinearities that might be implemented by artificial neural networks.},
  file         = {:pdf-files/Cybenko1989 - Approximation by Superpositions of a Sigmoidal Function.pdf:PDF},
  groups       = {Neural Networks},
  owner        = {flo},
  timestamp    = {2016.02.03},
}

@Article{Daly2011,
  author       = {R{\'{o}}n{\'{a}}n Daly and Qiang Shen and Stuart Aitken},
  title        = {Learning Bayesian networks: approaches and issues},
  journal      = {The Knowledge Engineering Review},
  journaltitle = {The Knowledge Engineering Review},
  year         = {2011},
  date         = {2011},
  volume       = {26},
  number       = {02},
  issue        = {02},
  pages        = {99--157},
  issn         = {1469-8005},
  doi          = {10.1017/s0269888910000251},
  url          = {http://journals.cambridge.org/article_S0269888910000251},
  file         = {:pdf-files/Daly2011 - Learning Bayesian Networks_ Approaches and Issues.pdf:PDF},
  groups       = {Machine Learning, Bayesian Networks},
  numpages     = {59},
  owner        = {flo},
  publisher    = {Cambridge University Press ({CUP})},
  timestamp    = {2016.02.09},
}

@InProceedings{Darms2008,
  author    = {Darms, M. and Rybski, P. and Urmson, C.},
  title     = {Classification and tracking of dynamic objects with multiple sensors for autonomous driving in urban environments},
  booktitle = {Intelligent Vehicles Symposium, 2008 IEEE},
  date      = {2008},
  pages     = {1197--1202},
  doi       = {10.1109/IVS.2008.4621259},
  file      = {:pdf-files/Darms2008 - Classification and Tracking of Dynamic Objects with Multiple Sensors for Autonomous Driving in Urban Environments.pdf:PDF},
  groups    = {Object Recognition},
  issn      = {1931-0587},
  keywords  = {driver information systems;pattern classification;sensor fusion;Tartan racing autonomous vehicle;data fusion algorithm;driver assistance systems;multiple sensors;object classification;object tracking;urban grand challenge;Intelligent sensors;Laser radar;Mobile robots;Object detection;Programmable control;Remotely operated vehicles;Sensor fusion;Sensor phenomena and characterization;Sensor systems;Vehicle dynamics},
  owner     = {flo},
  timestamp = {2015.12.16},
}

@Online{SYNAPSE-proj,
  author    = {{DARPA}},
  title     = {{DARPA SYNAPSE} webpage},
  url       = {https://www.darpa.mil/program/systems-of-neuromorphic-adaptive-plastic-scalable-electronics},
  urldate   = {2017-12-20},
  comment   = {TrueNorth Corelet language SyNAPSE is a DARPA-funded program to develop electronic neuromorphic machine technology that scales to biological levels. More simply stated, it is an attempt to build a new kind of computer with similar form and function to the mammalian brain. Such artificial brains would be used to build robots whose intelligence matches that of mice and cats. SyNAPSE is a backronym standing for Systems of Neuromorphic Adaptive Plastic Scalable Electronics. It started in 2008 and as of January 2013 has received 102.6 million dollars in funding. It is scheduled to run until around 2016. The project is primarily contracted to IBM and HRL who in turn subcontract parts of the research to various US universities. The ultimate aim is to build an electronic microprocessor system that matches a mammalian brain in function, size, and power consumption. It should recreate 10 billion neurons, 100 trillion synapses, consume one kilowatt (same as a small electric heater), and occupy less than two liters of space.},
  groups    = {Projects},
  owner     = {flo},
  timestamp = {2016.03.22},
}

@Article{Davies2010,
  author       = {Sergio Davies and Cameron Patterson and Francesco Galluppi and Alexander D. Rast and David R. Lester and Steve Furber},
  title        = {{I}nterfacing {R}eal-{T}ime {S}piking {I/O} with the {SpiNNaker} {N}euromimetic {A}rchitecture},
  journaltitle = {Australien Journal of Intelligent Information Processing Systems},
  date         = {2010},
  volume       = {11},
  number       = {1},
  file         = {:pdf-files/Davies2010 - Interfacing Real Time Spiking I_O with the SpiNNaker Neuromimetic Architecture.pdf:PDF},
  groups       = {Neuromorphic Hardware, SpiNNaker},
  owner        = {flo},
  timestamp    = {2016.01.18},
}

@Article{Davison2008,
  author       = {Davison, Andrew P. and Br{\"u}derle, Daniel and Eppler, Jochen and Kremkow, Jens and Muller, Eilif and Pecevski, Dejan and Perrinet, Laurent and Yger, Pierre},
  title        = {{P}y{N}{N}: {A} {C}ommon {I}nterface for {N}euronal {N}etwork {S}imulators},
  journaltitle = {Frontiers in neuroinformatics},
  date         = {2008},
  volume       = {2},
  pages        = {11},
  issn         = {1662-5196},
  doi          = {10.3389/neuro.11.011.2008},
  file         = {:pdf-files/Davison2008 - PyNN_ a Common Interface for Neuronal Network Simulators.pdf:PDF},
  groups       = {PyNN},
  owner        = {flo},
  timestamp    = {2015.12.10},
}

@Article{Deisenroth2013,
  author       = {Marc Peter Deisenroth and Gerhard Neumann and Jan Peters},
  title        = {A {S}urvey on {P}olicy {S}earch for {Real-Time} {R}obotics},
  journaltitle = {Foundations and Trends\textcircled{R} in Robotics},
  date         = {2013},
  volume       = {2},
  number       = {1-2},
  pages        = {1--142},
  issn         = {1935-8253},
  doi          = {10.1561/2300000021},
  abstract     = {Policy search is a subfield in reinforcement learning which focuses on finding good parameters for a given policy parametrization. It is well suited for robotics as it can cope with high-dimensional state and action spaces, one of the main challenges in robot learning. We review recent successes of both model-free and model-based policy search in robot learning. Model-free policy search is a general approach to learn policies based on sampled trajectories. We classify model-free methods based on their policy evaluation strategy, policy update strategy, and exploration strategy and present a unified view on existing algorithms. Learning a policy is often easier than learning an accurate forward model, and, hence, model-free methods are more frequently used in practice. How- ever, for each sampled trajectory, it is necessary to interact with the robot, which can be time consuming and challenging in practice. Model- based policy search addresses this problem by first learning a simulator of the robot's dynamics from data. Subsequently, the simulator gen- erates trajectories that are used for policy learning. For both model- free and model-based policy search methods, we review their respective properties and their applicability to robotic systems.},
  file         = {:pdf-files/Deisenroth2013 - A Survey on Policy Search for Real Time Robotics.pdf:PDF},
  groups       = {Robotics, ReinforcementLearning},
  owner        = {flo},
  timestamp    = {2016.10.19},
}

@Article{Delbruck2013,
  author       = {Delbruck, Tobi and Lang, Manuel},
  title        = {{R}obotic {G}oalie with 3ms {R}eaction {T}ime at 4\% {CPU} {L}oad {U}sing {E}vent-{B}ased {D}ynamic {V}ision {S}ensor},
  journaltitle = {Frontiers in Neuroscience},
  date         = {2013},
  volume       = {7},
  number       = {223},
  issn         = {1662-453X},
  doi          = {10.3389/fnins.2013.00223},
  abstract     = {Conventional vision-based robotic systems that must operate quickly require high video frame rates and consequently high computational costs. Visual response latencies are lower-bound by the frame period, e.g., 20 ms for 50 Hz frame rate. This paper shows how an asynchronous neuromorphic dynamic vision sensor (DVS) silicon retina is used to build a fast self-calibrating robotic goalie, which offers high update rates and low latency at low CPU load. Independent and
 asynchronous per pixel illumination change events from the DVS signify moving objects and are used in software to track multiple balls. Motor actions to block the most "threatening" ball are based on measured ball positions and velocities. The goalie also sees its single-axis goalie arm and calibrates the motor output map during idle periods so that it can plan open-loop arm movements to desired visual locations. Blocking capability is about 80\% for balls shot from 1 m from the goal even
 with the fastest-shots, and approaches 100\% accuracy when the ball does not beat the limits of the servo motor to move the arm to the necessary position in time. Running with standard USB buses under a standard preemptive multitasking operating system (Windows), the goalie robot achieves median update rates of 550 Hz, with latencies of 2.2 $\pm$ 2 ms from ball movement to motor command at a peak CPU load of less than 4\%. Practical observations and measurements of USB device latency are provided1.},
  file         = {:pdf-files/Delbruck2013 - Robotic Goalie with 3ms Reaction Time at 4% CPU Load Using Event Based Dynamic Vision Sensor.pdf:PDF},
  groups       = {Neuromorphic Vision},
  owner        = {flo},
  timestamp    = {2016.02.16},
}

@Article{Deneve2008,
  author       = {Den{\`e}ve, Sophie},
  title        = {Bayesian spiking neurons {I}: inference},
  journaltitle = {Neural computation},
  date         = {2008},
  volume       = {20},
  number       = {1},
  pages        = {91--117},
  issn         = {0899-7667},
  doi          = {10.1162/neco.2008.20.1.91},
  file         = {:pdf-files/Deneve2008 - Bayesian Spiking Neurons I_ Inference.pdf:PDF},
  groups       = {Bayesian Inference with Spiking Neurons},
  keywords     = {Action Potentials/physiology;Adaptation, Physiological/physiology;Algorithms;Animals;Bayes Theorem;Central Nervous System/physiology;Computer Simulation;Humans;Markov Chains;Models, Statistical;Movement/physiology;Nerve Net/physiology;Neural Networks (Computer);Neurons/physiology;Perception/physiology;Synaptic Transmission/physiology},
  owner        = {flo},
  timestamp    = {2016.02.09},
}

@Article{Deneve2008a,
  author       = {Den{\`e}ve, Sophie},
  title        = {Bayesian spiking neurons {II}: learning},
  journaltitle = {Neural computation},
  date         = {2008},
  volume       = {20},
  number       = {1},
  pages        = {118--145},
  issn         = {0899-7667},
  doi          = {10.1162/neco.2008.20.1.118},
  file         = {:pdf-files/Deneve2008a - Bayesian Spiking Neurons II_ Learning.pdf:PDF},
  groups       = {Bayesian Inference with Spiking Neurons},
  keywords     = {Action Potentials/physiology;Algorithms;Animals;Bayes Theorem;Central Nervous System/physiology;Computer Simulation;Humans;Learning/physiology;Markov Chains;Nerve Net/physiology;Neural Networks (Computer);Neuronal Plasticity/physiology;Neurons/physiology;Nonlinear Dynamics;Poisson Distribution;Synaptic Transmission/physiology;Time Perception/physiology},
  owner        = {flo},
  timestamp    = {2016.02.09},
}

@InProceedings{Deng2009,
  author    = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
  title     = {{ImageNet: A Large-Scale Hierarchical Image Database}},
  booktitle = {CVPR09},
  date      = {2009},
  comment   = {ImageNet Database reference},
  file      = {:pdf-files/Deng2009 - ImageNet_ a Large Scale Hierarchical Image Database.pdf:PDF},
  groups    = {Machine Learning, Datasets},
  owner     = {flo},
  timestamp = {2016.03.23},
}

@InProceedings{Denk2013,
  author    = {Christian Denk and Francisco Llobet{-}Blandino and Francesco Galluppi and Luis A. Plana and Steve Furber and J{\"o}rg Conradt},
  title     = {{Real-Time Interface Board for Closed-Loop Robotic Tasks on the SpiNNaker Neural Computing System}},
  booktitle = {Artificial Neural Networks and Machine Learning - {ICANN} 2013 - 23rd International Conference on Artificial Neural Networks, Sofia, Bulgaria, September 10-13, 2013. Proceedings},
  date      = {2013},
  pages     = {467--474},
  doi       = {10.1007/978-3-642-40728-4_59},
  file      = {:pdf-files/Denk2013 - Real Time Interface Board for Closed Loop Robotic Tasks on the SpiNNaker Neural Computing System.pdf:PDF},
  groups    = {Neuromorphic Robotics, Neuromorphic Hardware},
  owner     = {flo},
  timestamp = {2016.01.18},
}

@Article{Desantis2016,
  author       = {Andrea Desantis and Florian Waszak and Karolina Moutsopoulou and Patrick Haggard},
  title        = {How action structures time: About the perceived temporal order of action and predicted outcomes},
  journaltitle = {International Journal of Cognitive Science},
  date         = {2016},
  volume       = {146},
  pages        = {100--109},
  issn         = {0010-0277},
  doi          = {10.1016/j.cognition.2015.08.011},
  url          = {http://www.sciencedirect.com/science/article/pii/S001002771530055X},
  abstract     = {Few ideas are as inexorable as the arrow of causation: causes must precede their effects. Explicit or implicit knowledge about this causal order permits humans and other animals to predict and control events in order to produce desired outcomes. The sense of agency is deeply linked with representation of causation, since it involves the experience of a self-capable of acting on the world. Since causes must precede effects, the perceived temporal order of our actions and subsequent events should be relevant to the sense of agency. The present study investigated whether the ability to predict the outcome of an action would impose the classical cause-precedes-outcome pattern on temporal order judgements. Participants indicated whether a visual stimulus (dots moving upward or downward) was presented either before or after voluntary actions of the left or right hand. Crucially, the dot motion could be either congruent or incongruent with an operant association between hand and motion direction learned in a previous learning phase. When the visual outcome of voluntary action was congruent with previous learning, the motion onset was more often perceived as occurring after the action, compared to when the outcome was incongruent. This suggests that the prediction of specific sensory outcomes restructures our perception of timing of action and sensory events, inducing the experience that congruent effects occur after participants' actions. Interestingly, this bias to perceive events according to the temporal order of cause and outcome disappeared when participants knew that motion directions were automatically generated by the computer. This suggests that the reorganisation of time perception imposed by associative learning depends on participants' causal beliefs.},
  file         = {:pdf-files/Desantis2016 - How Action Structures Time_ about the Perceived Temporal Order of Action and Predicted Outcomes.pdf:PDF},
  groups       = {Neuroscience},
  keywords     = {Action, Prediction, Agency, Causality, Temporal order},
  owner        = {flo},
  timestamp    = {2018.02.22},
}

@InCollection{Dethier2011,
  author    = {Julie Dethier and Paul Nuyujukian and Chris Eliasmith and Terrence C. Stewart and Shauki A. Elasaad and Shenoy, Krishna V and Kwabena A. Boahen},
  title     = {{A Brain-Machine Interface Operating with a Real-Time Spiking Neural Network Control Algorithm}},
  booktitle = {Advances in Neural Information Processing Systems 24},
  date      = {2011},
  editor    = {J. Shawe-Taylor and R.S. Zemel and P.L. Bartlett and F. Pereira and K.Q. Weinberger},
  publisher = {Curran Associates, Inc.},
  pages     = {2213--2221},
  url       = {http://papers.nips.cc/paper/4276-a-brain-machine-interface-operating-with-a-real-time-spiking-neural-network-control-algorithm.pdf},
  abstract  = {Motor prostheses aim to restore function to disabled patients. Despite compelling proof of concept systems, barriers to clinical translation remain. One challenge is to develop a low-power, fully-implantable system that dissipates only minimal power so as not to damage tissue. To this end, we implemented a Kalman-filter based decoder via a spiking neural network (SNN) and tested it in brain-machine interface (BMI) experiments with a rhesus monkey. The Kalman filter was trained to predict the arm's velocity and mapped on to the SNN using the Neural Engineer- ing Framework (NEF). A 2,000-neuron embedded Matlab SNN implementation runs in real-time and its closed-loop performance is quite comparable to that of the standard Kalman filter. The success of this closed-loop decoder holds promise for hardware SNN implementations of statistical signal processing algorithms on neuromorphic chips, which may offer power savings necessary to overcome a major obstacle to the successful clinical translation of neural motor prostheses.},
  file      = {:pdf-files/Dethier2011 - A Brain Machine Interface Operating with a Real Time Spiking Neural Network Control Algorithm.pdf:PDF},
  groups    = {Neuromorphic Computing},
  owner     = {flo},
  timestamp = {2016.02.16},
}

@Article{DeWolf2016,
  author       = {DeWolf, Travis and Stewart, Terrence C. and Slotine, Jean-Jacques and Eliasmith, Chris},
  title        = {A spiking neural model of adaptive arm control},
  journaltitle = {Proceedings of the Royal Society of London B: Biological Sciences},
  date         = {2016},
  volume       = {283},
  number       = {1843},
  issn         = {0962-8452},
  doi          = {10.1098/rspb.2016.2134},
  eprint       = {http://rspb.royalsocietypublishing.org/content/283/1843/20162134.full.pdf},
  url          = {http://rspb.royalsocietypublishing.org/content/283/1843/20162134},
  abstract     = {We present a spiking neuron model of the motor cortices and cerebellum of the motor control system. The model consists of anatomically organized spiking neurons encompassing premotor, primary motor, and cerebellar cortices. The model proposes novel neural computations within these areas to control a nonlinear three-link arm model that can adapt to unknown changes in arm dynamics and kinematic structure. We demonstrate the mathematical stability of both forms of adaptation, suggesting that this is a robust approach for common biological problems of changing body size (e.g. during growth), and unexpected dynamic perturbations (e.g. when moving through different media, such as water or mud). To demonstrate the plausibility of the proposed neural mechanisms, we show that the model accounts for data across 19 studies of the motor control system. These data include a mix of behavioural and neural spiking activity, across subjects performing adaptive and static tasks. Given this proposed characterization of the biological processes involved in motor control of the arm, we provide several experimentally testable predictions that distinguish our model from previous work.},
  file         = {:pdf-files/DeWolf2016 - A Spiking Neural Model of Adaptive Arm Control.pdf:PDF},
  groups       = {Spiking Neural Networks},
  owner        = {flo},
  publisher    = {The Royal Society},
  timestamp    = {2017.09.21},
}

@Article{Dickmanns1990,
  author       = {E. D. Dickmanns and B. Mysliwetz and T. Christians},
  title        = {An integrated spatio-temporal approach to automatic visual guidance of autonomous vehicles},
  journaltitle = {IEEE Transactions on Systems, Man, and Cybernetics},
  date         = {1990},
  volume       = {20},
  number       = {6},
  pages        = {1273--1284},
  issn         = {0018-9472},
  doi          = {10.1109/21.61200},
  abstract     = {The Kalman filter approach to recursive state estimation making use of dynamic models for the motion of massive objects has been extended to image sequence processing. This confines image processing to the last frame of the sequence only, and derives a direct spatial interpretation including spatial velocity components by smoothing integrations of prediction errors. Results are presented for road-vehicle guidance at high speeds including obstacle detection and monocular relative spatial state estimation. The corresponding data-processing architecture is discussed; the system has been implemented on a MIMD parallel processing system. Speeds up to 100 km/h have been demonstrated},
  file         = {:pdf-files/Dickmanns1990 - An Integrated Spatio Temporal Approach to Automatic Visual Guidance of Autonomous Vehicles.pdf:PDF},
  groups       = {Autonomous Driving},
  keywords     = {Kalman filters;automatic guided vehicles;computer vision;road vehicles;state estimation;100 km/h;Kalman filter;MIMD parallel processing system;automatic visual guidance;autonomous vehicles;dynamic models;integrated spatio-temporal approach;monocular relative spatial state estimation;obstacle detection;prediction errors;recursive state estimation;smoothing;Humans;Image processing;Image sequences;Mobile robots;Navigation;Remotely operated vehicles;Roads;Shape measurement;State estimation;Video compression},
  owner        = {flo},
  timestamp    = {2018.02.15},
}

@InProceedings{Diehl2014,
  author    = {Diehl, Peter U. and Cook, Matthew},
  title     = {Efficient implementation of {STDP} rules on {SpiNNaker} neuromorphic hardware},
  booktitle = {2014 International Joint Conference on Neural Networks (IJCNN)},
  date      = {2014},
  pages     = {4288--4295},
  doi       = {10.1109/IJCNN.2014.6889876},
  abstract  = {Recent development of neuromorphic hardware offers great potential to speed up simulations of neural networks. SpiNNaker is a neuromorphic hardware and software system designed to be scalable and flexible enough to implement a variety of different types of simulations of neural systems, including spiking simulations with plasticity and learning. Spike-timing dependent plasticity (STDP) rules are the most common form of learning used in spiking networks. However, to date very few such rules have been implemented on SpiNNaker, in part because implementations must be designed to fit the specialized nature of the hardware. Here we explain how general STDP rules can be efficiently implemented in the SpiNNaker system. We give two examples of applications of the implemented rule: learning of a temporal sequence, and balancing inhibition and excitation of a neural network. Comparing the results from the SpiNNaker system to a conventional double-precision simulation, we find that the network behavior is comparable, and the final weights differ by less than 3\% between the two simulations, while the SpiNNaker simulation runs much faster, since it runs in real time, independent of network size.},
  file      = {:pdf-files/Diehl2014 - Efficient Implementation of STDP Rules on SpiNNaker Neuromorphic Hardware.pdf:PDF},
  groups    = {Neuromorphic Hardware, SpiNNaker, STDP},
  keywords  = {learning (artificial intelligence);neural nets;STDP rules;SpiNNaker neuromorphic hardware;inhibition balancing;network behavior;neural network excitation;neuromorphic hardware system;neuromorphic software system;spike-timing dependent plasticity rules;spiking neural networks;temporal sequence learning;Data structures;Delays;Hardware;Nerve fibers;Routing;SDRAM},
  owner     = {flo},
  timestamp = {2016.01.18},
}

@InProceedings{Diehl2015,
  author    = {Peter U. Diehl and Daniel Neil and Jonathan Binas and Matthew Cook and Shih-Chii Liu and Michael Pfeiffer},
  title     = {Fast-classifying, high-accuracy spiking deep networks through weight and threshold balancing},
  booktitle = {2015 International Joint Conference on Neural Networks (IJCNN)},
  year      = {2015},
  date      = {2015},
  publisher = {{IEEE}},
  pages     = {1--8},
  doi       = {10.1109/ijcnn.2015.7280696},
  abstract  = {Deep neural networks such as Convolutional Networks (ConvNets) and Deep Belief Networks (DBNs) represent the state-of-the-art for many machine learning and computer vision classification problems. To overcome the large computational cost of deep networks, spiking deep networks have recently been proposed, given the specialized hardware now available for spiking neural networks (SNNs). However, this has come at the cost of performance losses due to the conversion from analog neural networks (ANNs) without a notion of time, to sparsely firing, event-driven SNNs. Here we analyze the effects of converting deep ANNs into SNNs with respect to the choice of parameters for spiking neurons such as firing rates and thresholds. We present a set of optimization techniques to minimize performance loss in the conversion process for ConvNets and fully connected deep networks. These techniques yield networks that outperform all previous SNNs on the MNIST database to date, and many networks here are close to maximum performance after only 20 ms of simulated time. The techniques include using rectified linear units (ReLUs) with zero bias during training, and using a new weight normalization method to help regulate firing rates. Our method for converting an ANN into an SNN enables low-latency classification with high accuracies already after the first output spike, and compared with previous SNN approaches it yields improved performance without increased training time. The presented analysis and optimization techniques boost the value of spiking deep networks as an attractive framework for neuromorphic computing platforms aimed at fast and efficient pattern recognition.},
  file      = {:pdf-files/Diehl2015 - Fast Classifying, High Accuracy Spiking Deep Networks through Weight and Threshold Balancing.pdf:PDF},
  groups    = {Spiking Neural Networks},
  keywords  = {neural nets;pattern classification;ConvNets;MNIST database;ReLU;SNN;convolutional neural networks;deep ANN;firing rates;fully connected deep networks;low-latency classification;optimization techniques;rectified linear units;spiking deep networks;spiking neural networks;spiking neurons;threshold balancing;weight balancing;weight normalization method;Accuracy;Handheld computers;Neuromorphics;Neurons;Robustness},
  owner     = {flo},
  timestamp = {2016.01.18},
}

@Article{Doeller2010,
  author       = {Christian F. Doeller and Caswell Barry and Neil Burgess},
  title        = {Evidence for grid cells in a human memory network},
  journal      = {Nature},
  journaltitle = {Nature},
  year         = {2010},
  date         = {2010},
  volume       = {463},
  number       = {7281},
  pages        = {657--661},
  issn         = {1476-4687},
  doi          = {10.1038/nature08704},
  url          = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3173857/},
  abstract     = {Grid cells in entorhinal cortex of freely-moving rats provide a strikingly periodic representation of self-location() which is suggestive of very specific computational mechanisms(-). However, their existence in humans and distribution throughout the brain are unknown. Here we show that the preferred firing directions of directionally-modulated grid cells in rat entorhinal cortex are aligned with the grids, and that the spatial organization of grid cell firing is more strongly apparent at faster than slower running speeds. Since the grids are also aligned with each other(,), we predicted a macroscopic signal visible to functional magnetic resonance imaging (fMRI) in humans. We then looked for this signal as participants explored a virtual reality environment, mimicking the rats' foraging task: fMRI activation and adaptation showing a speed-modulated 6-fold rotational symmetry in running direction. The signal was found in a network of entorhinal/subicular, posterior and medial parietal, lateral temporal and medial prefrontal areas. The effect was strongest in right entorhinal cortex, and the coherence of the directional signal across entorhinal cortex correlated with spatial memory performance. Our study illustrates the potential power of combining single unit electrophysiology with fMRI in systems neuroscience. Our results provide the first evidence for grid-cell-like representations in humans, and implicate a specific type of neural representation in a network of regions which support spatial cognition and also, intriguingly, autobiographical memory.},
  comment      = {20090680[pmid] 20090680[pmid]},
  file         = {:pdf-files/Doeller2010 - Evidence for Grid Cells in a Human Memory Network.pdf:PDF},
  groups       = {Biology},
  owner        = {flo},
  publisher    = {Springer Nature},
  timestamp    = {2016.04.06},
}

@Article{Domingos2012,
  author       = {Domingos, Pedro},
  title        = {{A Few Useful Things to Know About Machine Learning}},
  journaltitle = {Communications of the ACM},
  date         = {2012},
  volume       = {55},
  number       = {10},
  pages        = {78--87},
  issn         = {0001-0782},
  doi          = {10.1145/2347736.2347755},
  acmid        = {2347755},
  file         = {:pdf-files/Domingos2012 - A Few Useful Things to Know about Machine Learning.pdf:PDF},
  groups       = {Machine Learning},
  issue_date   = {October 2012},
  location     = {New York, NY, USA},
  numpages     = {10},
  owner        = {flo},
  publisher    = {ACM},
  timestamp    = {2016.01.28},
}

@InProceedings{Dosovitskiy2017,
  author    = {Alexey Dosovitskiy and German Ros and Felipe Codevilla and Antonio Lopez and Vladlen Koltun},
  title     = {{CARLA}: {An} {O}pen {U}rban {D}riving {S}imulator},
  booktitle = {Proceedings of the 1st Annual Conference on Robot Learning},
  date      = {2017},
  pages     = {1--16},
  url       = {http://carla.org},
  comment   = {github repository: https://github.com/carla-simulator/carla},
  file      = {:pdf-files/Dosovitskiy2017 - CARLA_ an Open Urban Driving Simulator.pdf:PDF},
  groups    = {Simulators},
  owner     = {flo},
  timestamp = {2017.11.16},
}

@Article{Drazen2011,
  author       = {Drazen, David and Lichtsteiner, Patrick and Hafliger, Philipp and Delbruck, Tobi and Jensen, Atle},
  title        = {{T}oward real-time particle tracking using an event-based dynamic vision sensor},
  journaltitle = {Experiments in Fluids},
  date         = {2011},
  volume       = {51},
  number       = {5},
  pages        = {1465--1469},
  file         = {:pdf-files/Drazen2011 - Toward Real Time Particle Tracking Using an Event Based Dynamic Vision Sensor.pdf:PDF},
  groups       = {Neuromorphic Vision},
  owner        = {flo},
  timestamp    = {2016.04.14},
}

@InProceedings{Duan2016,
  author    = {Yan Duan and Xi Chen and Rein Houthooft and John Schulman and Pieter Abbeel},
  title     = {Benchmarking Deep Reinforcement Learning for Continuous Control},
  booktitle = {Proceedings of the 33nd International Conference on Machine Learning, {ICML} 2016, New York City, NY, USA, June 19-24, 2016},
  date      = {2016},
  pages     = {1329--1338},
  url       = {http://jmlr.org/proceedings/papers/v48/duan16.html},
  file      = {:pdf-files/Duan2016 - Benchmarking Deep Reinforcement Learning for Continuous Control.pdf:PDF},
  groups    = {ReinforcementLearning},
  owner     = {flo},
  timestamp = {Tue, 12 Jul 2016 21:51:16 +0200},
}

@Article{Elfring2016,
  author       = {Elfring, Jos and Appeldoorn, Rein and van den Dries, Sjoerd and Kwakkernaat, Maurice},
  title        = {Effective {W}orld {M}odeling: {M}ultisensor {D}ata {F}usion {M}ethodology for {A}utomated {D}riving},
  journaltitle = {Sensors},
  date         = {2016},
  volume       = {16},
  number       = {10},
  pages        = {1668},
  issn         = {1424-8220},
  doi          = {10.3390/s16101668},
  url          = {http://www.mdpi.com/1424-8220/16/10/1668},
  abstract     = {The number of perception sensors on automated vehicles increases due to the increasing number of advanced driver assistance system functions and their increasing complexity. Furthermore, fail-safe systems require redundancy, thereby increasing the number of sensors even further. A one-size-fits-all multisensor data fusion architecture is not realistic due to the enormous diversity in vehicles, sensors and applications. As an alternative, this work presents a methodology that can be used to effectively come up with an implementation to build a consistent model of a vehicle's surroundings. The methodology is accompanied by a software architecture. This combination minimizes the effort required to update the multisensor data fusion system whenever sensors or applications are added or replaced. A series of real-world experiments involving different sensors and algorithms demonstrates the methodology and the software architecture.},
  file         = {:pdf-files/Elfring2016 - Effective World Modeling_ Multisensor Data Fusion Methodology for Automated Driving.pdf:PDF},
  groups       = {Environment Model},
  owner        = {flo},
  timestamp    = {2016.10.12},
}

@Book{Eliasmith2013,
  author       = {Chris Eliasmith},
  title        = {{H}ow to build a brain: {A} neural architecture for biological cognition},
  date         = {2013},
  publisher    = {Oxford University Press},
  location     = {New York, NY},
  organization = {Oxford University Press},
  owner        = {flo},
  timestamp    = {2016.01.19},
}

@Book{Eliasmith2003,
  author    = {Eliasmith, Chris and Anderson, Charles H.},
  title     = {{Neural Engineering : Computation, Representation, and Dynamics in Neurobiological Systems}},
  date      = {2003},
  series    = {Computational neuroscience},
  publisher = {Cambridge, Mass. MIT Press},
  isbn      = {0-262-05071-4},
  groups    = {Nengo},
  owner     = {flo},
  timestamp = {2016.03.10},
}

@Article{Eliasmith2016,
  author       = {{Eliasmith}, C. and {Gosmann}, J. and {Choo}, X.},
  title        = {{BioSpaun: A large-scale behaving brain model with complex neurons}},
  journaltitle = {ArXiv e-prints},
  date         = {2016},
  eprint       = {1602.05220},
  eprintclass  = {q-bio.NC},
  eprinttype   = {arXiv},
  abstract     = {We describe a large-scale functional brain model that includes detailed, conductance- based, compartmental models of individual neurons. We call the model BioSpaun, to indicate the increased biological plausibility of these neurons, and because it is a direct extension of the Spaun model [1]. We demonstrate that including these detailed compartmental models does not adversely affect performance across a variety of tasks, including digit recognition, serial work- ing memory, and counting. We then explore the effects of applying TTX, a sodium channel blocking drug, to the model. We characterize the behav- ioral changes that result from this molecular level intervention. We believe this is the first demonstration of a large-scale brain model that clearly links low-level molecular interventions and high-level behavior.},
  file         = {:pdf-files/Eliasmith2016 - BioSpaun_ a Large Scale Behaving Brain Model with Complex Neurons.pdf:PDF},
  groups       = {Neural Modelling},
  keywords     = {Quantitative Biology - Neurons and Cognition, Computer Science - Artificial Intelligence},
  owner        = {flo},
  timestamp    = {2016.08.24},
}

@Article{Eliasmith2012,
  author       = {Eliasmith, Chris and Stewart, Terrence C. and Choo, Xuan and Bekolay, Trevor and DeWolf, Travis and Tang, Yichuan and Rasmussen, Daniel},
  title        = {{A Large-Scale Model of the Functioning Brain}},
  journaltitle = {Science},
  date         = {2012},
  volume       = {338},
  number       = {6111},
  pages        = {1202--1205},
  issn         = {0036-8075},
  doi          = {10.1126/science.1225266},
  eprint       = {http://science.sciencemag.org/content/338/6111/1202.full.pdf},
  url          = {http://science.sciencemag.org/content/338/6111/1202},
  abstract     = {A central challenge for cognitive and systems neuroscience is to relate the incredibly complex behavior of animals to the equally complex activity of their brains. Recently described, large-scale neural models have not bridged this gap between neural activity and biological function. In this work, we present a 2.5-million-neuron model of the brain (called {\textquotedblleft}Spaun{\textquotedblright}) that bridges this gap by exhibiting many different behaviors. The model is presented only with visual image sequences, and it draws all of its responses with a physically modeled arm. Although simplified, the model captures many aspects of neuroanatomy, neurophysiology, and psychological behavior, which we demonstrate via eight diverse tasks.},
  file         = {:pdf-files/Eliasmith2012 - A Large Scale Model of the Functioning Brain.pdf:PDF},
  groups       = {Neural Modelling},
  owner        = {flo},
  publisher    = {American Association for the Advancement of Science},
  timestamp    = {2016.01.19},
}

@InProceedings{Engstrom2001,
  author    = {J. Engstrom and T. Victor},
  title     = {Real-time recognition of large-scale driving patterns},
  booktitle = {ITSC 2001. 2001 IEEE Intelligent Transportation Systems. Proceedings (Cat. No.01TH8585)},
  date      = {2001},
  pages     = {1018--1023},
  doi       = {10.1109/ITSC.2001.948801},
  abstract  = {This work has explored the possibilities of real-time, automatic, recognition of large-scale driving situations. Employing a statistical pattern recognition framework, implemented by means of feedforward neural networks, models were developed for recognising, from vehicle control data, four classes of driving situations: highway, main road, suburban traffic and city traffic},
  file      = {:pdf-files/Engstrom2001 - Real Time Recognition of Large Scale Driving Patterns.pdf:PDF},
  groups    = {Situation/Context analysis},
  keywords  = {Bayes methods;feedforward neural nets;pattern recognition;probability;road vehicles;city traffic;feedforward neural networks;highway;large-scale driving patterns;main road;real-time recognition;statistical pattern recognition framework;suburban traffic;traffic safety;Automated highways;Automatic control;Communication system traffic control;Feedforward neural networks;Large-scale systems;Neural networks;Pattern recognition;Road vehicles;Traffic control;Vehicle driving},
  owner     = {flo},
  timestamp = {2017.11.15},
}

@InProceedings{Esser2013,
  author    = {Steven K. Esser and Alexander Andreopoulos and Rathinakumar Appuswamy and Pallab Datta and Davis Barch and Arnon Amir and John V. Arthur and Andrew Cassidy and Myron Flickner and Paul Merolla and Shyamal Chandra and Nicola Basilico and Stefano Carpin and Tom Zimmerman and Frank Zee and Rodrigo Alvarez{-}Icaza and Jeffrey A. Kusnitz and Theodore M. Wong and William P. Risk and Emmett McQuinn and Tapan K. Nayak and Raghavendra Singh and Dharmendra S. Modha},
  title     = {Cognitive computing systems: {A}lgorithms and applications for networks of neurosynaptic cores},
  booktitle = {The 2013 International Joint Conference on Neural Networks, {IJCNN} 2013, Dallas, TX, USA, August 4-9, 2013},
  date      = {2013},
  pages     = {1--10},
  doi       = {10.1109/IJCNN.2013.6706746},
  file      = {:pdf-files/Esser2013 - Cognitive Computing Systems_ Algorithms and Applications for Networks of Neurosynaptic Cores.pdf:PDF},
  groups    = {TrueNorth},
  owner     = {flo},
  timestamp = {Wed, 17 Jun 2015 13:44:42 +0200},
}

@InProceedings{Fairfield2011,
  author    = {Fairfield, Nathaniel and Urmson, Chris},
  title     = {Traffic light mapping and detection.},
  booktitle = {ICRA},
  date      = {2011},
  publisher = {IEEE},
  pages     = {5421--5426},
  doi       = {10.1109/ICRA.2011.5980164},
  file      = {:pdf-files/Fairfield2011 - Traffic Light Mapping and Detection..pdf:PDF},
  groups    = {Object Recognition},
  keywords  = {dblp},
  owner     = {flo},
  timestamp = {2016.01.18},
}

@Article{FeiFei2006,
  author       = {Li Fei-Fei and R. Fergus and P. Perona},
  title        = {One-shot learning of object categories},
  journal      = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year         = {2006},
  date         = {2006},
  volume       = {28},
  number       = {4},
  issue        = {4},
  pages        = {594--611},
  doi          = {10.1109/tpami.2006.79},
  comment      = {Caltech 101 Database reference},
  file         = {:pdf-files/FeiFei2006 - One Shot Learning of Object Categories.pdf:PDF},
  groups       = {Machine Learning, Datasets},
  owner        = {flo},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  timestamp    = {2016.03.23},
}

@Article{Flanagan2003,
  author       = {Flanagan, J. R. and Vetter, P. and Johansson, R. S. and Wolpert, D. M.},
  title        = {{{P}rediction precedes control in motor learning}},
  journaltitle = {Current Biology},
  date         = {2003},
  volume       = {13},
  number       = {2},
  pages        = {146--150},
  file         = {:pdf-files/Flanagan2003 - Prediction Precedes Control in Motor Learning.pdf:PDF},
  groups       = {Neuroscience},
  owner        = {flo},
  timestamp    = {2018.02.22},
}

@Article{Fong2018,
  author       = {{Fong}, R. and {Vedaldi}, A.},
  title        = {{Net2Vec: Quantifying and Explaining how Concepts are Encoded by Filters in Deep Neural Networks}},
  journaltitle = {ArXiv e-prints},
  date         = {2018},
  eprint       = {1801.03454},
  eprinttype   = {arXiv},
  file         = {:pdf-files/Fong2018 - Net2Vec_ Quantifying and Explaining How Concepts Are Encoded by Filters in Deep Neural Networks.pdf:PDF},
  groups       = {Word Embedding, Deep Neural Networks},
  keywords     = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence, Statistics - Machine Learning},
  owner        = {flo},
  timestamp    = {2018.01.14},
}

@InProceedings{Frenay2014a,
  author    = {Beno{\^i}t Fr{\'e}nay and Ata Kab{\'a}n},
  title     = {A comprehensive introduction to label noise},
  booktitle = {22th European Symposium on Artificial Neural Networks, {ESANN} 2014, Bruges, Belgium, April 23-25, 2014},
  date      = {2014},
  url       = {http://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2014-10.pdf},
  file      = {:pdf-files/Frenay2014a - A Comprehensive Introduction to Label Noise.pdf:PDF},
  groups    = {Machine Learning, Issues},
  owner     = {flo},
  timestamp = {Tue, 29 Jul 2014 18:06:52 +0200},
}

@Article{Frenay2014,
  author       = {Beno{\^i}t Fr{\'e}nay and Michel Verleysen},
  title        = {{Classification in the Presence of Label Noise: A Survey}},
  journaltitle = {{IEEE} Transactions on Neural Networks and Learning Systems},
  date         = {2014},
  volume       = {25},
  number       = {5},
  pages        = {845--869},
  doi          = {10.1109/TNNLS.2013.2292894},
  file         = {:pdf-files/Frenay2014 - Classification in the Presence of Label Noise_ a Survey.pdf:PDF},
  groups       = {Machine Learning, Issues},
  owner        = {flo},
  timestamp    = {Fri, 25 Apr 2014 15:35:57 +0200},
}

@Article{Freund1997,
  author       = {Yoav Freund and Robert E Schapire},
  title        = {{A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting}},
  journal      = {Journal of Computer and System Sciences},
  journaltitle = {Journal of Computer and System Sciences},
  year         = {1997},
  date         = {1997},
  volume       = {55},
  number       = {1},
  pages        = {119--139},
  issn         = {0022-0000},
  doi          = {10.1006/jcss.1997.1504},
  acmid        = {261549},
  file         = {:pdf-files/Freund1997 - A Decision Theoretic Generalization of on Line Learning and an Application to Boosting.pdf:PDF},
  groups       = {Machine Learning, Boosting},
  issue_date   = {Aug. 1997},
  location     = {Orlando, FL, USA},
  numpages     = {21},
  owner        = {flo},
  publisher    = {Elsevier {BV}},
  timestamp    = {2016.02.09},
}

@InCollection{Frome2013,
  author    = {Frome, Andrea and Corrado, Greg S and Shlens, Jon and Bengio, Samy and Dean, Jeff and Ranzato, Marc\textquotesingle Aurelio and Mikolov, Tomas},
  booktitle = {Advances in Neural Information Processing Systems 26},
  date      = {2013},
  title     = {DeViSE: A Deep Visual-Semantic Embedding Model},
  editor    = {C. J. C. Burges and L. Bottou and M. Welling and Z. Ghahramani and K. Q. Weinberger},
  pages     = {2121--2129},
  publisher = {Curran Associates, Inc.},
  url       = {http://papers.nips.cc/paper/5204-devise-a-deep-visual-semantic-embedding-model.pdf},
  file      = {:pdf-files/Frome2013 - DeViSE_ a Deep Visual Semantic Embedding Model.pdf:PDF},
  groups    = {Image Caption Generation},
  owner     = {flo},
  timestamp = {2017.11.15},
}

@Article{Furber2014,
  author       = {Steve B. Furber and Francesco Galluppi and Steve Temple and Luis A. Plana},
  title        = {The {SpiNNaker} Project},
  journal      = {Proceedings of the {IEEE}},
  journaltitle = {Proceedings of the IEEE},
  year         = {2014},
  date         = {2014},
  volume       = {102},
  number       = {5},
  pages        = {652--665},
  issn         = {0018-9219},
  doi          = {10.1109/jproc.2014.2304638},
  file         = {:pdf-files/Furber2014 - The SpiNNaker Project.pdf:PDF},
  groups       = {Neuromorphic Hardware, SpiNNaker},
  keywords     = {multiprocessing systems;neural net architecture;parallel processing;real-time systems;SpiNNaker project;data packets;interconnect architecture;mammalian brain;parallel million-core computer;real-time event-driven programming model;spiking neural network architecture;Brain modeling;Computational modeling;Computer architecture;Multitasking;Neural networks;Neuroscience;Parallel programming;Program processors;Brain modeling;multicast algorithms;multiprocessor interconnection networks;neural network hardware;parallel programming},
  owner        = {flo},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  timestamp    = {2015.12.10},
}

@InProceedings{Furda2010,
  author    = {Furda, A. and Vlacic, L.},
  title     = {{An object-oriented design of a World Model for autonomous city vehicles}},
  booktitle = {Intelligent Vehicles Symposium (IV), 2010 IEEE},
  date      = {2010},
  pages     = {1054--1059},
  doi       = {10.1109/IVS.2010.5548138},
  file      = {:pdf-files/Furda2010 - An Object Oriented Design of a World Model for Autonomous City Vehicles.pdf:PDF},
  groups    = {Environment Model},
  issn      = {1931-0587},
  keywords  = {application program interfaces;decision making;object-oriented programming;traffic engineering computing;3D simulation;application programming interface;autonomous city vehicles;autonomous vehicle control system;decision making subsystem;object-oriented design;on-board sensors;road traffic environment;software component;software design patterns;Cities and towns;Communication system control;Communication system traffic control;Control system synthesis;Mobile robots;Object oriented modeling;Remotely operated vehicles;Road vehicles;Traffic control;Vehicle driving},
  owner     = {flo},
  timestamp = {2016.01.18},
}

@InProceedings{Furgale2013,
  author    = {Furgale, Paul and et al. and Schwesinger, Ulrich and Rufli, Martin and Pradalier, C{\'e}dric and Siegwart, Roland and K{\"o}ser, Kevin and H{\"a}ne, Christian and Heng, Lionel and Lee, Gim Hee and Fraundorfer, Friedrich and Pollefeys, Marc},
  title     = {{T}oward automated driving in cities using close-to-market sensors: {A}n overview of the {V}-{C}harge {P}roject},
  booktitle = {Proceedings of 2013 IEEE Intelligent Vehicles Symposium (IV)},
  date      = {2013},
  publisher = {IEEE},
  location  = {Piscataway, NJ},
  pages     = {809--816},
  file      = {:pdf-files/Furgale2013 - Toward Automated Driving in Cities Using Close to Market Sensors_ an Overview of the V Charge Project.pdf:PDF},
  groups    = {Autonomous Driving},
  owner     = {flo},
  timestamp = {2016.01.18},
}

@Article{Fuster2004,
  author       = {Joaquin M. Fuster},
  title        = {Upper processing stages of the perception-action cycle},
  journaltitle = {Trends in Cognitive Sciences},
  date         = {2004},
  volume       = {8},
  number       = {4},
  pages        = {143--145},
  issn         = {1364-6613},
  doi          = {10.1016/j.tics.2004.02.004},
  url          = {http://www.sciencedirect.com/science/article/pii/S1364661304000476},
  abstract     = {Abstract The neural substrate for behavioral, cognitive and linguistic actions is hierarchically organized in the cortex of the frontal lobe. In their methodologically impeccable study, Koechlin et al. reveal the neural dynamics of the frontal hierarchy in behavioral action. Progressively higher areas control the performance of actions requiring the integration of progressively more complex and temporally dispersed information. The study substantiates the crucial role of the prefrontal cortex in the temporal organization of behavior.},
  file         = {:pdf-files/Fuster2004 - Upper Processing Stages of the Perception Action Cycle.pdf:PDF},
  groups       = {Neuroscience},
  owner        = {flo},
  timestamp    = {2018.01.07},
}

@Article{Gallant2013,
  author       = {Gallant, Stephen I. and Okaywe, T. Wendy},
  title        = {Representing Objects, Relations, and Sequences},
  journaltitle = {Neural Computation},
  date         = {2013},
  volume       = {25},
  number       = {8},
  pages        = {2038--2078},
  issn         = {0899-7667},
  doi          = {10.1162/NECO_a_00467},
  acmid        = {2494253},
  file         = {:pdf-files/Gallant2013 - Representing Objects, Relations, and Sequences.pdf:PDF},
  groups       = {Vector Symbolic Architectures},
  issue_date   = {August 2013},
  location     = {Cambridge, MA, USA},
  numpages     = {41},
  owner        = {flo},
  publisher    = {MIT Press},
  timestamp    = {2017.11.15},
}

@Article{Gallego2015,
  author       = {Guillermo Gallego and Christian Forster and Elias Mueggler and Davide Scaramuzza},
  title        = {{Event-based Camera Pose Tracking using a Generative Event Model}},
  journaltitle = {Computing Research Repository (CoRR)},
  date         = {2015},
  url          = {http://arxiv.org/abs/1510.01972},
  bibsource    = {dblp computer science bibliography, http://dblp.org},
  biburl       = {http://dblp.uni-trier.de/rec/bib/journals/corr/GallegoFMS15},
  file         = {:pdf-files/Gallego2015 - Event Based Camera Pose Tracking Using a Generative Event Model.pdf:PDF},
  groups       = {Neuromorphic Vision},
  owner        = {flo},
  timestamp    = {Sun, 01 Nov 2015 17:30:45 +0100},
}

@InProceedings{Galluppi2012,
  author    = {Galluppi, Francesco and Davies, Sergio and Rast, Alexander and Sharp, Thomas and Plana, Luis A. and Furber, Steve},
  title     = {{A Hierachical Configuration System for a Massively Parallel Neural Hardware Platform}},
  booktitle = {Proceedings of the 9th Conference on Computing Frontiers},
  date      = {2012},
  series    = {CF '12},
  publisher = {ACM},
  location  = {Cagliari, Italy},
  isbn      = {978-1-4503-1215-8},
  pages     = {183--192},
  doi       = {10.1145/2212908.2212934},
  acmid     = {2212934},
  address   = {New York, NY, USA},
  file      = {:pdf-files/Galluppi2012 - A Hierachical Configuration System for a Massively Parallel Neural Hardware Platform.pdf:PDF},
  groups    = {Neuromorphic Hardware},
  keywords  = {neuromorphic hardware, parallel hardware, spiking neural networks, spinnaker},
  numpages  = {10},
  owner     = {flo},
  timestamp = {2015.12.15},
}

@InProceedings{Galluppi2014,
  author    = {Francesco Galluppi and Christian Denk and Matthias C. Meiner and Terrence C. Stewart and Luis A. Plana and Chris Eliasmith and Stephen B. Furber and J{\"o}rg Conradt},
  title     = {Event-based neural computing on an autonomous mobile platform},
  booktitle = {2014 {IEEE} International Conference on Robotics and Automation, {ICRA} 2014, Hong Kong, China, May 31 - June 7, 2014},
  date      = {2014},
  pages     = {2862--2867},
  doi       = {10.1109/ICRA.2014.6907270},
  file      = {:pdf-files/Galluppi2014 - Event Based Neural Computing on an Autonomous Mobile Platform.pdf:PDF},
  groups    = {Neuromorphic Robotics, Neuromorphic Hardware, SpiNNaker},
  owner     = {flo},
  timestamp = {2016.01.18},
}

@Article{Galluppi2015,
  author       = {Francesco Galluppi and Xavier Lagorce and Evangelos Stromatias and Michael Pfeiffer and Luis A. Plana and Steve B. Furber and Ryad B. Benosman},
  title        = {A framework for plasticity implementation on the {SpiNNaker} neural architecture},
  journal      = {Frontiers in Neuroscience},
  journaltitle = {Frontiers in Neuroscience},
  year         = {2015},
  date         = {2015},
  volume       = {8},
  number       = {429},
  issn         = {1662-453X},
  doi          = {10.3389/fnins.2014.00429},
  abstract     = {Many of the precise biological mechanisms of synaptic plasticity remain elusive, but simulations of neural networks have greatly enhanced our understanding of how specific global functions arise from the massively parallel computation of neurons and local Hebbian or spike-timing dependent plasticity rules. For simulating large portions of neural tissue, this has created an increasingly strong need for large scale simulations of plastic neural networks on special purpose hardware platforms, because synaptic transmissions and updates are badly matched to computing style supported by current architectures. Because of the great diversity of biological plasticity phenomena and the corresponding diversity of models, there is a great need for testing various hypotheses about plasticity before committing to one hardware implementation. Here we present a novel framework for investigating different plasticity approaches on the SpiNNaker distributed digital neural simulation platform. The key innovation of the proposed architecture is to exploit the reconfigurability of the ARM processors inside SpiNNaker, dedicating a subset of them exclusively to process synaptic plasticity updates, while the rest perform the usual neural and synaptic simulations. We demonstrate the flexibility of the proposed approach by showing the implementation of a variety of spike- and rate-based learning rules, including standard Spike-Timing dependent plasticity (STDP), voltage-dependent STDP, and the rate-based BCM rule. We analyze their performance and validate them by running classical learning experiments in real time on a 4-chip SpiNNaker board. The result is an efficient, modular, flexible and scalable framework, which provides a valuable tool for the fast and easy exploration of learning models of very different kinds on the parallel and reconfigurable SpiNNaker system.},
  file         = {:pdf-files/Galluppi2015 - A Framework for Plasticity Implementation on the SpiNNaker Neural Architecture.pdf:PDF},
  groups       = {SpiNNaker},
  owner        = {flo},
  publisher    = {Frontiers Media {SA}},
  timestamp    = {2016.03.10},
}

@InProceedings{Garca2016,
  author    = {Garibaldi Pineda Garcia and Patrick Camilleri and Qian Liu and Steve Furber},
  title     = {{pyDVS}: An extensible, real-time Dynamic Vision Sensor emulator using off-the-shelf hardware},
  booktitle = {2016 {IEEE} Symposium Series on Computational Intelligence ({SSCI})},
  year      = {2016},
  date      = {2016},
  publisher = {{IEEE}},
  doi       = {10.1109/ssci.2016.7850249},
  url       = {https://ieeexplore.ieee.org/document/7850249/},
  comment   = {Code available at https://github.com/chanokin/pyDVS},
  file      = {:pdf-files/Garca2016 - PyDVS_ an Extensible, Real Time Dynamic Vision Sensor Emulator Using off the Shelf Hardware.pdf:PDF},
  groups    = {Neuromorphic Vision},
  owner     = {flo},
  timestamp = {2017.02.03},
}

@InProceedings{Gayler1998,
  author               = {Gayler, Ross},
  title                = {{Multiplicative Binding, Representation Operators and Analogy}},
  booktitle            = {Advances in analogy research: Integration of theory and data from the cognitive, computational, and neural sciences},
  date                 = {1998},
  editor               = {D. Gentner, K. J. Holyoak, \& B. N. Kokinov},
  organization         = {Sofia, Bulgaria: New Bulgarian University.},
  pages                = {1--4},
  url                  = {http://cogprints.org/502},
  abstract             = {Analogical inference depends on systematic substitution of the components of compositional structures. Simple systematic substitution has been achieved in a number of connectionist systems that support binding (the ability to create connectionist representations of the combination of component representations). These systems have used various implementations of two generic composition operators: bind() and bundle(). This paper introduces a novel implementation of the bind() operator that is simple, can be efficiently implemented, and highlights the relationship between retrieval queries and analogical mapping. A frame of role/filler bindings can easily be represented using bind() and bundle(). However, typical binding systems are unable to adequately represent multiple frames and arbitrary nested compositional structures. A novel family of representational operators (called braid()) is introduced to address these problems. Other binding systems make the strong assumption that the roles and fillers are disjoint in order to avoid ambiguities inherent in their representational idioms. The braid() operator can be used to avoid this assumption. The new representational idiom suggests how the cognitive processes of bottom-up and top-down object recognition might be implemented. These processes depend on analogical mapping to integrate disjoint representations and drive perceptual search.},
  citeulike-article-id = {494457},
  citeulike-linkout-0  = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.24.1482},
  comment              = {Poster from 1998 Bulgarian conference},
  file                 = {:pdf-files/Gayler1998 - Multiplicative Binding, Representation Operators and Analogy.pdf:PDF},
  groups               = {Vector Symbolic Architectures},
  keywords             = {cogsci, vector\_symbolic\_architecture},
  owner                = {flo},
  posted-at            = {2006-02-06 22:38:21},
  timestamp            = {2017.06.30},
}

@Conference{Gayler2003,
  author       = {Ross Gayler},
  title        = {Vector {S}ymbolic {A}rchitectures answer {J}ackendoff's challenges for cognitive neuroscience},
  booktitle    = {ICCS/ASCS International Conference on Cognitive Science},
  date         = {2003},
  editor       = {Peter Slezak},
  organization = {University of New South Wales},
  publisher    = {CogPrints},
  pages        = {133--138},
  file         = {:pdf-files/Gayler2003 - Vector Symbolic Architectures Answer Jackendoff's Challenges for Cognitive Neuroscience.pdf:PDF},
  groups       = {Vector Symbolic Architectures},
  owner        = {flo},
  timestamp    = {2017.04.26},
}

@PhdThesis{Geiger2013,
  author      = {Geiger, Andreas},
  title       = {Probabilistic {M}odels for {3D} {U}rban {S}cene {U}nderstanding from {M}ovable {P}latforms},
  institution = {Karlsruhe Institute of Technology},
  date        = {2013},
  file        = {:pdf-files/Geiger2013 - Probabilistic Models for 3D Urban Scene Understanding from Movable Platforms.pdf:PDF},
  groups      = {Environment Model},
  owner       = {flo},
  school      = {Karlsruhe Institute of Technology},
  timestamp   = {2016.08.18},
}

@Article{Geiger2013a,
  author       = {A Geiger and P Lenz and C Stiller and R Urtasun},
  title        = {Vision meets robotics: The {KITTI} dataset},
  journal      = {The International Journal of Robotics Research},
  journaltitle = {The International Journal of Robotics Research},
  year         = {2013},
  date         = {2013},
  volume       = {32},
  number       = {11},
  pages        = {1231--1237},
  doi          = {10.1177/0278364913491297},
  eprint       = {https://doi.org/10.1177/0278364913491297},
  abstract     = {We present a novel dataset captured from a VW station wagon for use in mobile robotics and autonomous driving research. In total, we recorded 6 hours of traffic scenarios at 10-100 Hz using a variety of sensor modalities such as high-resolution color and grayscale stereo cameras, a Velodyne 3D laser scanner and a high-precision GPS/IMU inertial navigation system. The scenarios are diverse, capturing real-world traffic situations, and range from freeways over rural areas to inner-city scenes with many static and dynamic objects. Our data is calibrated, synchronized and timestamped, and we provide the rectified and raw image sequences. Our dataset also contains object labels in the form of 3D tracklets, and we provide online benchmarks for stereo, optical flow, object detection and other tasks. This paper describes our recording platform, the data format and the utilities that we provide.},
  file         = {:pdf-files/Geiger2013IJRR - Vision Meets Robotics_ the KITTI Dataset.pdf:PDF},
  groups       = {Datasets},
  owner        = {flo},
  publisher    = {{SAGE} Publications},
  timestamp    = {2016.07.14},
}

@Article{Georgopoulos1989,
  author       = {A. Georgopoulos and J. Lurito and M Petrides and A. Schwartz and J. Massey},
  title        = {Mental rotation of the neuronal population vector},
  journal      = {Science},
  journaltitle = {Science},
  year         = {1989},
  date         = {1989},
  volume       = {243},
  number       = {4888},
  pages        = {234--236},
  issn         = {0036-8075},
  doi          = {10.1126/science.2911737},
  eprint       = {http://science.sciencemag.org/content/243/4888/234.full.pdf},
  url          = {http://science.sciencemag.org/content/243/4888/234},
  abstract     = {A rhesus monkey was trained to move its arm in a direction that was perpendicular to and counterclockwise from the direction of a target light that changed in position from trial to trial. Solution of this problem was hypothesized to involve the creation and mental rotation of an imagined movement vector from the direction of the light to the direction of the movement. This hypothesis was tested directly by recording the activity of cells in the motor cortex during performance of the task and computing the neuronal population vector in successive time intervals during the reaction time. The population vector rotated gradually counterclockwise from the direction of the light to the direction of the movement at an average rate of 732 degrees per second. These results provide direct, neural evidence for the mental rotation hypothesis and indicate that the neuronal population vector is a useful tool for "reading out" and identifying cognitive operations of neuronal ensembles.},
  file         = {:pdf-files/Georgopoulos1989 - Mental Rotation of the Neuronal Population Vector.pdf:PDF},
  groups       = {Neuroscience},
  owner        = {flo},
  publisher    = {American Association for the Advancement of Science ({AAAS})},
  timestamp    = {2018.04.05},
}

@Book{Gerstner2002,
  author    = {Gerstner, Wulfram and Kistler, Werner},
  title     = {Spiking Neuron Models: An Introduction},
  date      = {2002},
  publisher = {Cambridge University Press},
  location  = {New York, NY, USA},
  isbn      = {0521890799},
  file      = {:pdf-files/Gerstner2002 - Spiking Neuron Models_ an Introduction.pdf:PDF},
  groups    = {Neural Modelling, Spiking Neural Networks},
  owner     = {flo},
  timestamp = {2016.02.09},
}

@Book{Gerstner2014,
  author    = {Wulfram Gerstner and Werner Kistler and Richard Naud and Liam Paninski},
  title     = {Neuronal {D}ynamics - {F}rom single neurons to networks and models of cognition},
  date      = {2014},
  publisher = {Cambridge University Press},
  url       = {http://neuronaldynamics.epfl.ch/online/index.html},
  abstract  = {What happens in our brain when we make a decision? What triggers a neuron to send out a signal? What is the neural code? This textbook for advanced undergraduate and beginning graduate students provides a thorough and up-to-date introduction to the fields of computational and theoretical neuroscience. It covers classical topics, including the Hodgkin-Huxley equations and Hopfield model, as well as modern developments in the field such as Generalized Linear Models and decision theory. Concepts are introduced using clear step-by-step explanations suitable for readers with only a basic knowledge of differential equations and probabilities, and are richly illustrated by figures and worked-out examples. End-of-chapter summaries and classroom-tested exercises make the book ideal for courses or for self-study. The authors also give pointers to the literature and an extensive bibliography, which will prove invaluable to readers interested in further study.},
  groups    = {Neural Modelling},
  owner     = {flo},
  timestamp = {2016.04.13},
}

@Article{Gewaltig2007,
  author       = {Gewaltig, Marc-Oliver and Diesmann, Markus},
  title        = {{NEST} ({NEural} {Simulation} {Tool)}},
  journaltitle = {Scholarpedia},
  date         = {2007},
  volume       = {2},
  number       = {4},
  pages        = {1430},
  doi          = {10.4249/scholarpedia.1430},
  url          = {http://www.scholarpedia.org/article/NEST_(NEural_Simulation_Tool)},
  groups       = {Neural Modelling, Simulators},
  keywords     = {simulation},
  owner        = {flo},
  timestamp    = {2016.02.18},
}

@Book{Gibson1966,
  author    = {Gibson, J.J.},
  title     = {The senses considered as perceptual systems},
  date      = {1966},
  publisher = {Houghton Mifflin},
  url       = {https://books.google.de/books?id=J9ROAAAAMAAJ},
  comment   = {Definition of affordance},
  groups    = {Neuroscience},
  lccn      = {66007132},
  owner     = {flo},
  timestamp = {2017.11.22},
}

@Article{Goodman2009,
  author       = {Goodman, Dan F M and Brette, Romain},
  title        = {{The Brian simulator}},
  journal      = {Frontiers in Neuroscience},
  journaltitle = {Frontiers in Neuroscience},
  year         = {2009},
  date         = {2009},
  volume       = {3},
  number       = {26},
  pages        = {192--197},
  issn         = {1662-453X},
  doi          = {10.3389/neuro.01.026.2009},
  abstract     = {"Brian" is a simulator for spiking neural networks (http://www.briansimulator.org). The focus is on making the writing of simulation code as quick and easy as possible for the user, and on flexibility: new and non-standard models are no more difficult to define than standard ones. This allows scientists to spend more time on the details of their models, and less on their implementation. Neuron models are defined by writing differential equations in standard mathematical notation, facilitating scientific communication. Brian is written in the Python programming language, and uses vector-based computation to allow for efficient simulations. It is particularly useful for neuroscientific modelling at the systems level, and for teaching computational neuroscience.},
  file         = {:pdf-files/Goodman2009 - The Brian Simulator.pdf:PDF},
  groups       = {Neural Modelling, Simulators},
  owner        = {flo},
  publisher    = {Frontiers Media {SA}},
  timestamp    = {2016.02.18},
}

@Article{Goodman2008,
  author       = {Goodman, N. D. and Tenenbaum, J. B. and Feldman, J. and Griffiths, T. L.},
  title        = {{{A} rational analysis of rule-based concept learning}},
  journaltitle = {Cognitive Science},
  date         = {2008},
  volume       = {32},
  number       = {1},
  pages        = {108--154},
  file         = {:pdf-files/Goodman2008 - A Rational Analysis of Rule Based Concept Learning.pdf:PDF},
  groups       = {Neuroscience},
  owner        = {flo},
  timestamp    = {2017.04.26},
}

@InProceedings{Gruening2014,
  author    = {Andr{\'e} Gr{\"u}ning and Sander M. Bohte},
  title     = {{S}piking {N}eural {N}etworks: {P}rinciples and {C}hallenges},
  booktitle = {Proceeding of European Symposium on {N}eural {N}etworks ({E}{S}{A}{N}{N} 2014)},
  date      = {2014},
  volume    = {22},
  pages     = {1--10},
  file      = {:pdf-files/Gruening2014 - Spiking Neural Networks_ Principles and Challenges.pdf:PDF},
  groups    = {Spiking Neural Networks},
  owner     = {flo},
  timestamp = {2016.01.18},
}

@InProceedings{Graf2014,
  author    = {R. Graf and H. Deusch and F. Seeliger and M. Fritzsche and K. Dietmayer},
  title     = {A {L}earning {C}oncept for {B}ehavior {P}rediction at {I}ntersections},
  booktitle = {2014 IEEE Intelligent Vehicles Symposium Proceedings},
  date      = {2014},
  pages     = {939--945},
  doi       = {10.1109/IVS.2014.6856415},
  abstract  = {The idea presented in this paper is an online learning approach for behavior prediction of other road participants at an intersection. Learning traffic situations online has the advantage that it is possible to react to changes in driving behavior due to changes in the environment. If visual obstruction occurs because of changes in the environment, e.g. a growing corn field, the behavior of drivers changes. In contrast to pre-trained models an online learning concept is able to react to these changes in driving behavior. In this contribution Case-Based Reasoning, a concept which adapts human reasoning and thinking to a system, is used. The functionality of the concept is shown by predicting the maneuver of an approaching vehicle at an intersection. The presented concept is able to predict if a vehicle turns in front of the ego-vehicle or stops and give the ego-vehicle right of way.},
  file      = {:pdf-files/Graf2014 - A Learning Concept for Behavior Prediction at Intersections.pdf:PDF},
  groups    = {Behaviour analysis},
  issn      = {1931-0587},
  keywords  = {human factors;learning (artificial intelligence);predictive control;traffic control;behavior prediction;case-based reasoning;ego-vehicle;human reasoning;intersections;online learning approach;online learning concept;pre-trained models;traffic situation online learning;Cognition;Context;Feature extraction;Market research;Roads;Vehicles;Visualization},
  owner     = {flo},
  timestamp = {2017.09.20},
}

@Article{Graves2016,
  author       = {Graves, Alex and Wayne, Greg and Reynolds, Malcolm and Harley, Tim and Danihelka, Ivo and Grabska-Barwi{\'n}ska, Agnieszka and Colmenarejo, Sergio G{\'o}mez and Grefenstette, Edward and Ramalho, Tiago and Agapiou, John and Badia, Adri{\`a} Puigdom{\`e}nech and Hermann, Karl Moritz and Zwols, Yori and Ostrovski, Georg and Cain, Adam and King, Helen and Summerfield, Christopher and Blunsom, Phil and Kavukcuoglu, Koray and Hassabis, Demis},
  title        = {Hybrid computing using a neural network with dynamic external memory},
  journaltitle = {Nature},
  date         = {2016},
  volume       = {advance online publication},
  pages        = {471--476},
  issn         = {1476-4687},
  doi          = {10.1038/nature20101},
  abstract     = {Artificial neural networks are remarkably adept at sensory processing, sequence learning and reinforcement learning, but are limited in their ability to represent variables and data structures and to store data over long timescales, owing to the lack of an external memory. Here we introduce a machine learning model called a differentiable neural computer (DNC), which consists of a neural network that can read from and write to an external memory matrix, analogous to the random-access memory in a conventional computer. Like a conventional computer, it can use its memory to represent and manipulate complex data structures, but, like a neural network, it can learn to do so from data. When trained with supervised learning, we demonstrate that a DNC can successfully answer synthetic questions designed to emulate reasoning and inference problems in natural language. We show that it can learn tasks such as finding the shortest path between specified points and inferring the missing links in randomly generated graphs, and then generalize these tasks to specific graphs such as transport networks and family trees. When trained with reinforcement learning, a DNC can complete a moving blocks puzzle in which changing goals are specified by sequences of symbols. Taken together, our results demonstrate that DNCs have the capacity to solve complex, structured tasks that are inaccessible to neural networks without external read-write memory.},
  comment      = {combination of neural network with external memory cognitive tasks. competition for spaun?},
  file         = {:pdf-files/Graves2016 - Hybrid Computing Using a Neural Network with Dynamic External Memory.pdf:PDF},
  groups       = {Deep Neural Networks},
  owner        = {flo},
  publisher    = {Macmillan Publishers Limited, part of Springer Nature. All rights reserved.},
  timestamp    = {2016.10.19},
}

@Article{Grillner2016,
  author       = {Sten Grillner and Nancy Ip and Christof Koch and Walter Koroshetz and Hideyuki Okano and Miri Polachek and Mu-ming Poo and Terrence J Sejnowski},
  title        = {Worldwide initiatives to advance brain research},
  journal      = {Nature Neuroscience},
  journaltitle = {Nature Neuroscience},
  year         = {2016},
  date         = {2016},
  volume       = {19},
  number       = {9},
  pages        = {1118--1122},
  issn         = {1097-6256},
  doi          = {10.1038/nn.4371},
  abstract     = {To highlight worldwide efforts to fund neuroscience research and address the growing threat of brain disorders, Nature Neuroscience asked leaders of six global brain initiatives to write about their programs.},
  file         = {:pdf-files/Grillner2016 - Worldwide Initiatives to Advance Brain Research.pdf:PDF},
  groups       = {Projects},
  owner        = {flo},
  publisher    = {Springer Nature},
  timestamp    = {2016.09.21},
}

@Article{Gu2016,
  author       = {Shixiang Gu and Timothy P. Lillicrap and Ilya Sutskever and Sergey Levine},
  title        = {Continuous {D}eep {Q}-Learning with {M}odel-based {A}cceleration},
  journaltitle = {Computing Research Repository (CoRR)},
  date         = {2016},
  volume       = {abs/1603.00748},
  url          = {http://arxiv.org/abs/1603.00748},
  file         = {:pdf-files/Gu2016 - Continuous Deep Q Learning with Model Based Acceleration.pdf:PDF},
  groups       = {ReinforcementLearning, Neural Networks, Deep Neural Networks},
  owner        = {flo},
  timestamp    = {2016.10.12},
}

@Article{Guizzo2015,
  author       = {E. Guizzo and E. Ackerman},
  title        = {The hard lessons of DARPA's robotics challenge [News]},
  journaltitle = {IEEE Spectrum},
  date         = {2015},
  volume       = {52},
  number       = {8},
  pages        = {11--13},
  issn         = {0018-9235},
  doi          = {10.1109/MSPEC.2015.7164385},
  abstract     = {In what must be the biggest public display of robot adoration and empathy ever witnessed, thousands cheered as the team from the Korea Advanced Institute of Science and Technology (KAIST) won the DARPA Robotics Challenge (DRC) in Pomona, Calif., on 6 June. Its robot, an adaptable humanoid called DRC-Hubo, beat out 22 other bots from six countries in a two-day competition organized with the aim of advancing the field of disaster robotics. The team from KAIST, which is in Daejeon, South Korea, walked away from the competition with the US $2 million grand prize.},
  file         = {:pdf-files/Guizzo2015 - The Hard Lessons of DARPA's Robotics Challenge [News].pdf:PDF},
  groups       = {Robotics},
  owner        = {flo},
  timestamp    = {2018.01.20},
}

@Article{Gupta2014,
  author       = {Gupta, Nitin and Stopfer, Mark},
  title        = {A temporal channel for information in sparse sensory coding},
  journaltitle = {Current biology},
  date         = {2014},
  volume       = {24},
  number       = {19},
  pages        = {2247--2256},
  issn         = {1879-0445},
  url          = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4189991/},
  abstract     = {BACKGROUND: Sparse codes are found in nearly every sensory system, but the role of spike timing in sparse sensory coding is unclear. Here we used the olfactory system of awake locusts to test whether the timing of spikes in Kenyon cells, a population of neurons that responds sparsely to odors, carries sensory information to, and influences the responses of, follower neurons. RESULTS: We characterized two major classes of direct followers of Kenyon cells. With paired intracellular and field potential recordings made during odor presentations, we found these followers contain information about odor identity in the temporal patterns of their spikes, rather than in the spike rate, the spike phase or the identities of the responsive neurons. Subtly manipulating the relative timing of Kenyon cell spikes with temporally and spatially structured microstimulation reliably altered the response patterns of the followers. CONCLUSIONS: Our results show that even remarkably sparse spiking responses can provide information through stimulus-specific variations in timing on the order of tens to hundreds of milliseconds, and that these variations can determine the responses of downstream neurons. These results establish the importance of spike timing in a sparse sensory code.},
  file         = {:pdf-files/Gupta2014 - A Temporal Channel for Information in Sparse Sensory Coding.pdf:PDF},
  groups       = {Biology},
  owner        = {flo},
  timestamp    = {2016.04.21},
}

@Article{Gutig2006,
  author       = {G{\"u}tig, Robert and Sompolinsky, Haim},
  title        = {The tempotron: a neuron that learns spike timing-based decisions},
  journaltitle = {Nature Neuroscience},
  date         = {2006},
  volume       = {9},
  number       = {3},
  pages        = {420--428},
  issn         = {1097-6256},
  doi          = {10.1038/nn1643},
  abstract     = {The timing of action potentials in sensory neurons contains substantial information about the eliciting stimuli. Although the computational advantages of spike timing-based neuronal codes have long been recognized, it is unclear whether, and if so how, neurons can learn to read out such representations. We propose a new, biologically plausible supervised synaptic learning rule that enables neurons to efficiently learn a broad range of decision rules, even when information is embedded in the spatiotemporal structure of spike patterns rather than in mean firing rates. The number of categorizations of random spatiotemporal patterns that a neuron can implement is several times larger than the number of its synapses. The underlying nonlinear temporal computation allows neurons to access information beyond single-neuron statistics and to discriminate between inputs on the basis of multineuronal spike statistics. Our work demonstrates the high capacity of neural systems to learn to decode information embedded in distributed patterns of spike synchrony.},
  comment      = {10.1038/nn1643},
  file         = {:pdf-files/Guetig_The_tempotron_a_neuron_that_learns_spike_timing-based_decisions.pdf:PDF},
  groups       = {Spiking Neural Networks},
  owner        = {flo},
  publisher    = {Nature Publishing Group},
  timestamp    = {2016.08.10},
}

@Article{Habenschuss2013,
  author       = {Habenschuss, Stefan and Jonke, Zeno and Maass, Wolfgang},
  title        = {Stochastic computations in cortical microcircuit models},
  journaltitle = {PLoS computational biology},
  date         = {2013},
  volume       = {9},
  number       = {11},
  pages        = {1--28},
  doi          = {10.1371/journal.pcbi.1003311},
  abstract     = {The brain has not only the capability to process sensory input, but it can also produce predictions, imaginations, and solve problems that combine learned knowledge with information about a new scenario. But although these more complex information processing capabilities lie at the heart of human intelligence, we still do not know how they are organized and implemented in the brain. Numerous studies in cognitive science and neuroscience conclude that many of these processes involve probabilistic inference. This suggests that neuronal circuits in the brain process information in the form of probability distributions, but we are missing insight into how complex distributions could be represented and stored in large and diverse networks of neurons in the brain. We prove in this article that realistic cortical microcircuit models can store complex probabilistic knowledge by embodying probability distributions in their inherent stochastic dynamics - yielding a knowledge representation in which typical probabilistic inference problems such as marginalization become straightforward readout tasks. We show that in cortical microcircuit models such computations can be performed satisfactorily within a few. Furthermore, we demonstrate how internally stored distributions can be programmed in a simple manner to endow a neural circuit with powerful problem solving capabilities.},
  added-at     = {2014-09-10T16:04:51.000+0200},
  description  = {v},
  file         = {:pdf-files/Habenschuss2013 - Stochastic Computations in Cortical Microcircuit Models.pdf:PDF},
  groups       = {public, Biology},
  interhash    = {1e49749f00cc6db79d9ea84bd6eff8dd},
  intrahash    = {50e1395092985251e9dc00f096685476},
  keywords     = {NeuralSampling},
  owner        = {flo},
  publisher    = {Public Library of Science},
  timestamp    = {2014-09-23T11:52:35.000+0200},
  username     = {kappeld},
}

@Article{Hafting2005,
  author       = {Hafting, Torkel and Fyhn, Marianne and Molden, Sturla and Moser, May-Britt and Moser, Edvard I.},
  title        = {Microstructure of a spatial map in the entorhinal cortex},
  journaltitle = {Nature},
  date         = {2005},
  volume       = {436},
  number       = {7052},
  pages        = {801--806},
  issn         = {0028-0836},
  doi          = {10.1038/nature03721},
  abstract     = {The ability to find one's way depends on neural algorithms that integrate information about place, distance and direction, but the implementation of these operations in cortical microcircuits is poorly understood. Here we show that the dorsocaudal medial entorhinal cortex (dMEC) contains a directionally oriented, topographically organized neural map of the spatial environment. Its key unit is the 'grid cell', which is activated whenever the animal's position coincides with any vertex of a regular grid of equilateral triangles spanning the surface of the environment. Grids of neighbouring cells share a common orientation and spacing, but their vertex locations (their phases) differ. The spacing and size of individual fields increase from dorsal to ventral dMEC. The map is anchored to external landmarks, but persists in their absence, suggesting that grid cells may be part of a generalized, path-integration-based map of the spatial environment.},
  comment      = {10.1038/nature03721},
  file         = {:pdf-files/Hafting2005 - Microstructure of a Spatial Map in the Entorhinal Cortex.pdf:PDF},
  groups       = {Biology},
  owner        = {flo},
  timestamp    = {2016.04.06},
}

@Article{Handjaras2016,
  author       = {Giacomo Handjaras and Emiliano Ricciardi and Andrea Leo and Alessandro Lenci and Luca Cecchetti and Mirco Cosottini and Giovanna Marotta and Pietro Pietrini},
  title        = {How concepts are encoded in the human brain: {A} modality independent, category-based cortical organization of semantic knowledge},
  journaltitle = {NeuroImage},
  date         = {2016},
  volume       = {135},
  pages        = {232--242},
  issn         = {1053-8119},
  doi          = {10.1016/j.neuroimage.2016.04.063},
  url          = {http://www.sciencedirect.com/science/article/pii/S1053811916301021},
  abstract     = {Abstract How conceptual knowledge is represented in the human brain remains to be determined. To address the differential role of low-level sensory-based and high-level abstract features in semantic processing, we combined behavioral studies of linguistic production and brain activity measures by functional magnetic resonance imaging in sighted and congenitally blind individuals while they performed a property-generation task with concrete nouns from eight categories, presented through visual and/or auditory modalities. Patterns of neural activity within a large semantic cortical network that comprised parahippocampal, lateral occipital, temporo-parieto-occipital and inferior parietal cortices correlated with linguistic production and were independent both from the modality of stimulus presentation (either visual or auditory) and the (lack of) visual experience. In contrast, selected modality-dependent differences were observed only when the analysis was limited to the individual regions within the semantic cortical network. We conclude that conceptual knowledge in the human brain relies on a distributed, modality-independent cortical representation that integrates the partial category and modality specific information retained at a regional level.},
  file         = {:pdf-files/Handjaras2016 - How Concepts Are Encoded in the Human Brain_ a Modality Independent, Category Based Cortical Organization of Semantic Knowledge.pdf:PDF},
  groups       = {Neuroscience},
  keywords     = {Semantic knowledge, Blindness, Supramodality, Category-based organization, fMRI, Multivoxel pattern analysis},
  owner        = {flo},
  timestamp    = {2018.01.12},
}

@Article{Hasler2013,
  author       = {Hasler, Jennifer and Marr, Bo},
  title        = {Finding a roadmap to achieve large neuromorphic hardware systems},
  journaltitle = {Frontiers in neuroscience},
  date         = {2013},
  volume       = {7},
  file         = {:pdf-files/Hasler2013 - Finding a Roadmap to Achieve Large Neuromorphic Hardware Systems.pdf:PDF},
  groups       = {Neuromorphic Computing, Neuromorphic Hardware},
  owner        = {flo},
  publisher    = {Frontiers Media SA},
  timestamp    = {2016.01.26},
}

@InProceedings{Hauptmann1996,
  author    = {W. Hauptmann and F. Graf and K. Heesche},
  title     = {Driving environment recognition for adaptive automotive systems},
  booktitle = {Proceedings of IEEE 5th International Fuzzy Systems},
  date      = {1996},
  volume    = {1},
  pages     = {387--393},
  doi       = {10.1109/FUZZY.1996.551772},
  abstract  = {With the rapid development of electronics and the growing demand for higher performance with respect to safety, driveability, fuel efficiency, and emissions, modern automotive systems are required to perform increasingly sophisticated tasks. To meet these challenges single type controls for each subsystem will tend to be integrated by an overall intelligent control system which is able to perceive the present situation and adjust adaptive vehicular components accordingly. To take a crucial step towards intelligent automotive systems the problem of environment recognition is addressed and a neuro-fuzzy approach for the identification of the driving situation based on available sensor information is introduced. It uses fuzzy logic for the classification task, generated and optimized by means of a neural network, and allows the bidirectional conversion between the fuzzy and neural domain. The proposed method leads to superior classification results and reduced development time compared to "manual" system design},
  file      = {:pdf-files/Hauptmann1996 - Driving Environment Recognition for Adaptive Automotive Systems.pdf:PDF},
  groups    = {Situation/Context analysis},
  keywords  = {automotive electronics;adaptive automotive systems;automobiles;driving environment recognition;fuzzy logic;fuzzy neural networks;intelligent control;neural networks;pattern classification;sensor fusion;Adaptive control;Adaptive systems;Automotive engineering;Control systems;Fuels;Fuzzy logic;Intelligent control;Intelligent sensors;Programmable control;Safety},
  owner     = {flo},
  timestamp = {2017.11.15},
}

@Book{Haykin2007,
  author    = {Haykin, Simon},
  title     = {{Neural Networks: A Comprehensive Foundation (3rd Edition)}},
  date      = {2007},
  publisher = {Prentice-Hall, Inc.},
  location  = {Upper Saddle River, NJ, USA},
  isbn      = {0131471392},
  file      = {:pdf-files/Haykin2007 - Neural Networks_ a Comprehensive Foundation (3rd Edition).pdf:PDF},
  groups    = {Neural Networks},
  owner     = {flo},
  timestamp = {2016.01.18},
}

@Book{Hebb1949,
  author    = {Hebb, Donald O.},
  title     = {{The Organization of Behavior}},
  date      = {1949},
  publisher = {John Wiley},
  comment   = {Original Reference for Hebbian Learning},
  groups    = {Biology, STDP},
  owner     = {flo},
  timestamp = {2016.03.10},
}

@InProceedings{Held2012,
  author    = {David Held and Jesse Levinson and Sebastian Thrun},
  title     = {A probabilistic framework for car detection in images using context and scale},
  booktitle = {{IEEE} International Conference on Robotics and Automation, {ICRA} 2012, 14-18 May, 2012, St. Paul, Minnesota, {USA}},
  date      = {2012},
  pages     = {1628--1634},
  doi       = {10.1109/ICRA.2012.6224722},
  file      = {:pdf-files/Held2012 - A Probabilistic Framework for Car Detection in Images Using Context and Scale.pdf:PDF},
  groups    = {Object Recognition},
  owner     = {flo},
  timestamp = {2016.01.18},
}

@InCollection{Hennequin2014,
  author    = {Hennequin, Guillaume and Aitchison, Laurence and Lengyel, Mate},
  title     = {{Fast Sampling-Based Inference in Balanced Neuronal Networks}},
  booktitle = {Advances in Neural Information Processing Systems 27},
  date      = {2014},
  editor    = {Z. Ghahramani and M. Welling and C. Cortes and N.D. Lawrence and K.Q. Weinberger},
  publisher = {Curran Associates, Inc.},
  pages     = {2240--2248},
  url       = {http://papers.nips.cc/paper/5265-fast-sampling-based-inference-in-balanced-neuronal-networks.pdf},
  file      = {:pdf-files/Hennequin2014 - Fast Sampling Based Inference in Balanced Neuronal Networks.pdf:PDF},
  groups    = {Bayesian Inference with Spiking Neurons},
  owner     = {flo},
  timestamp = {2016.02.09},
}

@Article{Hennequin2014a,
  author       = {Hennequin, Guillaume and Aitchison, Laurence and Lengyel, M{\'a}t{\'e}},
  title        = {Fast sampling for Bayesian inference in neural circuits},
  journaltitle = {ArXiv e-prints},
  date         = {2014},
  file         = {:pdf-files/Hennequin2014a - Fast Sampling for Bayesian Inference in Neural Circuits.pdf:PDF},
  groups       = {Bayesian Inference with Spiking Neurons},
  owner        = {flo},
  timestamp    = {2016.02.09},
}

@InProceedings{Hermann2008,
  author    = {Hermann, A. and Desel, J.},
  title     = {Driving situation analysis in automotive environment},
  booktitle = {IEEE International Conference on Vehicular Electronics and Safety (ICVES)},
  date      = {2008},
  pages     = {216--221},
  doi       = {10.1109/ICVES.2008.4640860},
  file      = {:pdf-files/Hermann2008 - Driving Situation Analysis in Automotive Environment.pdf:PDF},
  groups    = {Environment Model, Situation/Context analysis},
  keywords  = {automobiles;road traffic;sensors;automotive environment;driving situation analysis;ego vehicle;in-car sensors;Automotive applications;Automotive engineering;Computer science;Safety;Traffic control;USA Councils;Uncertainty;Vehicle detection;Vehicle driving;Vehicular and wireless technologies},
  owner     = {flo},
  timestamp = {2015.12.16},
}

@InProceedings{Hermann2007,
  author    = {A. Hermann and S. Lutz},
  title     = {Situation based {D}ata {D}istribution in a {D}istributed {E}nvironment {M}odel},
  booktitle = {2007 IEEE Intelligent Vehicles Symposium},
  date      = {2007},
  pages     = {486--491},
  doi       = {10.1109/IVS.2007.4290162},
  abstract  = {For advanced driver assistance systems (ADASs) knowledge of the environment plays a fundamental role. This also includes real-time data distribution and information about the current driving situation. A flexible situation model and a uniform situation analysis method are proposed to enable situation dependent information distribution, interpretation and fusion. This is a novel approach in the scope of automotive software. Waning from the proposed situation analysis an event-based programming model and a situation dependent data distribution is introduced. The introduction of driving situations to optimize data distribution and interpretation enables the ADAS developer to focus on their key algorithms. The proposed framework provides the distribution of the data and the situation analysis.},
  file      = {:pdf-files/Hermann2007 - Situation Based Data Distribution in a Distributed Environment Model.pdf:PDF},
  groups    = {Environment Model},
  issn      = {1931-0587},
  keywords  = {distributed processing;driver information systems;object-oriented programming;sensor fusion;ADAS developer;advanced driver assistance systems;automotive software;distributed environment model;event-based programming model;flexible situation model;information fusion;information interpretation;real-time data distribution;situation based data distribution;situation dependent information distribution;uniform situation analysis method;Actuators;Automotive engineering;Hardware;Information analysis;Intelligent vehicles;Object oriented modeling;Safety;Samarium;Vehicle detection;Vehicle driving},
  owner     = {flo},
  timestamp = {2017.11.15},
}

@Misc{OralPresentationAdvice,
  author    = {Mark D. Hill},
  title     = {Oral {P}resentation {A}dvice},
  date      = {1997},
  url       = {http://pages.cs.wisc.edu/~markhill/conference-talk.html},
  groups    = {Non-Technical},
  owner     = {flo},
  timestamp = {2016.10.14},
}

@Article{Hodgkin1952,
  author       = {Hodgkin, A.L. and Huxley, A.F.},
  title        = {A quantitative description of membrane current and its application to conduction and excitation in nerve},
  journaltitle = {Journal of Physiology},
  date         = {1952},
  volume       = {117},
  pages        = {500--544},
  file         = {:pdf-files/Hodgkin1952 - A Quantitative Description of Membrane Current and Its Application to Conduction and Excitation in Nerve.pdf:PDF},
  groups       = {Biology, Spiking Neural Networks},
  owner        = {flo},
}

@Article{Hornung2013,
  author       = {Armin Hornung and Kai M. Wurm and Maren Bennewitz and Cyrill Stachniss and Wolfram Burgard},
  title        = {{OctoMap}: {A}n {E}fficient {P}robabilistic {3D} {M}apping {F}ramework {B}ased on {O}ctrees},
  journaltitle = {Autonomous Robots},
  date         = {2013},
  note         = {Software available at http://octomap.github.com},
  doi          = {10.1007/s10514-012-9321-0},
  url          = {http://octomap.github.com},
  file         = {:pdf-files/Hornung2013 - OctoMap_ an Efficient Probabilistic 3D Mapping Framework Based on Octrees.pdf:PDF},
  groups       = {Robotics},
  owner        = {flo},
  timestamp    = {2016.01.28},
}

@InProceedings{Hsu2005,
  author    = {Chung-Hsing Hsu and Wu-chun Feng and J.S. Archuleta},
  title     = {Towards Efficient Supercomputing: A Quest for the Right Metric},
  booktitle = {19th {IEEE} International Parallel and Distributed Processing Symposium},
  date      = {2005},
  publisher = {{IEEE}},
  doi       = {10.1109/ipdps.2005.440},
  abstract  = {Over the past decade, we have been building less and less efficient supercomputers, resulting in the construction of substantially larger machine rooms and even new buildings. In addition, because of the thermal power envelope of these supercomputers, a small fortune must be spent to cool them. These infrastructure costs coupled with the additional costs of administering and maintaining such (unreliable) supercomputers dramatically increases their total cost of ownership. As a result, there has been substantial interest in recent years to produce more reliable and more efficient supercomputers that are easy to maintain and use. But how does one quantify efficient supercomputing? That is, what metric should be used to evaluate how efficiently a supercomputer delivers answers? We argue that existing efficiency metrics such as the performance-power ratio are insufficient and motivate the need for a new type of efficiency metric, one that incorporates notions of reliability, availability, productivity, and total cost of ownership (TCO), for instance. In doing so, however, this paper raises more questions than it answers with respect to efficiency. And in the end, we still return to the performance-power ratio as an efficiency metric with respect to power and use it to evaluate a menagerie of processor platforms in order to provide a set of reference data points for the high-performance computing community.},
  file      = {:pdf-files/Hsu2005 - Towards Efficient Supercomputing_ a Quest for the Right Metric.pdf:PDF},
  groups    = {Computing and GPU},
  keywords  = {computer maintenance;parallel machines;performance evaluation;power consumption;high-performance computing;performance-power ratio;supercomputer maintenance;supercomputing;thermal power envelope;Availability;Buildings;Cooling;Costs;Energy consumption;High performance computing;Laboratories;Maintenance;Productivity;Supercomputers},
  owner     = {flo},
  timestamp = {2016.01.18},
}

@Book{Hsu2002,
  author    = {Hsu, Feng-Hsiung},
  title     = {Behind Deep Blue: Building the Computer That Defeated the World Chess Champion},
  date      = {2002},
  publisher = {Princeton University Press},
  location  = {Princeton, NJ, USA},
  isbn      = {0691090653},
  abstract  = {On May 11, 1997, as millions worldwide watched a stunning victory unfold on television, a machine shocked the chess world by defeating the defending world champion, Garry Kasparov. Written by the man who started the adventure, Behind Deep Blue reveals the inside story of what happened behind the scenes at the two historic Deep Blue vs. Kasparov matches. This is also the story behind the quest to create the mother of all chess machines. The book unveils how a modest student project eventually produced a multimillion dollar supercomputer, from the development of the scientific ideas through technical setbacks, rivalry in the race to develop the ultimate chess machine, and wild controversies to the final triumph over the world's greatest human player. In nontechnical, conversational prose, Fenghsiung Hsu, the system architect of Deep Blue, tells us how he and a small team of fellow researchers forged ahead at IBM with a project they'd begun as students at Carnegie Mellon in the mid-1980s: the search for one of the oldest holy grails in artificial intelligence -- a machine that could beat any human chess player in a bona fide match. Back in 1949 science had conceived the foundations of modern chess computers but not until almost fifty years later -- until Deep Blue -- would the quest be realized. Hsu refutes Kasparov's controversial claim that only human intervention could have allowed Deep Blue to make its decisive, "uncomputerlike" moves. In riveting detail he describes the heighteing tension in this war of brains and nerves, the "smoldering fire" in Kasparov's eyes. Behind Deep Blue is not just another tale of man versus machine. This fascinating book tells us how man as genius was given an ultimate, unforgettable run for his mind, no, not by the genius of a computer, but of man as toolmaker.},
  comment   = {Deep Blue beat Kasparow in chess in 1997},
  groups    = {Computing and GPU},
  owner     = {flo},
  timestamp = {2016.04.13},
}

@Article{Hu2016,
  author       = {Hu, Yuhuang and Liu, Hongjie and Pfeiffer, Michael and Delbruck, Tobi},
  title        = {{DVS} {B}enchmark {D}atasets for {O}bject {T}racking, {A}ction {R}ecognition, and {O}bject {R}ecognition},
  journaltitle = {Frontiers in Neuroscience},
  date         = {2016},
  volume       = {10},
  pages        = {405},
  issn         = {1662-453X},
  doi          = {10.3389/fnins.2016.00405},
  comment      = {Dataset available online at http://cmp.felk.cvut.cz/~vojirtom/dataset/},
  file         = {:pdf-files/Hu2016 - DVS Benchmark Datasets for Object Tracking, Action Recognition, and Object Recognition.pdf:PDF},
  groups       = {Neuromorphic Vision},
  owner        = {flo},
  timestamp    = {2016.09.01},
}

@Online{HBP-proj,
  author    = {{Human {B}rain {P}roject}},
  title     = {{H}uman {B}rain {P}roject webpage},
  url       = {https://www.humanbrainproject.eu},
  urldate   = {2018-04-05},
  comment   = {started on 1 October 2013, funded with 1 billion Euro},
  groups    = {Projects},
  owner     = {flo},
  timestamp = {2016.03.22},
  year      = {2018},
}

@Article{Hunsberger2015,
  author       = {Eric Hunsberger and Chris Eliasmith},
  title        = {{S}piking {D}eep {N}etworks with {LIF} {N}eurons},
  journaltitle = {Computing Research Repository (CoRR)},
  date         = {2015},
  volume       = {abs/1510.08829},
  url          = {http://arxiv.org/abs/1510.08829},
  file         = {:pdf-files/Hunsberger2015 - Spiking Deep Networks with LIF Neurons.pdf:PDF},
  groups       = {Spiking Neural Networks},
  owner        = {flo},
  timestamp    = {2016.03.15},
}

@Article{Huval2015,
  author       = {Brody Huval and Tao Wang and Sameep Tandon and Jeff Kiske and Will Song and Joel Pazhayampallil and Mykhaylo Andriluka and Pranav Rajpurkar and Toki Migimatsu and Royce Cheng{-}Yue and Fernando Mujica and Adam Coates and Andrew Y. Ng},
  title        = {An {E}mpirical {E}valuation of {D}eep {L}earning on {H}ighway {D}riving},
  journaltitle = {Computing Research Repository (CoRR)},
  date         = {2015},
  volume       = {abs/1504.01716},
  url          = {http://arxiv.org/abs/1504.01716},
  file         = {:pdf-files/Huval2015 - An Empirical Evaluation of Deep Learning on Highway Driving.pdf:PDF},
  groups       = {Autonomous Driving, Deep Neural Networks},
  owner        = {flo},
  timestamp    = {2016.10.26},
}

@InProceedings{Indiveri1997,
  author    = {G. Indiveri},
  title     = {{Neuromorphic Systems For Industrial Applications}},
  booktitle = {Proc.International Body Engineering Conference \& Exposition},
  date      = {1997},
  location  = {Stuttgart, Germany},
  url       = {http://ncs.ethz.ch/pubs/pdf/Indiveri97.pdf},
  file      = {:pdf-files/Indiveri1997 - Neuromorphic Systems for Industrial Applications.pdf:PDF},
  groups    = {Neuromorphic Hardware},
  owner     = {flo},
  timestamp = {2016.01.18},
}

@Article{Indiveri2009,
  author       = {Giacomo Indiveri and Elisabetta Chicca and Rodney J. Douglas},
  title        = {Artificial Cognitive Systems: From {VLSI} Networks of Spiking Neurons to Neuromorphic Cognition},
  journal      = {Cognitive Computation},
  journaltitle = {Cognitive Computation},
  year         = {2009},
  date         = {2009},
  volume       = {1},
  number       = {2},
  pages        = {119--127},
  doi          = {10.1007/s12559-008-9003-6},
  url          = {http://ncs.ethz.ch/pubs/pdf/Indiveri_etal09.pdf},
  file         = {:pdf-files/Indiveri2009 - Artificial Cognitive Systems_ from VLSI Networks of Spiking Neurons to Neuromorphic Cognition.pdf:PDF},
  groups       = {Neural Modelling, Spiking Neural Networks},
  keywords     = {neuromorphic, soft WTA, spike-based plasticity, VLSI},
  owner        = {flo},
  publisher    = {Springer Nature},
  timestamp    = {2015.12.16},
}

@Article{Indiveri2015,
  author       = {Giacomo Indiveri and Shih{-}Chii Liu},
  title        = {Memory and information processing in neuromorphic systems},
  journaltitle = {Proceedings of the {IEEE}},
  date         = {2015},
  volume       = {103},
  number       = {8},
  pages        = {1379--1397},
  doi          = {10.1109/JPROC.2015.2444094},
  url          = {http://ncs.ethz.ch/pubs/pdf/Indiveri_Liu15.pdf},
  abstract     = {A striking difference between brain-inspired neuromorphic processors and current von Neumann processors architectures is the way in which memory and processing is organized. As Information and Communication Technologies continue to address the need for increased computational power through the increase of cores within a digital processor, neuromorphic engineers and scientists can complement this need by building processor architectures where memory is distributed with the processing. In this paper we present a survey of brain-inspired processor architectures that support models of cortical networks and deep neural networks. These architectures range from serial clocked implementations of multi-neuron systems to massively parallel asynchronous ones and from purely digital systems to mixed analog/digital systems which implement more biological-like models of neurons and synapses together with a suite of adaptation and learning mechanisms analogous to the ones found in biological nervous systems. We describe the advantages of the different approaches being pursued and present the challenges that need to be addressed for building artificial neural processing systems that can display the richness of behaviors seen in biological systems.},
  file         = {:pdf-files/Indiveri2015 - Memory and Information Processing in Neuromorphic Systems.pdf:PDF},
  groups       = {Neuromorphic Computing},
  owner        = {flo},
  publisher    = {IEEE},
  timestamp    = {2016.03.09},
}

@Online{CollabBrainProjects,
  author    = {{International Neuroinformatics Coordinating Facility (INCF)}},
  title     = {List of collaborative brain projects},
  url       = {https://www.incf.org/about-us/major-brain-initiatives-around-the-globe},
  urldate   = {2018-04-05},
  groups    = {Projects},
  owner     = {flo},
  timestamp = {2016.04.19},
}

@Article{Izhikevich2004,
  author       = {Izhikevich, E. M.},
  title        = {{Which Model to Use for Cortical Spiking Neurons?}},
  journaltitle = {IEEE Transactions on Neural Networks},
  date         = {2004},
  volume       = {15},
  number       = {5},
  pages        = {1063--1070},
  issn         = {1045-9227},
  doi          = {10.1109/TNN.2004.832719},
  url          = {http://www.izhikevich.org/publications/whichmod.pdf},
  abstract     = {We discuss the biological plausibility and computational efficiency of some of the most useful models of spiking and bursting neurons. We compare their applicability to large-scale simulations of cortical neural networks.},
  booktitle    = {Neural Networks, IEEE Transactions on},
  file         = {:pdf-files/Izhikevich2004 - Which Model to Use for Cortical Spiking Neurons_.pdf:PDF},
  groups       = {public, Spiking Neural Networks},
  keywords     = {spiking network neural},
  owner        = {flo},
  timestamp    = {2016.01.18},
  username     = {mhwombat},
}

@Article{Izhikevich2003,
  author       = {Izhikevich, E. M.},
  title        = {Simple model of spiking neurons},
  journaltitle = {IEEE Transactions on Neural Networks},
  date         = {2003},
  volume       = {14},
  number       = {6},
  pages        = {1569--1572},
  issn         = {1045-9227},
  doi          = {10.1109/TNN.2003.820440},
  url          = {http://www.izhikevich.org/publications/spikes.pdf},
  abstract     = {A model is presented that reproduces spiking and bursting behavior of known types of cortical neurons. The model combines the biologically plausibility of Hodgkin-Huxley-type dynamics and the computational efficiency of integrate-and-fire neurons. Using this model, one can simulate tens of thousands of spiking cortical neurons in real time (1 ms resolution) using a desktop PC.},
  booktitle    = {Neural Networks, IEEE Transactions on},
  file         = {:pdf-files/Izhikevich2003 - Simple Model of Spiking Neurons..pdf:PDF},
  groups       = {Spiking Neural Networks},
  keywords     = {spiking network neural},
  owner        = {flo},
  timestamp    = {2016.01.18},
  username     = {mhwombat},
}

@Article{Izhikevich2008,
  author       = {Izhikevich, Eugene M. and Edelman, Gerald M.},
  title        = {Large-scale model of mammalian thalamocortical systems},
  journaltitle = {Proceedings of the National Academy of Sciences},
  date         = {2008},
  volume       = {105},
  number       = {9},
  pages        = {3593--3598},
  doi          = {10.1073/pnas.0712231105},
  abstract     = {The understanding of the structural and dynamic complexity of mammalian brains is greatly facilitated by computer simulations. We present here a detailed large-scale thalamocortical model based on experimental measures in several mammalian species. The model spans three anatomical scales. (i) It is based on global (white-matter) thalamocortical anatomy obtained by means of diffusion tensor imaging ({DTI)} of a human brain. (ii) It includes multiple thalamic nuclei and six-layered cortical microcircuitry based on in vitro labeling and three-dimensional reconstruction of single neurons of cat visual cortex. (iii) It has 22 basic types of neurons with appropriate laminar distribution of their branching dendritic trees. The model simulates one million multicompartmental spiking neurons calibrated to reproduce known types of responses recorded in vitro in rats. It has almost half a billion synapses with appropriate receptor kinetics, short-term plasticity, and long-term dendritic spike-timing-dependent synaptic plasticity (dendritic {STDP).} The model exhibits behavioral regimes of normal brain activity that were not explicitly built-in but emerged spontaneously as the result of interactions among anatomical and dynamic processes. We describe spontaneous activity, sensitivity to changes in individual neurons, emergence of waves and rhythms, and functional connectivity on different scales.},
  file         = {:pdf-files/Izhikevich2008 - Large Scale Model of Mammalian Thalamocortical Systems.pdf:PDF},
  groups       = {Neural Modelling},
  owner        = {flo},
  timestamp    = {2016.02.19},
}

@Book{Jackendoff2002,
  author    = {Jackendoff, R.},
  title     = {Foundations of {L}anguage: {B}rain, {M}eaning, {G}rammar, {E}volution},
  date      = {2002},
  series    = {Oxford scholarship online},
  publisher = {Oxford University Press},
  isbn      = {9780198270126},
  url       = {https://books.google.de/books?id=gtGliq-q2aMC},
  file      = {:pdf-files/Jackendoff2002 - Foundations of Language_ Brain, Meaning, Grammar, Evolution.pdf:PDF},
  groups    = {Neuroscience},
  lccn      = {2001052066},
  owner     = {flo},
  timestamp = {2017.07.03},
}

@Article{Jacobs2013,
  author       = {Joshua Jacobs and Christoph T Weidemann and Jonathan F Miller and Alec Solway and John F Burke and Xue-Xin Wei and Nanthia Suthana and Michael R Sperling and Ashwini D Sharan and Itzhak Fried and Michael J Kahana},
  title        = {Direct recordings of grid-like neuronal activity in human spatial navigation},
  journal      = {Nature Neuroscience},
  journaltitle = {Nature Neuroscience},
  year         = {2013},
  date         = {2013},
  volume       = {16},
  number       = {9},
  pages        = {1188--1190},
  issn         = {1097-6256},
  doi          = {10.1038/nn.3466},
  abstract     = {Grid cells in the entorhinal cortex appear to represent spatial location via a triangular coordinate system. Such cells, which have been identified in rats, bats, and monkeys, are believed to support a wide range of spatial behaviors. By recording neuronal activity from neurosurgical patients performing a virtual-navigation task we identified cells exhibiting grid-like spiking patterns in the human brain, suggesting that humans and simpler animals rely on homologous spatial-coding schemes.},
  file         = {:pdf-files/Jacobs2013 - Direct Recordings of Grid like Neuronal Activity in Human Spatial Navigation.pdf:PDF},
  groups       = {Biology},
  owner        = {flo},
  publisher    = {Springer Nature},
  timestamp    = {2016.04.06},
}

@Article{Jaderberg2017,
  author       = {{Jaderberg}, M. and {Dalibard}, V. and {Osindero}, S. and {Czarnecki}, W.~M. and {Razavi}, A. and {Vinyals}, O. and {Green}, T. and {Dunning}, I. and {Fernando}, C. and {Kavukcuoglu}, K.},
  title        = {{Population Based Training of Neural Networks}},
  journaltitle = {ArXiv e-prints},
  date         = {2017},
  eprint       = {1711.09846},
  eprintclass  = {cs.LG},
  eprinttype   = {arXiv},
  file         = {:pdf-files/Jaderberg2017 - Population Based Training of Neural Networks.pdf:PDF},
  groups       = {Deep Neural Networks},
  keywords     = {Computer Science - Learning, Computer Science - Neural and Evolutionary Computing},
  owner        = {flo},
  timestamp    = {2017.11.29},
}

@Article{Janai2017,
  author       = {{Janai}, J. and {G{\"u}ney}, F. and {Behl}, A. and {Geiger}, A.},
  title        = {{Computer Vision for Autonomous Vehicles: Problems, Datasets and State-of-the-Art}},
  journaltitle = {ArXiv e-prints},
  date         = {2017},
  eprint       = {1704.05519},
  eprintclass  = {cs.CV},
  eprinttype   = {arXiv},
  abstract     = {Recent years have witnessed amazing progress in AI related fields such as computer vision, machine learning and autonomous vehicles. As with any rapidly growing field, however, it becomes increasingly difficult to stay up-to-date or enter the field as a beginner. While several topic specific survey papers have been written, to date no general survey on problems, datasets and methods in computer vision for autonomous vehicles exists. This paper attempts to narrow this gap by providing a state-of-the-art survey on this topic. Our survey includes both the historically most relevant literature as well as the current state-of-the-art on several specific topics, including recognition, reconstruction, motion estimation, tracking, scene understanding and end-to-end learning. Towards this goal, we first provide a taxonomy to classify each approach and then analyze the performance of the state-of-the-art on several challenging benchmarking datasets including KITTI, ISPRS, MOT and Cityscapes. Besides, we discuss open problems and current research challenges. To ease accessibility and accommodate missing references, we will also provide an interactive platform which allows to navigate topics and methods, and provides additional information and project links for each paper.},
  file         = {:pdf-files/Janai2017 - Computer Vision for Autonomous Vehicles_ Problems, Datasets and State of the Art.pdf:PDF},
  groups       = {Autonomous Driving},
  keywords     = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
  owner        = {flo},
  timestamp    = {2017.04.25},
}

@Article{Jia2014,
  author       = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
  title        = {{C}affe: {C}onvolutional {A}rchitecture for {F}ast {F}eature {E}mbedding},
  journaltitle = {ArXiv e-prints},
  date         = {2014},
  comment      = {Caffe: a tool for deep learning used in digits-box},
  file         = {:pdf-files/Jia2014 - Caffe_ Convolutional Architecture for Fast Feature Embedding.pdf:PDF},
  groups       = {Deep Neural Networks, Software and Tools},
  owner        = {flo},
  timestamp    = {2016.03.09},
}

@PhdThesis{Kaempchen2007,
  author      = {Nico Kaempchen},
  title       = {Feature-level fusion of laser scanner and video data for advanced driver assistance systems},
  institution = {Universit{\"a}t Ulm, Fakult{\"a}t f{\"u}r Ingenieurwissenschaften und Informatik},
  date        = {2007},
  url         = {http://vts.uni-ulm.de/doc.asp?id=5958},
  file        = {:pdf-files/Kaempchen2007 - Feature Level Fusion of Laser Scanner and Video Data for Advanced Driver Assistance Systems.pdf:PDF},
  groups      = {Environment Model},
  owner       = {flo},
  timestamp   = {2016.03.29},
}

@Misc{Kaempchen2015,
  author       = {Nico Kaempchen and Hariolf Gentner},
  title        = {Central Environment Model - From first release in the new {B}{M}{W} 7 series to highly automated driving},
  date         = {2015},
  howpublished = {17th International Congress Electronics in Vehicles},
  file         = {:pdf-files/Kaempchen2015 - Central Environment Model from First Release in the New BMW 7 Series to Highly Automated Driving.pdf:PDF},
  groups       = {Environment Model},
  owner        = {flo},
  timestamp    = {2015.12.11},
}

@Book{Kaiser1996,
  author     = {P. K. Kaiser and R. M. Boynton},
  title      = {{H}uman {C}olor {V}ision},
  date       = {1996},
  publisher  = {Optical Society of America},
  annotation = {SIGNATUR = 789.929},
  groups     = {Biology},
  keywords   = {VISUAL PERCEPTION AND BIOLOGICAL VISION},
  owner      = {flo},
  place      = {Favoritenstrasse 9/4th Floor/1863},
  timestamp  = {2015.12.16},
}

@InBook{Kanerva2000,
  author    = {Kanerva, Pentti},
  title     = {Large Patterns Make Great Symbols: An Example of Learning from Example},
  booktitle = {Hybrid Neural Systems},
  date      = {2000},
  editor    = {Wermter, Stefan and Sun, Ron},
  publisher = {Springer Berlin Heidelberg},
  location  = {Berlin, Heidelberg},
  isbn      = {978-3-540-46417-4},
  pages     = {194--203},
  doi       = {10.1007/10719871_13},
  file      = {:pdf-files/Kanerva2000 - Large Patterns Make Great Symbols_ an Example of Learning from Example.pdf:PDF},
  groups    = {Vector Symbolic Architectures},
  owner     = {flo},
  timestamp = {2017.05.18},
}

@Article{Kanerva2009,
  author       = {Pentti Kanerva},
  title        = {Hyperdimensional {C}omputing: {A}n {I}ntroduction to {C}omputing in {D}istributed {R}epresentation with {H}igh-{D}imensional {R}andom {V}ectors},
  journaltitle = {Cognitive Computation},
  date         = {2009},
  volume       = {1},
  number       = {2},
  pages        = {139--159},
  doi          = {10.1007/s12559-009-9009-8},
  file         = {:pdf-files/Kanerva2009 - Hyperdimensional Computing_ an Introduction to Computing in Distributed Representation with High Dimensional Random Vectors.pdf:PDF},
  groups       = {Vector Symbolic Architectures},
  owner        = {flo},
  timestamp    = {2017.05.04},
}

@Book{Kanerva1988,
  author    = {Kanerva, Pentti},
  title     = {Sparse {D}istributed {M}emory},
  date      = {1988},
  publisher = {MIT Press},
  location  = {Cambridge, MA, USA},
  isbn      = {0262111322},
  groups    = {Vector Symbolic Architectures},
  owner     = {flo},
  timestamp = {2017.07.05},
}

@InProceedings{Kang2014,
  author    = {M. Kang and S. Hur and W. Jeong and Y. Park},
  title     = {Map Building Based on Sensor Fusion for Autonomous Vehicle},
  booktitle = {11th International Conference on Information Technology: New Generations (ITNG)},
  date      = {2014},
  pages     = {490--495},
  doi       = {10.1109/ITNG.2014.30},
  abstract  = {An autonomous vehicle requires the technology of generating maps by recognizing the surrounding environment. The recognition of the vehicle's environment can be achieved by using distance information from a 2D laser scanner and color information from a camera. Such sensor information is used to generate 2D or 3D maps. A 2D map is used mostly for generating routs, because it contains information only about a section. In contrast, a 3D map involves height values also, and therefore can be used not only for generating routs but also for finding out vehicle accessible space. Nevertheless, an autonomous vehicle using 3D maps has difficulty in recognizing environment in real time. Accordingly, this paper proposes the technology for generating 2D maps that guarantee real-time recognition. The proposed technology uses only the color information obtained by removing height values from 3D maps generated based on the fusion of 2D laser scanner and camera data.},
  file      = {:pdf-files/Kang2014 - Map Building Based on Sensor Fusion for Autonomous Vehicle.pdf:PDF},
  groups    = {Environment Model},
  keywords  = {image colour analysis;mobile robots;object recognition;optical scanners;sensor fusion;2D laser scanner;2D map;3D map;autonomous vehicle;color information;distance information;height value;map building;sensor fusion;vehicle accessible space;Information technology;2D Laser Scanner;Autonomous Vehicle;Camera;Map Building;Occupancy Grid Map;Sensor Fusion},
  owner     = {flo},
  timestamp = {2016.03.22},
}

@Article{Karpathy2017,
  author       = {Karpathy, Andrej and Fei-Fei, Li},
  date         = {2017},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title        = {Deep {V}isual-{S}emantic {A}lignments for {G}enerating {I}mage {D}escriptions},
  doi          = {10.1109/TPAMI.2016.2598339},
  issn         = {0162-8828},
  number       = {4},
  pages        = {664--676},
  volume       = {39},
  acmid        = {3069250},
  file         = {:pdf-files/Karpathy2017 - Deep Visual Semantic Alignments for Generating Image Descriptions.pdf:PDF},
  groups       = {Image Caption Generation},
  issue_date   = {April 2017},
  location     = {Washington, DC, USA},
  numpages     = {13},
  owner        = {flo},
  publisher    = {IEEE Computer Society},
  timestamp    = {2017.10.18},
}

@InProceedings{Katz2012,
  author    = {M. L. Katz and K. Nikolic and T. Delbruck},
  title     = {Live demonstration: Behavioural emulation of event-based vision sensors},
  booktitle = {2012 {IEEE} International Symposium on Circuits and Systems},
  year      = {2012},
  date      = {2012},
  publisher = {{IEEE}},
  pages     = {736--740},
  doi       = {10.1109/iscas.2012.6272143},
  abstract  = {This demonstration shows how an inexpensive high frame-rate USB camera is used to emulate existing and proposed activity-driven event-based vision sensors. A PS3-Eye camera which runs at a maximum of 125 frames/second with colour QVGA (320$\times$240) resolution is used to emulate several event-based vision sensors, including a Dynamic Vision Sensor (DVS), a colour-change sensitive DVS (cDVS), and a hybrid vision sensor with DVS+cDVS pixels. The emulator is integrated into the jAER software project for event-based real-time vision and is used to study use cases for future vision sensor designs.},
  file      = {:pdf-files/Katz2012 - Live Demonstration_ Behavioural Emulation of Event Based Vision Sensors.pdf:PDF},
  groups    = {Neuromorphic Vision},
  issn      = {0271-4302},
  keywords  = {cameras;image colour analysis;image resolution;image sensors;peripheral interfaces;DVS+cDVS pixel;PS3-eye camera;activity-driven event-based vision sensor;behavioural emulation;colour QVGA resolution;colour-change sensitive DVS;dynamic vision sensor;high frame-rate USB camera;jAER software project;Brightness;Cameras;Emulation;Image color analysis;Sensors;Software;Voltage control;Associated Track 11.1;Image and Vision Sensors;Sensory Systems},
  owner     = {flo},
  timestamp = {2016.02.18},
}

@TechReport{Katzoff1964,
  author      = {Katzoff, S.},
  title       = {Clarity in technical reporting},
  institution = {NASA Langley Research Center},
  date        = {1964},
  location    = {Washington},
  abstract    = {This booklet offers common-sense suggestions for improving written and oral reports. It is designed not only for prospective writers within the National Aeronautics and Space Administration but also for scientists and engineers among the agency's contractors who must report the results of their research. It discusses basic attitudes, some elements of composition, the organization and contents of the report, and the editorial review.},
  added-at    = {2011-07-19T11:55:05.000+0200},
  file        = {:pdf-files/Katzoff1964 - Clarity in Technical Reporting.pdf:PDF},
  groups      = {Non-Technical},
  keywords    = {nasa pdf technicalreport writing},
  owner       = {flo},
  timestamp   = {2017.07.21},
}

@InProceedings{Kelly2012,
  author    = {Matthew A. Kelly and Robert L. West},
  title     = {From Vectors to Symbols to Cognition: The Symbolic and Sub-Symbolic Aspects of Vector-Symbolic Cognitive Models},
  booktitle = {Proceedings of the 34th Annual Meeting of the Cognitive Science Society, CogSci 2012, Sapporo, Japan, August 1-4, 2012},
  date      = {2012},
  url       = {https://mindmodeling.org/cogsci2012/papers/0311/index.html},
  file      = {:pdf-files/Kelly2012 - From Vectors to Symbols to Cognition_ the Symbolic and Sub Symbolic Aspects of Vector Symbolic Cognitive Models.pdf:PDF},
  groups    = {Vector Symbolic Architectures},
  owner     = {flo},
  timestamp = {Mon, 07 Mar 2016 14:09:29 +0100},
}

@InProceedings{Khosroshahi2016,
  author    = {A. Khosroshahi and E. Ohn-Bar and M. M. Trivedi},
  title     = {Surround {V}ehicles {T}rajectory {A}nalysis with {R}ecurrent {N}eural {N}etworks},
  booktitle = {2016 IEEE 19th International Conference on Intelligent Transportation Systems (ITSC)},
  date      = {2016},
  pages     = {2267--2272},
  doi       = {10.1109/ITSC.2016.7795922},
  abstract  = {Behavior analysis of vehicles surrounding the egovehicle is an essential component in safe and pleasant autonomous driving. This study develops a framework for activity classification of observed on-road vehicles using 3D trajectory cues and a Long Short Term Memory (LSTM) model. As a case study, we aim to classify maneuvers of surrounding vehicles at four way intersections. LIDAR, GPS, and IMU measurements are used to extract ego-motion compensated surround trajectories from data clips in the KITTI benchmark. The impact of different prediction label space choices, feature space input, noisy/missing trajectory data, and LSTM model architectures are analyzed, presenting the strengths and limitations of the proposed approach.},
  file      = {:pdf-files/Khosroshahi2016 - Surround Vehicles Trajectory Analysis with Recurrent Neural Networks.pdf:PDF},
  groups    = {Behaviour analysis},
  keywords  = {neural nets;road safety;road vehicles;traffic engineering computing;3D trajectory cues;GPS measurement;IMU measurement;LIDAR measurement;activity classification;autonomous driving;behavior analysis;ego-motion extraction;egovehicle;long short term memory model;maneuver classification;recurrent neural networks;surround vehicles trajectory analysis;Feature extraction;Hidden Markov models;Logic gates;Three-dimensional displays;Trajectory;Turning;Vehicles},
  owner     = {flo},
  timestamp = {2017.09.20},
}

@InProceedings{Kievit-Kylar2011,
  author    = {Brent Kievit{-}Kylar and Michael N. Jones},
  title     = {The {S}emantic {P}ictionary {P}roject},
  booktitle = {Proceedings of the 33th Annual Meeting of the Cognitive Science Society, CogSci 2011, Boston, Massachusetts, USA, July 20-23, 2011},
  date      = {2011},
  url       = {http://www.indiana.edu/~clcl/Papers/KK_Jones_CogSci2011.pdf},
  file      = {:pdf-files/Kievit-Kylar2011 - The Semantic Pictionary Project.pdf:PDF},
  groups    = {Vector Symbolic Architectures},
  owner     = {flo},
  timestamp = {2017.08.02},
}

@InProceedings{Kim2014,
  author    = {Hanme Kim and Ankur Handa and Ryad Benosman and Sio{-}Hoi Ieng and Andrew J. Davison},
  title     = {Simultaneous Mosaicing and Tracking with an Event Camera},
  booktitle = {British Machine Vision Conference, {BMVC} 2014, Nottingham, UK, September 1-5, 2014},
  date      = {2014},
  file      = {:pdf-files/Kim2014 - Simultaneous Mosaicing and Tracking with an Event Camera.pdf:PDF},
  groups    = {Neuromorphic Vision},
  owner     = {flo},
  timestamp = {2016.01.18},
}

@Online{BrainScaleS-proj,
  author    = {{Kirchhoff-Institute for Physics, Heidelberg University}},
  title     = {Brain{S}cale{S}-project},
  url       = {https://brainscales.kip.uni-heidelberg.de},
  urldate   = {2018-04-05},
  comment   = {The project started on 1 January 2011 and ended on 31 March 2015. It was a collaboration of 19 research groups from 10 European countries. The hardware development on the neuromorphic computing systems is continued in the Human Brain Project (HBP) in the Neuromorphic Computing Platform. "Brain-inspired multiscale compu- tation in neuromorphic hybrid systems". This project was funded by the European Union under the FP7-ICT program, and started in January 2011. It builds on the research carried out in the previous EU FACETS (Fast Analog Computing with Emergent Transient States) project, and is now part of the EU FET Flagship Human Brain Project (HBP). The mixed signal analog-digital system being developed in this project currently represents the "physical model" Neuromorphic Computing Platform of the HBP.},
  groups    = {Projects},
  owner     = {flo},
  timestamp = {2016.03.22},
}

@Online{FACETS-proj,
  author    = {{Kirchhoff-Institute for Physics, Heidelberg University}},
  title     = {{FACETS}-project},
  url       = {https://facets.kip.uni-heidelberg.de},
  urldate   = {2018-04-05},
  comment   = {2005-31 August 2010 results: Spikey, PyNN The BrainScaleS project builds on and extends the research done in FACETS},
  groups    = {Projects},
  owner     = {flo},
  timestamp = {2016.03.22},
}

@Online{Annieway,
  author    = {{Karlsruhe Institute of Technology}},
  title     = {Annieway Project},
  url       = {http://www.mrt.kit.edu/annieway/},
  urldate   = {2018-02-22},
  groups    = {Autonomous Driving},
  owner     = {flo},
  timestamp = {2018.02.22},
}

@Article{Kleyko2015a,
  author       = {Denis Kleyko and Evgeny Osipov and Ross W. Gayler and Asad I. Khan and Adrian G. Dyer},
  date         = {2015},
  journaltitle = {Biologically Inspired Cognitive Architectures},
  title        = {Imitation of honey bees' concept learning processes using Vector Symbolic Architectures},
  doi          = {10.1016/j.bica.2015.09.002},
  issn         = {2212-683X},
  pages        = {57--72},
  url          = {http://www.sciencedirect.com/science/article/pii/S2212683X15000456},
  volume       = {14},
  abstract     = {Abstract This article presents a proof-of-concept validation of the use of Vector Symbolic Architectures as central component of an online learning architectures. It is demonstrated that Vector Symbolic Architectures enable the structured combination of features/relations that have been detected by a perceptual circuitry and allow such relations to be applied to novel structures without requiring the massive training needed for classical neural networks that depend
 on trainable connections. The system is showcased through the functional imitation of concept learning in honey bees. Data from real-world experiments with honey bees (Avargu{\`e}s-Weber et al., 2012) are used for benchmarking. It is demonstrated that the proposed pipeline features a similar learning curve and accuracy of generalization to that observed for the living bees. The main claim of this article is that there is a class of simple artificial systems that reproduce the learning behaviors of certain living organisms without requiring the implementation of computationally intensive cognitive architectures. Consequently, it is possible in some cases to implement rather advanced cognitive behavior using simple techniques.},
  file         = {:pdf-files/Kleyko2015a - Imitation of Honey Bees' Concept Learning Processes Using Vector Symbolic Architectures.pdf:PDF},
  groups       = {Vector Symbolic Architectures},
  keywords     = {Vector Symbolic Architecture},
  owner        = {flo},
  timestamp    = {2017.05.17},
}

@InProceedings{Kleyko2015,
  author    = {D. Kleyko and E. Osipov and N. Papakonstantinou and V. Vyatkin and A. Mousavi},
  title     = {Fault detection in the hyperspace: Towards intelligent automation systems},
  booktitle = {2015 IEEE 13th International Conference on Industrial Informatics (INDIN)},
  date      = {2015},
  pages     = {1219--1224},
  doi       = {10.1109/INDIN.2015.7281909},
  abstract  = {This article presents a methodology for intelligent, biologically inspired fault detection system for generic complex systems of systems. The proposed methodology utilizes the concepts of associative memory and vector symbolic architectures, commonly used for modeling cognitive abilities of human brain. Compared to classical methods of artificial intelligence used in the context of fault detection the proposed methodology shows an unprecedented performance, while featuring zero configuration and simple operations.},
  file      = {:pdf-files/Kleyko2015 - Fault Detection in the Hyperspace_ Towards Intelligent Automation Systems.pdf:PDF},
  groups    = {Vector Symbolic Architectures},
  issn      = {1935-4576},
  keywords  = {content-addressable storage;factory automation;fault diagnosis;learning (artificial intelligence);artificial intelligence;associative memory;biologically inspired fault detection system;generic complex system;human brain;intelligent automation system;vector symbolic architecture;Accuracy;Artificial neural networks;Circuit faults;Computer architecture;Fault detection;Fault diagnosis;Neurons;Holographic Graph Neuron;Hyperdimensional Computing;Vector Symbolic Architecture;fault detection;nuclear power plant},
  owner     = {flo},
  timestamp = {2017.04.26},
}

@Article{Kober2013,
  author       = {J. Kober and J. Andrew (Drew) Bagnell and J. Peters},
  title        = {Reinforcement {L}earning in {R}obotics: {A} {S}urvey},
  journaltitle = {International Journal of Robotics Research},
  date         = {2013},
  file         = {:pdf-files/Kober2013 - Reinforcement Learning in Robotics_ a Survey.pdf:PDF},
  groups       = {Robotics, ReinforcementLearning, Deep Neural Networks},
  owner        = {flo},
  timestamp    = {2016.10.12},
}

@InProceedings{Kolski2006,
  author    = {Kolski, S. and Ferguson, D. and Stachniss, C. and Siegwart, R.},
  title     = {{A}utonomous {D}riving in {D}ynamic {E}nvironments},
  booktitle = {Proceedings of The Workshop on Safe Navigation in Open and Dynamic Environments (IROS)},
  date      = {2006},
  file      = {:pdf-files/Kolski2006 - Autonomous Driving in Dynamic Environments.pdf:PDF},
  groups    = {Autonomous Driving},
  owner     = {flo},
  timestamp = {2016.01.18},
}

@Article{Koomey2011,
  author       = {Jonathan Koomey and Stephen Berard and Marla Sanchez and Henry Wong},
  title        = {Implications of Historical Trends in the Electrical Efficiency of Computing},
  journal      = {{IEEE} Annals of the History of Computing},
  journaltitle = {{IEEE} Annals of the History of Computing},
  year         = {2011},
  date         = {2011},
  volume       = {33},
  number       = {3},
  pages        = {46--54},
  issn         = {1058-6180},
  doi          = {10.1109/mahc.2010.28},
  abstract     = {The electrical efficiency of computation has doubled roughly every year and a half for more than six decades, a pace of change comparable to that for computer performance and electrical efficiency in the microprocessor era. These efficiency improvements enabled the creation of laptops, smart phones, wireless sensors, and other mobile computing devices, with many more such innovations yet to come. The Web Extra appendix outlines the data and methods used in this study.},
  comment      = {Koomey's Law: The number of computations per joule of energy dissipated has been doubling approximately every 1.57 years since the 1950s},
  file         = {:pdf-files/Koomey2011 - Implications of Historical Trends in the Electrical Efficiency of Computing.pdf:PDF},
  groups       = {Computing and GPU},
  keywords     = {laptop computers;low-power electronics;mobile handsets;notebook computers;power aware computing;Web Extra;electrical computing efficiency;laptops;microprocessor;mobile computing devices;smart phones;wireless sensors;Battery charge measurement;Computer performance;Electric variables measurement;History;Microprocessors;Mobile computing;Moore's Law;Portable computers;Power generation;Moore's law;computer performance;electrical efficiency;history of computing;mobile computing;power usage},
  owner        = {flo},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  timestamp    = {2016.02.18},
}

@Misc{HowtoWriteAnAbstract,
  author    = {Philip Koopman},
  title     = {How to {W}rite an {A}bstract},
  date      = {1997},
  url       = {https://users.ece.cmu.edu/~koopman/essays/abstract.html},
  groups    = {Non-Technical},
  owner     = {flo},
  timestamp = {2016.10.14},
}

@Article{Koopman2016,
  author       = {Philip Koopman and Michael Wagner},
  title        = {Challenges in {A}utonomous {V}ehicle {T}esting and {V}alidation},
  journaltitle = {SAE International Journal of Transportation Safety},
  date         = {2016},
  volume       = {4},
  pages        = {15--24},
  doi          = {10.4271/2016-01-0128},
  abstract     = {AbstractSoftware testing is all too often simply a bug hunt rather than a well-considered exercise in ensuring quality. A more methodical approach than a simple cycle of system-level test-fail-patch-test will be required to deploy safe autonomous vehicles at scale. The ISO 26262 development V process sets up a framework that ties each type of testing to a corresponding design or requirement document, but presents challenges when adapted to deal with the sorts of novel testing problems that face autonomous vehicles. This paper identifies five major challenge areas in testing according to the V model for autonomous vehicles: driver out of the loop, complex requirements, non-deterministic algorithms, inductive learning algorithms, and fail-operational systems. General solution approaches that seem promising across these different challenge areas include: phased deployment using successively relaxed operational scenarios, use of a monitor/actuator pair architecture to separate the most complex autonomy functions from simpler safety functions, and fault injection as a way to perform more efficient edge case testing. While significant challenges remain in safety-certifying the type of algorithms that provide high-level autonomy themselves, it seems within reach to instead architect the system and its accompanying design process to be able to employ existing software safety approaches.},
  file         = {:pdf-files/Koopman2016 - Challenges in Autonomous Vehicle Testing and Validation.pdf:PDF},
  groups       = {Autonomous Driving},
  owner        = {flo},
  publisher    = {SAE International},
  timestamp    = {2016.10.14},
}

@InProceedings{Kotsiantis2007,
  author    = {Kotsiantis, S. B.},
  title     = {{Supervised Machine Learning: A Review of Classification Techniques}},
  booktitle = {Proceedings of the 2007 Conference on Emerging Artificial Intelligence Applications in Computer Engineering: Real Word AI Systems with Applications in eHealth, HCI, Information Retrieval and Pervasive Technologies},
  date      = {2007},
  publisher = {IOS Press},
  location  = {Amsterdam, The Netherlands, The Netherlands},
  isbn      = {978-1-58603-780-2},
  pages     = {3--24},
  url       = {http://dl.acm.org/citation.cfm?id=1566770.1566773},
  abstract  = {The goal of supervised learning is to build a concise model of the distribution of class labels in terms of predictor features. The resulting classifier is then used to assign class labels to the testing instances where the values of the predictor features are known, but the value of the class label is unknown. This paper describes various supervised machine learning classification techniques. Of course, a single chapter cannot be a complete review of all supervised machine learning classification algorithms (also known induction classification algorithms), yet we hope that the references cited will cover the major theoretical issues, guiding the researcher in interesting research directions and suggesting possible bias combinations that have yet to be explored.},
  acmid     = {1566773},
  file      = {:pdf-files/Kotsiantis2007 - Supervised Machine Learning_ a Review of Classification Techniques.pdf:PDF},
  groups    = {Machine Learning},
  keywords  = {Classifiers, Data Mining, Intelligent Data Analysis, Learning Algorithms},
  numpages  = {22},
  owner     = {flo},
  timestamp = {2016.01.28},
}

@InProceedings{Koutnik2013,
  author    = {Jan Koutn{\'i}k and Giuseppe Cuccu and J{\"u}rgen Schmidhuber and Faustino J. Gomez},
  title     = {Evolving large-scale neural networks for vision-based reinforcement learning},
  booktitle = {Genetic and Evolutionary Computation Conference, {GECCO} '13, Amsterdam, The Netherlands, July 6-10, 2013},
  date      = {2013},
  pages     = {1061--1068},
  doi       = {10.1145/2463372.2463509},
  file      = {:pdf-files/Koutnik2013 - Evolving Large Scale Neural Networks for Vision Based Reinforcement Learning.pdf:PDF},
  groups    = {ReinforcementLearning, Deep Neural Networks},
  owner     = {flo},
  timestamp = {2016.11.03},
}

@InProceedings{Koutnik2013a,
  author    = {Jan Koutn{\'i}k and Giuseppe Cuccu and J{\"u}rgen Schmidhuber and Faustino J. Gomez},
  title     = {Evolving large-scale neural networks for vision-based {TORCS}},
  booktitle = {Proceedings of the 8th International Conference on the Foundations of Digital Games, {FDG} 2013, Chania, Crete, Greece, May 14-17, 2013.},
  date      = {2013},
  pages     = {206--212},
  url       = {http://www.fdg2013.org/program/papers/paper27_koutnik_etal.pdf},
  file      = {:pdf-files/Koutnik2013a - Evolving Large Scale Neural Networks for Vision Based TORCS.pdf:PDF},
  groups    = {ReinforcementLearning, Deep Neural Networks},
  owner     = {flo},
  timestamp = {2016.11.03},
}

@InProceedings{Krichmar2011,
  author    = {Krichmar, Jeffrey L. and Dutt, Nikil and Nageswaran, Jayram M. and Richert, Micah},
  title     = {{Neuromorphic Modeling Abstractions and Simulation of Large-scale Cortical Networks}},
  booktitle = {Proceedings of the International Conference on Computer-Aided Design},
  date      = {2011},
  series    = {ICCAD '11},
  publisher = {IEEE Press},
  location  = {San Jose, California},
  isbn      = {978-1-4577-1398-9},
  pages     = {334--338},
  url       = {http://dl.acm.org/citation.cfm?id=2132325.2132411},
  acmid     = {2132411},
  address   = {Piscataway, NJ, USA},
  file      = {:pdf-files/Krichmar2011 - Neuromorphic Modeling Abstractions and Simulation of Large Scale Cortical Networks.pdf:PDF},
  groups    = {Neural Modelling},
  keywords  = {GPU, computational neuroscience, parallel processing, spiking neural networks, synapse, vision},
  numpages  = {5},
}

@InCollection{Krizhevsky2012,
  author    = {Alex Krizhevsky and Sutskever, Ilya and Geoffrey E. Hinton},
  title     = {{I}mage{N}et {C}lassification with {D}eep {C}onvolutional {N}eural {N}etworks},
  booktitle = {Advances in Neural Information Processing Systems 25},
  date      = {2012},
  editor    = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
  publisher = {Curran Associates, Inc.},
  pages     = {1097--1105},
  url       = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf},
  abstract  = {We trained a large, deep convolutional neural network to classify the 1.3 million high-resolution images in the LSVRC-2010 ImageNet training set into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 39.7\% and 18.9\% which is considerably better than the previous state-of-the-art results. The neural network, which has 60 million parameters and 500,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and two globally connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of convolutional nets. To reduce overfitting in the globally connected layers we employed a new regularization method that proved to be very effective.},
  comment   = {AlexNet model in digits resp. Caffe},
  file      = {:pdf-files/Krizhevsky2012 - ImageNet Classification with Deep Convolutional Neural Networks.pdf:PDF},
  groups    = {Deep Neural Networks},
  owner     = {flo},
  timestamp = {2016.03.09},
}

@Article{Lagorce2015,
  author       = {X. Lagorce and C. Meyer and S. H. Ieng and D. Filliat and R. Benosman},
  title        = {{Asynchronous Event-Based Multikernel Algorithm for High-Speed Visual Features Tracking}},
  journaltitle = {IEEE Transactions on Neural Networks and Learning Systems},
  date         = {2015},
  volume       = {26},
  number       = {8},
  pages        = {1710--1720},
  issn         = {2162-237X},
  doi          = {10.1109/TNNLS.2014.2352401},
  abstract     = {This paper presents a number of new methods for visual tracking using the output of an event-based asynchronous neuromorphic dynamic vision sensor. It allows the tracking of multiple visual features in real time, achieving an update rate of several hundred kilohertz on a standard desktop PC. The approach has been specially adapted to take advantage of the event-driven properties of these sensors by combining both spatial and temporal correlations of events in an
 asynchronous iterative framework. Various kernels, such as Gaussian, Gabor, combinations of Gabor functions, and arbitrary user-defined kernels, are used to track features from incoming events. The trackers described in this paper are capable of handling variations in position, scale, and orientation through the use of multiple pools of trackers. This approach avoids the N2 operations per event associated with conventional kernel-based convolution operations with N $\times$ N kernels. The tracking performance was evaluated experimentally for each type of kernel in order to demonstrate the robustness of the proposed solution.},
  file         = {:pdf-files/Lagorce2015 - Asynchronous Event Based Multikernel Algorithm for High Speed Visual Features Tracking.pdf:PDF},
  groups       = {Neuromorphic Vision},
  keywords     = {computer vision;convolution;correlation methods;image sensors;iterative methods;target tracking;Gabor functions;Gaussian functions;arbitrary user-defined kernels;asynchronous event-based multikernel algorithm;convolution operations;high-speed visual features tracking;iterative framework;multiple pools;neuromorphic dynamic vision sensor;orientation;position;real time;scale;spatial correlations;standard desktop PC;temporal correlations;update rate;Heuristic algorithms;Kernel;Real-time systems;Robot sensing systems;Shape;Tracking;Visualization;Event-based vision;neuromorphic sensing;visual tracking},
  owner        = {flo},
  timestamp    = {2016.03.10},
}

@Article{Lagorce2015a,
  author       = {Xavier Lagorce and Evangelos Stromatias and Francesco Galluppi and Luis A. Plana and Shih-Chii Liu and Steve B. Furber and Ryad B. Benosman},
  title        = {Breaking the millisecond barrier on {SpiNNaker}: implementing asynchronous event-based plastic models with microsecond resolution},
  journal      = {Frontiers in Neuroscience},
  journaltitle = {Frontiers in Neuroscience},
  year         = {2015},
  date         = {2015},
  volume       = {9},
  number       = {206},
  issn         = {1662-453X},
  doi          = {10.3389/fnins.2015.00206},
  abstract     = {Spike-based neuromorphic sensors such as retinas and cochleas, change the way in which the world is sampled. Instead of producing data sampled at a constant rate, these sensors output spikes that are asynchronous and event driven. The event-based nature of neuromorphic sensors implies a complete paradigm shift in current perception algorithms toward those that emphasize the importance of precise timing. The spikes produced by these sensors usually have a time resolution in the order of microseconds. This high temporal resolution is a crucial factor in learning tasks. It is also widely used in the field of biological neural networks. Sound localization for instance relies on detecting time lags between the two ears which, in the barn owl, reaches a temporal resolution of 5 $/mu$s. Current available neuromorphic computation platforms such as SpiNNaker often limit their users to a time resolution in the order of milliseconds that is not compatible with the asynchronous outputs of neuromorphic sensors. To overcome these limitations and allow for the exploration of new types of neuromorphic computing architectures, we introduce a novel software framework on the SpiNNaker platform. This framework allows for simulations of spiking networks and plasticity mechanisms using a completely asynchronous and event-based scheme running with a microsecond time resolution. Results on two example networks using this new implementation are presented.},
  file         = {:pdf-files/Lagorce2015a - Breaking the Millisecond Barrier on SpiNNaker_ Implementing Asynchronous Event Based Plastic Models with Microsecond Resolution.pdf:PDF},
  groups       = {SpiNNaker},
  owner        = {flo},
  publisher    = {Frontiers Media {SA}},
  timestamp    = {2016.03.10},
}

@InProceedings{Lawitzky2013,
  author    = {A. Lawitzky and D. Althoff and C. F. Passenberg and G. Tanzmeister and D. Wollherr and M. Buss},
  title     = {Interactive scene prediction for automotive applications},
  booktitle = {Intelligent Vehicles Symposium (IV), 2013 IEEE},
  date      = {2013},
  pages     = {1028--1033},
  doi       = {10.1109/IVS.2013.6629601},
  abstract  = {In this work, a framework for motion prediction of vehicles and safety assessment of traffic scenes is presented. The developed framework can be used for driver assistant systems as well as for autonomous driving applications. In order to assess the safety of the future trajectories of the vehicle, these systems require a prediction of the future motion of all traffic participants. As the traffic participants have a mutual influence on each other, the interaction of them is explicitly considered in this framework, which is inspired by an optimization problem. Taking the mutual influence of traffic participants into account, this framework differs from the existing approaches which consider the interaction only insufficiently, suffering reliability in real traffic scenes. For motion prediction, the collision probability of a vehicle performing a certain maneuver, is computed. Based on the safety evaluation and the assumption that drivers avoid collisions, the prediction is realized. Simulation scenarios and real-world results show the functionality.},
  file      = {:pdf-files/Lawitzky2013 - Interactive Scene Prediction for Automotive Applications.pdf:PDF},
  groups    = {Environment Model, Behaviour analysis},
  issn      = {1931-0587},
  keywords  = {collision avoidance;driver information systems;image motion analysis;interactive systems;natural scenes;optimisation;road safety;road traffic;road vehicles;automotive applications;autonomous driving applications;collision avoidance;collision probability;driver assistant systems;interactive scene prediction;optimization problem;reliability;safety assessment;safety evaluation;traffic participants;traffic scenes;vehicle motion prediction;Estimation;Hidden Markov models;Predictive models;Roads;Trajectory;Vehicles},
  owner     = {flo},
  timestamp = {2016.08.25},
}

@Article{LeCun2015,
  author       = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  title        = {Deep learning},
  journaltitle = {Nature},
  date         = {2015},
  volume       = {521},
  number       = {7553},
  pages        = {436--444},
  issn         = {0028-0836},
  file         = {:pdf-files/LeCun2015 - Deep Learning.pdf:PDF},
  groups       = {Deep Neural Networks},
  owner        = {flo},
  timestamp    = {2016.02.03},
}

@Article{LeCun1998,
  author       = {LeCun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  title        = {{Gradient-Based Learning Applied to Document Recognition}},
  journaltitle = {Proceedings of the IEEE},
  date         = {1998},
  volume       = {86},
  number       = {11},
  pages        = {2278--2324},
  comment      = {MNIST citation},
  file         = {:pdf-files/LeCun1998 - Gradient Based Learning Applied to Document Recognition.pdf:PDF},
  groups       = {Machine Learning, Datasets},
  owner        = {flo},
  timestamp    = {2016.02.19},
}

@InProceedings{Lee2012,
  author    = {J. H. Lee and P. K. J. Park and C. W. Shin and H. Ryu and B. C. Kang and T. Delbruck},
  title     = {Touchless hand gesture {UI} with instantaneous responses},
  booktitle = {2012 19th IEEE International Conference on Image Processing},
  date      = {2012},
  pages     = {1957--1960},
  doi       = {10.1109/ICIP.2012.6467270},
  abstract  = {In this paper we present a simple technique for real-time touchless hand gesture user interface (UI) for mobile devices based on a biologically inspired vision sensor, the dynamic vision sensor (DVS). The DVS can detect a moving object in a fast and cost effective way by outputting events asynchronously on edges of the object. The output events are spatiotemporally correlated by using novel event-driven processing algorithms based on leaky integrate-and-fire neurons to track a finger tip or to infer directions of hand swipe motions. The experimental results show that the proposed technique can achieve graphic UI capable finger tip tracking with milliseconds intervals and accurate hand swipe motion detection with negligible latency.},
  file      = {:pdf-files/Lee2012 - Touchless Hand Gesture UI with Instantaneous Responses.pdf:PDF},
  groups    = {Neuromorphic Vision},
  issn      = {1522-4880},
  keywords  = {correlation methods;gesture recognition;image motion analysis;image sensors;mobile computing;object detection;object tracking;spatiotemporal phenomena;DVS;accurate hand swipe motion detection;biologically inspired vision sensor;dynamic vision sensor;event-driven processing algorithms;graphic UI capable finger tip tracking;instantaneous responses;integrate-and-fire neurons;mobile devices;moving object detection;object edges;output events;real-time touchless hand gesture user interface;spatiotemporal correlation;touchless hand gesture UI;Computational efficiency;Neurons;Radio frequency;Thumb;Tracking;Voltage control;Gesture recognition;Neuromorphic processing;User Interface},
  owner     = {flo},
  timestamp = {2016.09.21},
}

@Article{Lefevre2014,
  author       = {Lef{\`e}vre, St{\'e}phanie and Vasquez, Dizan and Laugier, Christian},
  title        = {A survey on motion prediction and risk assessment for intelligent vehicles},
  journaltitle = {ROBOMECH Journal},
  date         = {2014-07-23},
  volume       = {1},
  number       = {1},
  pages        = {1},
  issn         = {2197-4225},
  doi          = {10.1186/s40648-014-0001-z},
  abstract     = {With the objective to improve road safety, the automotive industry is moving toward more ``intelligent'' vehicles. One of the major challenges is to detect dangerous situations and react accordingly in order to avoid or mitigate accidents. This requires predicting the likely evolution of the current traffic situation, and assessing how dangerous that future situation might be. This paper is a survey of existing methods for motion prediction and risk assessment for intelligent vehicles. The proposed classification is based on the semantics used to define motion and risk. We point out the tradeoff between model completeness and real-time constraints, and the fact that the choice of a risk assessment method is influenced by the selected motion model.},
  day          = {23},
  file         = {:pdf-files/Lefevre2014 - A Survey on Motion Prediction and Risk Assessment for Intelligent Vehicles.pdf:PDF},
  groups       = {Behaviour analysis},
  owner        = {flo},
  timestamp    = {2018.03.09},
}

@InProceedings{Lenz2017,
  author    = {D. Lenz and F. Diehl and M. T. Le and A. Knoll},
  title     = {Deep neural networks for {M}arkovian interactive scene prediction in highway scenarios},
  booktitle = {2017 IEEE Intelligent Vehicles Symposium (IV)},
  date      = {2017},
  pages     = {685--692},
  doi       = {10.1109/IVS.2017.7995797},
  abstract  = {In this paper, we compare different deep neural network approaches for motion prediction within a highway entrance scenario. The focus of our work lies on models that operate on limited history of data in order to fulfill the Markov property and be usable within an integrated prediction and motion planning framework for automated vehicles. We examine different model structures and feature combinations in order to find a model with a good tradeoff between accuracy and computational performance. We evaluate all models with standard metrics like the negative log-likelihood (NLL) and evaluate the performance of each model within a closed-loop simulation. We find a neural network only operating on spatial features of the current state to have the best closed-loop prediction performance, despite the NLL suggesting otherwise.},
  file      = {:pdf-files/Lenz2017 - Deep Neural Networks for Markovian Interactive Scene Prediction in Highway Scenarios.pdf:PDF},
  groups    = {Behaviour analysis},
  keywords  = {Markov processes;closed loop systems;neurocontrollers;path planning;road vehicles;Markovian interactive scene prediction;automated vehicles;closed-loop prediction performance;closed-loop simulation;deep neural networks;highway entrance scenario;motion planning framework;motion prediction;negative log-likelihood;Computational modeling;Data models;Feature extraction;Hidden Markov models;Neural networks;Predictive models;Trajectory},
  owner     = {flo},
  timestamp = {2017.10.12},
}

@Article{Levine2015,
  author       = {Sergey Levine and Chelsea Finn and Trevor Darrell and Pieter Abbeel},
  title        = {End-to-{E}nd {T}raining of {D}eep {V}isuomotor {P}olicies},
  journaltitle = {Journal of Machine Learning Research},
  date         = {2016},
  volume       = {17},
  number       = {1},
  pages        = {1334--1373},
  issn         = {1532-4435},
  url          = {http://dl.acm.org/citation.cfm?id=2946645.2946684},
  acmid        = {2946684},
  comment      = {interesting talk by the first author: https://www.youtube.com/watch?v=EtMyH_--vnU},
  file         = {:pdf-files/Levine2015 - End to End Training of Deep Visuomotor Policies.pdf:PDF},
  groups       = {ReinforcementLearning, Deep Neural Networks},
  issue_date   = {January 2016},
  keywords     = {neural networks, optimal control, reinforcement learning, vision},
  numpages     = {40},
  owner        = {flo},
  publisher    = {JMLR.org},
  timestamp    = {2016.10.12},
}

@InProceedings{Levinson2011,
  author    = {Jesse Levinson and Jake Askeland and Jan Becker and Jennifer Dolson and David Held and Soeren Kammel and J. Zico Kolter and Dirk Langer and Oliver Pink and Vaughan Pratt and Michael Sokolsky and Ganymed Stanek and David Stavens and Alex Teichman and Moritz Werling and Sebastian Thrun},
  title     = {Towards fully autonomous driving: Systems and algorithms},
  booktitle = {2011 {IEEE} Intelligent Vehicles Symposium ({IV})},
  year      = {2011},
  date      = {2011},
  publisher = {{IEEE}},
  pages     = {163--168},
  doi       = {10.1109/IVS.2011.5940562},
  file      = {:pdf-files/Levinson2011 - Towards Fully Autonomous Driving_ Systems and Algorithms.pdf:PDF},
  groups    = {Autonomous Driving},
  issn      = {1931-0587},
  keywords  = {computer vision;mobile robots;remotely operated vehicles;DARPA urban challenge;LIDAR;autonomous driving;closed-course competition;environment perception;obstacle classification;obstacle tracking;online localization;planning system;realtime system;recognition algorithm;robust autonomous operation;robust vehicle platform;software infrastructure;unpredictable traffic;Calibration;Laser beams;Planning;Software;Trajectory;Vehicle dynamics;Vehicles},
  owner     = {flo},
  timestamp = {2015.12.14},
}

@InProceedings{Levinson2010,
  author    = {Jesse Levinson and Sebastian Thrun},
  title     = {Robust vehicle localization in urban environments using probabilistic maps},
  booktitle = {{IEEE} International Conference on Robotics and Automation, {ICRA} 2010, Anchorage, Alaska, USA, 3-7 May 2010},
  date      = {2010},
  pages     = {4372--4378},
  doi       = {10.1109/ROBOT.2010.5509700},
  file      = {:pdf-files/Levinson2010 - Robust Vehicle Localization in Urban Environments Using Probabilistic Maps.pdf:PDF},
  groups    = {Localization},
  owner     = {flo},
  timestamp = {2015.12.14},
}

@InProceedings{Levy2013,
  author    = {S. D. Levy and S. Bajracharya and R.W. Gayler},
  title     = {Learning Behavior Hierarchies via High-Dimensional Sensor Projection},
  booktitle = {Learning Rich Representations from Low-Level Sensors: Papers from the 2013 AAAI Workshop},
  date      = {2013},
  editor    = {Marc Pickett},
  publisher = {AAAI Press},
  file      = {:pdf-files/Levy2013 - Learning Behavior Hierarchies Via High Dimensional Sensor Projection.pdf:PDF},
  groups    = {Vector Symbolic Architectures},
  owner     = {flo},
  timestamp = {2017.04.26},
}

@InProceedings{Levy2008,
  author    = {Levy, Simon D. and Gayler, Ross},
  title     = {Vector {S}ymbolic {A}rchitectures: {A} {N}ew {B}uilding {M}aterial for {A}rtificial {G}eneral {I}ntelligence},
  booktitle = {Proceedings of the 2008 Conference on Artificial General Intelligence 2008: Proceedings of the First AGI Conference},
  date      = {2008},
  publisher = {IOS Press},
  location  = {Amsterdam, The Netherlands, The Netherlands},
  isbn      = {978-1-58603-833-5},
  pages     = {414--418},
  url       = {http://dl.acm.org/citation.cfm?id=1566174.1566215},
  acmid     = {1566215},
  file      = {:pdf-files/Levy2008 - Vector Symbolic Architectures_ a New Building Material for Artificial General Intelligence.pdf:PDF},
  groups    = {Vector Symbolic Architectures},
  keywords  = {Associative Memory, Binary Spatter Codes, Connectionism, Distributed Representations, Holographic Reduced Representation, Vector Symbolic Architectures},
  numpages  = {5},
  owner     = {flo},
  timestamp = {2017.04.26},
}

@InProceedings{Li2012,
  author    = {Cheng-Han Li and Tobi Delbruck and Shih-Chii Liu},
  title     = {Real-time speaker identification using the {AEREAR}2 event-based silicon cochlea},
  booktitle = {2012 {IEEE} International Symposium on Circuits and Systems},
  year      = {2012},
  date      = {2012},
  publisher = {{IEEE}},
  pages     = {1159--1162},
  doi       = {10.1109/iscas.2012.6271438},
  url       = {https://ieeexplore.ieee.org/document/6271438/},
  file      = {:pdf-files/Li2012 - Real Time Speaker Identification Using the AEREAR2 Event Based Silicon Cochlea.pdf:PDF},
  groups    = {Neuromorphic Hardware},
  owner     = {flo},
  timestamp = {2016.01.18},
}

@Article{Li2015,
  author       = {Haojie Li and Fuming Sun and Lijuan Liu and Ling Wang},
  title        = {A novel traffic sign detection method via color segmentation and robust shape matching},
  journaltitle = {Neurocomputing},
  date         = {2015},
  volume       = {169},
  pages        = {77--88},
  note         = {Learning for Visual Semantic Understanding in Big DataESANN 2014Industrial Data Processing and AnalysisSelected papers from the 22nd European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning (ESANN 2014)Selected papers from the 11th World Congress on Intelligent Control and Automation (WCICA2014)},
  issn         = {0925-2312},
  doi          = {10.1016/j.neucom.2014.12.111},
  url          = {http://www.sciencedirect.com/science/article/pii/S0925231215006712},
  abstract     = {The robust and accurate detection of traffic signs is a challenging problem due to the many issues that are often encountered in real traffic video capturing such as the various weather conditions, shadows and partial occlusion. To address such adverse factors, in this paper, we propose a new traffic sign detection method by integrating color invariants based image segmentation and pyramid histogram of oriented gradients (PHOG) features based shape matching. Given the target image, we first extract its color invariants in Gaussian color model, and then segment the image into different regions to get the candidate regions of interests (ROIs) by clustering on the color invariants. Next, \{PHOG\} is adopted to represent the shape features of \{ROIs\} and support vector machine is used to identify the traffic signs. The traditional \{PHOG\} is sensitive to the cluttered background of traffic sign when extracting the object contour. To boost the discriminative power of PHOG, we propose introducing Chromatic-edge to enhance object contour while suppress the noises. Extensive experiments demonstrate that our method can robustly detect traffic signs under varying weather, shadow, occlusion and complex background conditions.},
  file         = {:pdf-files/Li2015 - A Novel Traffic Sign Detection Method Via Color Segmentation and Robust Shape Matching.pdf:PDF},
  groups       = {Object Recognition},
  keywords     = {Color invariants},
  owner        = {flo},
  timestamp    = {2016.07.20},
}

@Article{Lichtsteiner2008,
  author       = {Lichtsteiner, Patrick and Posch, Christoph and Delbruck, Tobi},
  title        = {A 128x128 120 dB 15 $\mu$s {L}atency {A}synchronous {T}emporal {C}ontrast {V}ision {S}ensor},
  journaltitle = {IEEE Journal of Solid-State Circuits},
  date         = {2008},
  volume       = {43},
  number       = {2},
  pages        = {566--576},
  issn         = {0018-9200},
  doi          = {10.1109/JSSC.2007.914337},
  comment      = {DVS reference},
  file         = {:pdf-files/Lichtsteiner2008 - A 128x128 120 DB 15 $$s Latency Asynchronous Temporal Contrast Vision Sensor.pdf:PDF},
  groups       = {Neuromorphic Vision, Neuromorphic Hardware},
  owner        = {flo},
  timestamp    = {2015.12.10},
}

@Article{Lieto2014,
  author       = {Antonio Lieto},
  title        = {A Computational Framework for Concept Representation in Cognitive Systems and Architectures: Concepts as Heterogeneous Proxytypes},
  journaltitle = {Procedia Computer Science},
  date         = {2014},
  volume       = {41},
  pages        = {6--14},
  issn         = {1877-0509},
  doi          = {10.1016/j.procs.2014.11.078},
  url          = {http://www.sciencedirect.com/science/article/pii/S1877050914015233},
  abstract     = {In this paper a possible general framework for the representation of concepts in cognitive artificial systems and cognitive architectures is proposed. The framework is inspired by the so called proxytype theory of concepts and combines it with the heterogeneity approach to concept representations, according to which concepts do not constitute a unitary phenomenon. The contribution of the paper is twofold: on one hand, it aims at providing a novel theoretical hypothesis for the debate about concepts in cognitive sciences by providing unexplored connections between different theories; on the other hand it is aimed at sketching a computational characterization of the problem of concept representation in cognitively inspired artificial systems and in cognitive architectures.},
  file         = {:pdf-files/Lieto2014 - A Computational Framework for Concept Representation in Cognitive Systems and Architectures_ Concepts As Heterogeneous Proxytypes.pdf:PDF},
  keywords     = {Knowledge Representation},
  owner        = {flo},
  timestamp    = {2017.04.05},
}

@InProceedings{Lim2014,
  author    = {H. Lim and J. Lim and H. J. Kim},
  title     = {Real-time 6-{DOF} monocular visual {SLAM} in a large-scale environment},
  booktitle = {2014 IEEE International Conference on Robotics and Automation (ICRA)},
  date      = {2014},
  pages     = {1532--1539},
  doi       = {10.1109/ICRA.2014.6907055},
  abstract  = {Real-time approach for monocular visual simultaneous localization and mapping (SLAM) within a large-scale environment is proposed. From a monocular video sequence, the proposed method continuously computes the current 6-DOF camera pose and 3D landmarks position. The proposed method successfully builds consistent maps from challenging outdoor sequences using a monocular camera as the only sensor, while existing approaches have utilized additional structural information such as camera height from the ground. By using a binary descriptor and metric-topological mapping, the system demonstrates real-time performance on a large-scale outdoor environment without utilizing GPUs or reducing input image size. The effectiveness of the proposed method is demonstrated on various challenging video sequences including the KITTI dataset and indoor video captured on a micro aerial vehicle.},
  comment   = {https://github.com/limhyon/vslam

https://www.youtube.com/watch?v=JyG1EeqCmHY},
  file      = {:pdf-files/Lim2014 - Real Time 6 DOF Monocular Visual SLAM in a Large Scale Environment.pdf:PDF},
  groups    = {Localization},
  issn      = {1050-4729},
  keywords  = {SLAM (robots);aerospace robotics;image sequences;microrobots;robot vision;video signal processing;3D landmarks position;6-DOF monocular visual SLAM;KITTI dataset;binary descriptor;camera height;camera pose;degrees-of-freedom;large-scale environment;metric-topological mapping;microaerial vehicle;monocular camera;monocular video sequence;simultaneous localization and mapping;structural information;Cameras;Feature extraction;Measurement;Optimization;Simultaneous localization and mapping;Three-dimensional displays;Visualization},
  owner     = {flo},
  timestamp = {2017.02.13},
}

@Article{Lim2000,
  author       = {Lim, Tjen-Sien and Loh, Wei-Yin and Shih, Yu-Shan},
  title        = {{A Comparison of Prediction Accuracy, Complexity, and Training Time of Thirty-Three Old and New Classification Algorithms}},
  journaltitle = {Machine Learning},
  date         = {2000},
  volume       = {40},
  number       = {3},
  pages        = {203--228},
  issn         = {1573-0565},
  doi          = {10.1023/A:1007608224229},
  abstract     = {Twenty-two decision tree, nine statistical, and two neural network algorithms are compared on thirty-two datasets in terms of classification accuracy, training time, and (in the case of trees) number of leaves. Classification accuracy is measured by mean error rate and mean rank of error rate. Both criteria place a statistical, spline-based, algorithm called POLYCLSSS at the top, although it is not statistically significantly different from twenty other algorithms. Another statistical algorithm, logistic regression, is second with respect to the two accuracy criteria. The most accurate decision tree algorithm is QUEST with linear splits, which ranks fourth and fifth, respectively. Although spline-based statistical algorithms tend to have good accuracy, they also require relatively long training times. POLYCLASS, for example, is third last in terms of median training time. It often requires hours of training compared to seconds for other algorithms. The QUEST and logistic regression algorithms are substantially faster. Among decision tree algorithms with univariate splits, C4.5, IND-CART, and QUEST have the best combinations of error rate and speed. But C4.5 tends to produce trees with twice as many leaves as those from IND-CART and QUEST.},
  file         = {:pdf-files/Lim2000 - A Comparison of Prediction Accuracy, Complexity, and Training Time of Thirty Three Old and New Classification Algorithms.pdf:PDF},
  groups       = {Machine Learning, DecisionTrees},
  owner        = {flo},
  timestamp    = {2016.02.09},
}

@Article{Liu2010,
  author               = {Liu, Shih-Chii and Delbruck, Tobi},
  title                = {{Neuromorphic sensory systems}},
  journaltitle         = {Current Opinion in Neurobiology},
  date                 = {2010},
  volume               = {20},
  number               = {3},
  pages                = {288--295},
  issn                 = {0959-4388},
  doi                  = {10.1016/j.conb.2010.03.007},
  abstract             = {{Biology provides examples of efficient machines which greatly outperform conventional technology. Designers in neuromorphic engineering aim to construct electronic systems with the same efficient style of computation. This task requires a melding of novel engineering principles with knowledge gleaned from neuroscience. We discuss recent progress in realizing neuromorphic sensory systems which mimic the biological retina and cochlea, and subsequent sensor processing. The main trends are the increasing number of sensors and sensory systems that communicate through asynchronous digital signals analogous to neural spikes; the improved performance and usability of these sensors; and novel sensory processing methods which capitalize on the timing of spikes from these sensors. Experiments using these sensors can impact how we think the brain processes sensory information.}},
  citeulike-article-id = {7300927},
  citeulike-linkout-0  = {http://dx.doi.org/10.1016/j.conb.2010.03.007},
  file                 = {:pdf-files/Liu2010 - Neuromorphic Sensory Systems.pdf:PDF},
  groups               = {Neuromorphic Hardware},
  keywords             = {ai, computation, engineering, function, neural, sensory},
  owner                = {flo},
  posted-at            = {2012-11-04 14:35:38},
  timestamp            = {2016.01.26},
}

@Book{Liu2002,
  author    = {S.-C. Liu and J. Kramer and G. Indiveri and T. Delbruck and R.J. Douglas},
  title     = {Analog {VLSI}:Circuits and Principles},
  date      = {2002},
  publisher = {MIT Press},
  groups    = {Neuromorphic Hardware},
  keywords  = {neuromorphic},
  owner     = {flo},
  timestamp = {2016.04.04},
}

@Article{Liu2014,
  author       = {Shih-Chii Liu and Andre van Schaik and Bradley A. Minch and Tobi Delbruck},
  title        = {{A}synchronous {B}inaural {S}patial {A}udition {S}ensor {W}ith 2 x 64 x 4 {C}hannel {O}utput},
  journal      = {{IEEE} Transactions on Biomedical Circuits and Systems},
  journaltitle = {IEEE Transactions on Biomedical Circuits and Systems},
  year         = {2014},
  date         = {2014},
  volume       = {8},
  number       = {4},
  pages        = {453--464},
  issn         = {1932-4545},
  doi          = {10.1109/tbcas.2013.2281834},
  file         = {:pdf-files/Liu2014 - Asynchronous Binaural Spatial Audition Sensor with 2 X 64 X 4 Channel Output.pdf:PDF},
  groups       = {Neuromorphic Hardware},
  keywords     = {CMOS integrated circuits;audio signal processing;biomedical measurement;cochlear implants;ear;hearing;medical signal processing;microphones;preamplifiers;pulse frequency modulation;speech;timing jitter;2P4M CMOS chip;64-stage cascaded analog second-order filter banks;AER;PFM;asynchronous binaural spatial audition sensor;auditory scene analysis;average power;biasing circuits;channel output;cochlea chip;computational cost;conventional cross-correlation approach;event timing jitter;event-driven source localization application;integrated event-based binaural silicon cochlea system;integrated microphone preamplifier;local DAC;peak output rates;power 14 mW;pulse-frequency modulated address-event representation outputs;quality factors;speech data rates;time 2 mus;voltage 200 mV;Computer architecture;Gain;Microphones;Silicon;System-on-chip;Transistors;Universal Serial Bus;Address-event representation (AER);audition;cochleas;localization;neuromorphic;spike-based},
  owner        = {flo},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  timestamp    = {2015.12.15},
}

@Article{Loeb2014,
  author       = {Loeb, Gerald E. and Fishel, Jeremy A.},
  title        = {Bayesian Action\&Perception: Representing the World in the Brain},
  journaltitle = {Frontiers in Neuroscience},
  date         = {2014},
  volume       = {8},
  pages        = {341},
  issn         = {1662-453X},
  doi          = {10.3389/fnins.2014.00341},
  abstract     = {Theories of perception seek to explain how sensory data are processed to identify previously experienced objects, but they usually do not consider the decisions and effort that goes into acquiring the sensory data. Identification of objects according to their tactile properties requires active exploratory movements. The sensory data thereby obtained depend on the details of those movements, which human subjects change rapidly and seemingly capriciously. Bayesian Exploration is an algorithm that uses prior experience to decide which next exploratory movement should provide the most useful data to disambiguate the most likely possibilities. In previous studies, a simple robot equipped with a biomimetic tactile sensor and operated according to Bayesian Exploration performed in a manner similar to and actually better than humans on a texture identification task. Expanding on this, "Bayesian Action\&Perception" refers to the construction and querying of an associative memory of previously experienced entities containing both sensory data and the motor programs that elicited them. We hypothesize that this memory can be queried i) to identify useful next exploratory movements during identification of an unknown entity ("action for perception") or ii) to characterize whether an unknown entity is fit for purpose ("perception for action") or iii) to recall what actions might be feasible for a known entity (Gibsonian affordance). The biomimetic design of this mechatronic system may provide insights into the neuronal basis of biological action and perception.},
  file         = {:pdf-files/Loeb2014 - Bayesian Action&Perception_ Representing the World in the Brain.pdf:PDF},
  groups       = {Neural Modelling},
  owner        = {flo},
  timestamp    = {2017.12.28},
}

@Article{Loiacono2010,
  author       = {D. Loiacono and P. L. Lanzi and J. Togelius and E. Onieva and D. A. Pelta and M. V. Butz and T. D. Lonneker and L. Cardamone and D. Perez and Y. Saez and M. Preuss and J. Quadflieg},
  title        = {The 2009 {S}imulated {C}ar {R}acing {C}hampionship},
  journaltitle = {IEEE Transactions on Computational Intelligence and AI in Games},
  date         = {2010},
  volume       = {2},
  number       = {2},
  pages        = {131--147},
  issn         = {1943-068X},
  doi          = {10.1109/TCIAIG.2010.2050590},
  abstract     = {In this paper, we overview the 2009 Simulated Car Racing Championship-an event comprising three competitions held in association with the 2009 IEEE Congress on Evolutionary Computation (CEC), the 2009 ACM Genetic and Evolutionary Computation Conference (GECCO), and the 2009 IEEE Symposium on Computational Intelligence and Games (CIG). First, we describe the competition regulations and the software framework. Then, the five best teams describe the methods of computational intelligence they used to develop their drivers and the lessons they learned from the participation in the championship. The organizers provide short summaries of the other competitors. Finally, we summarize the championship results, followed by a discussion about what the organizers learned about 1) the development of high-performing car racing controllers and 2) the organization of scientific competitions.},
  file         = {:pdf-files/Loiacono2010 - The 2009 Simulated Car Racing Championship.pdf:PDF},
  groups       = {Autonomous Driving},
  keywords     = {evolutionary computation;learning (artificial intelligence);sport;2009 ACM Genetic and Evolutionary Computation Conference;2009 IEEE Congress on Evolutionary Computation;2009 IEEE Symposium on Computational Intelligence and Games;2009 Simulated Car Racing Championship;competition regulations;high-performing car racing controllers;scientific competitions;Artificial intelligence;Computational Intelligence Society;Computational intelligence;Computational modeling;Computer science;Discrete event simulation;Evolutionary computation;Genetics;Leg;Technological innovation;Car racing;competitions},
  owner        = {flo},
  timestamp    = {2017.01.11},
}

@Article{Long2009,
  author       = {Long, Philip M. and Servedio, Rocco A.},
  title        = {Random classification noise defeats all convex potential boosters},
  journaltitle = {Machine Learning},
  date         = {2009},
  volume       = {78},
  number       = {3},
  pages        = {287--304},
  issn         = {1573-0565},
  doi          = {10.1007/s10994-009-5165-z},
  abstract     = {A broad class of boosting algorithms can be interpreted as performing coordinate-wise gradient descent to minimize some potential function of the margins of a data set. This class includes AdaBoost, LogitBoost, and other widely used and well-studied boosters. In this paper we show that for a broad class of convex potential functions, any such boosting algorithm is highly susceptible to random classification noise. We do this by showing that for any such booster and any nonzero random classification noise rate $\eta$, there is a simple data set of examples which is efficiently learnable by such a booster if there is no noise, but which cannot be learned to accuracy better than 1/2 if there is random classification noise at rate $\eta$. This holds even if the booster regularizes using early stopping or a bound on the L 1 norm of the voting weights. This negative result is in contrast with known branching program based boosters which do not fall into the convex potential function framework and which can provably learn to high accuracy in the presence of random classification noise.},
  file         = {:pdf-files/Long2009 - Random Classification Noise Defeats All Convex Potential Boosters.pdf:PDF},
  groups       = {Machine Learning, Boosting},
  owner        = {flo},
  timestamp    = {2016.02.09},
}

@Misc{Thesis_writing,
  author    = {LSR},
  title     = {Thesis Writing},
  file      = {:pdf-files/Thesis_writing - Thesis Writing.pdf:PDF},
  groups    = {Non-Technical},
  owner     = {flo},
  timestamp = {2017.06.26},
}

@InProceedings{Lu2016,
  author    = {Lu, Cewu and Krishna, Ranjay and Bernstein, Michael and Fei-Fei, Li},
  booktitle = {European Conference on Computer Vision},
  date      = {2016},
  title     = {Visual {R}elationship {D}etection with {L}anguage {P}riors},
  file      = {:pdf-files/Lu2016 - Visual Relationship Detection with Language Priors.pdf:PDF},
  groups    = {Image Caption Generation},
  owner     = {flo},
  timestamp = {2017.10.18},
}

@InProceedings{Lu2014,
  author    = {Lu, David V. and Hershberger, Dave and Smart, William D.},
  title     = {Layered {C}ostmaps for {C}ontext-{S}ensitive {N}avigation},
  booktitle = {Proceedings of the {IEEE/RSJ} International Conference on Intelligent Robots and Systems ({IROS})},
  date      = {2014},
  location  = {Chicago, USA},
  file      = {:pdf-files/Lu2014 - Layered Costmaps for Context Sensitive Navigation.pdf:PDF},
  groups    = {Robotics},
  owner     = {flo},
  timestamp = {2016.01.28},
}

@InProceedings{Mueller2011,
  author    = {Georg R. M{\"u}ller and J{\"o}rg Conradt},
  title     = {A miniature low-power sensor system for real time 2D visual tracking of {LED} markers},
  booktitle = {2011 {IEEE} International Conference on Robotics and Biomimetics},
  year      = {2011},
  date      = {2011},
  language  = {en},
  publisher = {{IEEE}},
  doi       = {10.1109/robio.2011.6181669},
  file      = {:pdf-files/Mueller2011 - A Miniature Low Power Sensor System for Real Time 2D Visual Tracking of LED Markers.pdf:PDF},
  groups    = {Neuromorphic Robotics},
  owner     = {flo},
  timestamp = {2017.11.22},
}

@Article{Ma2014,
  author       = {Wei Ji Ma and Mehrdad Jazayeri},
  date         = {2014},
  journaltitle = {Annual Review of Neuroscience},
  title        = {Neural Coding of Uncertainty and Probability},
  doi          = {10.1146/annurev-neuro-071013-014017},
  eprint       = {http://dx.doi.org/10.1146/annurev-neuro-071013-014017},
  note         = {PMID: 25032495},
  number       = {1},
  pages        = {205--220},
  volume       = {37},
  abstract     = {Organisms must act in the face of sensory, motor, and reward uncertainty stemming from a pandemonium of stochasticity and missing information. In many tasks, organisms can make better decisions if they have at their disposal a representation of the uncertainty associated with task-relevant variables. We formalize this problem using Bayesian decision theory and review recent behavioral and neural evidence that the brain may use knowledge of uncertainty, confidence, and probability.},
  file         = {:pdf-files/Ma2014 - Neural Coding of Uncertainty and Probability.pdf:PDF},
  groups       = {Biology, Neural Modelling},
  owner        = {flo},
  timestamp    = {2016.04.13},
}

@Article{Maass1997,
  author       = {Maass, Wofgang},
  title        = {{Networks of Spiking Neurons: The Third Generation of Neural Network Models}},
  journal      = {Neural Networks},
  journaltitle = {Neural Networks},
  year         = {1997},
  date         = {1997},
  volume       = {14},
  number       = {4},
  pages        = {1659--1671},
  issn         = {0893-6080},
  doi          = {10.1016/S0893-6080(97)00011-7},
  url          = {http://www.sciencedirect.com/science/article/pii/S0893608097000117},
  acmid        = {281637},
  file         = {:pdf-files/Maass1997 - Networks of Spiking Neurons_ the Third Generation of Neural Network Models.pdf:PDF},
  groups       = {Spiking Neural Networks},
  issue_date   = {Dec. 1997},
  keywords     = {computational complexity, integrate-and-fire neutron, lower bounds, sigmoidal neural nets, spiking neuron},
  location     = {San Diego, CA, USA},
  numpages     = {13},
  owner        = {flo},
  publisher    = {Society for Computer Simulation International},
  timestamp    = {2016.02.03},
}

@Article{MacNeil2011,
  author       = {David MacNeil and Chris Eliasmith},
  title        = {Fine-Tuning and the Stability of Recurrent Neural Networks},
  journal      = {{PLoS} {ONE}},
  journaltitle = {PLoS One},
  year         = {2011},
  date         = {2011},
  editor       = {Eleni Vasilaki},
  volume       = {6},
  number       = {9},
  pages        = {1--16},
  doi          = {10.1371/journal.pone.0022885},
  abstract     = {A central criticism of standard theoretical approaches to constructing stable, recurrent model networks is that the synaptic connection weights need to be finely-tuned. This criticism is severe because proposed rules for learning these weights have been shown to have various limitations to their biological plausibility. Hence it is unlikely that such rules are used to continuously fine-tune the network in vivo. We describe a learning rule that is able to tune synaptic weights in a biologically plausible manner. We demonstrate and test this rule in the context of the oculomotor integrator, showing that only known neural signals are needed to tune the weights. We demonstrate that the rule appropriately accounts for a wide variety of experimental results, and is robust under several kinds of perturbation. Furthermore, we show that the rule is able to achieve stability as good as or better than that provided by the linearly optimal weights often used in recurrent models of the integrator. Finally, we discuss how this rule can be generalized to tune a wide variety of recurrent attractor networks, such as those found in head direction and path integration systems, suggesting that it may be used to tune a wide variety of stable neural systems.},
  file         = {:pdf-files/MacNeil2011 - Fine Tuning and the Stability of Recurrent Neural Networks.pdf:PDF},
  groups       = {Nengo},
  owner        = {flo},
  publisher    = {Public Library of Science},
  timestamp    = {2017.11.23},
}

@PhdThesis{Mahowald1992,
  author      = {Misha Mahowald},
  title       = {{VLSI} analogs of neuronal visual processing: a synthesis of form and function},
  institution = {California Institute of Technology},
  date        = {1992},
  file        = {:pdf-files/Mahowald1992 - VLSI Analogs of Neuronal Visual Processing_ a Synthesis of Form and Function.pdf:PDF},
  groups      = {Neuromorphic Hardware},
  owner       = {flo},
  timestamp   = {2016.03.29},
}

@Article{Marr2013,
  author       = {Marr, B. and Degnan, B. and Hasler, P. and Anderson, D.},
  title        = {{Scaling Energy Per Operation via an Asynchronous Pipeline}},
  journaltitle = {IEEE Transactions on Very Large Scale Integration (VLSI) Systems},
  date         = {2013},
  volume       = {21},
  number       = {1},
  pages        = {147--151},
  issn         = {1063-8210},
  doi          = {10.1109/TVLSI.2011.2178126},
  abstract     = {Statistical analysis of computations per unit energy in processors over the last 30 years is given that illustrates a sharp reduction in the rate of energy efficiency improvements over the last several years resulting in the formation of an asymptotic "wall" with our dataset; we use the measure of giga multiply accumulates per Joule. We have developed an energy model which takes into account the realities of scaling, specifically for asynchronous systems. Studies of an energy efficient asynchronous pipeline show fabricated results of 17 Giga Operations per Joule in 0.6 $\mu$m at subthreshold when fully pipelined, and simulations at a more modern 65 nm process show a further order of magnitude improvement on that.},
  file         = {:pdf-files/Marr2013 - Scaling Energy Per Operation Via an Asynchronous Pipeline.pdf:PDF},
  groups       = {Neuromorphic Hardware},
  keywords     = {asynchronous circuits;low-power electronics;microprocessor chips;statistical analysis;asymptotic wall;asynchronous pipeline;energy efficiency improvement;energy scaling;processor;size 65 nm;statistical analysis;Adders;Delay;Logic gates;Pipelines;Program processors;Solid state circuits;Very large scale integration;Asynchronous circuits;digital integrated circuits;energy efficiency;integrated circuit modeling;performance analysis;power consumption},
  owner        = {flo},
  timestamp    = {2016.02.16},
}

@Article{Marti2015,
  author       = {{Mart{\'i}}, D. and {Rigotti}, M. and {Seok}, M. and {Fusi}, S.},
  title        = {{Energy-efficient neuromorphic classifiers}},
  journaltitle = {ArXiv e-prints},
  date         = {2015},
  eprint       = {1507.00235},
  eprintclass  = {q-bio.NC},
  eprinttype   = {arXiv},
  file         = {:pdf-files/Marti2015 - Energy Efficient Neuromorphic Classifiers.pdf:PDF},
  groups       = {Neuromorphic Computing},
  keywords     = {Quantitative Biology - Neurons and Cognition, Computer Science - Neural and Evolutionary Computing},
  owner        = {flo},
  timestamp    = {2016.10.12},
}

@Article{Masquelier2007,
  author       = {Timoth{\'{e}}e Masquelier and Rudy Guyonneau and Simon J. Thorpe},
  title        = {Spike Timing Dependent Plasticity Finds the Start of Repeating Patterns in Continuous Spike Trains},
  journal      = {{PLoS} {ONE}},
  journaltitle = {PLoS ONE},
  year         = {2008},
  date         = {2007},
  editor       = {Olaf Sporns},
  volume       = {3},
  number       = {1},
  pages        = {e1377},
  issn         = {1932-6203},
  doi          = {10.1371/journal.pone.0001377},
  url          = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2147052/},
  abstract     = {Experimental studies have observed Long Term synaptic Potentiation (LTP) when a presynaptic neuron fires shortly before a postsynaptic neuron, and Long Term Depression (LTD) when the presynaptic neuron fires shortly after, a phenomenon known as Spike Timing Dependant Plasticity (STDP). When a neuron is presented successively with discrete volleys of input spikes STDP has been shown to learn 'early spike patterns', that is to concentrate synaptic weights on afferents that consistently fire early, with the result that the postsynaptic spike latency decreases, until it reaches a minimal and stable value. Here, we show that these results still stand in a continuous regime where afferents fire continuously with a constant population rate. As such, STDP is able to solve a very difficult computational problem: to localize a repeating spatio-temporal spike pattern embedded in equally dense 'distractor' spike trains. STDP thus enables some form of temporal coding, even in the absence of an explicit time reference. Given that the mechanism exposed here is simple and cheap it is hard to believe that the brain did not evolve to use it.},
  comment      = {07-PONE-RA-02431R1[PII]
18167538[pmid]},
  file         = {:pdf-files/Masquelier2007 - Spike Timing Dependent Plasticity Finds the Start of Repeating Patterns in Continuous Spike Trains.pdf:PDF},
  groups       = {Spiking Neural Networks},
  location     = {San Francisco, USA},
  owner        = {flo},
  publisher    = {Public Library of Science ({PLoS})},
  timestamp    = {2018.04.04},
}

@Article{Mayer2015,
  author       = {Nikolaus Mayer and Eddy Ilg and Philip H{\"a}usser and Philipp Fischer and Daniel Cremers and Alexey Dosovitskiy and Thomas Brox},
  title        = {A {L}arge {D}ataset to {T}rain {C}onvolutional {N}etworks for {D}isparity, {O}ptical {F}low, and {S}cene {F}low {E}stimation},
  journaltitle = {Computing Research Repository (CoRR)},
  date         = {2015},
  volume       = {abs/1512.02134},
  url          = {http://arxiv.org/abs/1512.02134},
  file         = {:pdf-files/Mayer2015 - A Large Dataset to Train Convolutional Networks for Disparity, Optical Flow, and Scene Flow Estimation.pdf:PDF},
  groups       = {Datasets},
  owner        = {flo},
  timestamp    = {2016.07.14},
}

@Article{Mayor2010h,
  author       = {Mayor, J. and Plunkett, K.},
  title        = {{{A} neurocomputational account of taxonomic responding and fast mapping in early word learning}},
  journaltitle = {Psychological Review},
  year         = {2010},
  date         = {2010},
  volume       = {117},
  number       = {1},
  pages        = {1--31},
  doi          = {10.1037/a0018130},
  file         = {:pdf-files/Mayor2010h - A Neurocomputational Account of Taxonomic Responding and Fast Mapping in Early Word Learning.pdf:PDF},
  groups       = {Neuroscience},
  owner        = {flo},
  publisher    = {American Psychological Association ({APA})},
  timestamp    = {2017.03.24},
}

@Article{McCulloch1943,
  author       = {Warren S. McCulloch and Walter Pitts},
  title        = {A logical calculus of the ideas immanent in nervous activity},
  journaltitle = {The Bulletin of Mathematical Biophysics},
  year         = {1943},
  date         = {1943},
  volume       = {5},
  number       = {4},
  pages        = {115--133},
  doi          = {10.1007/bf02478259},
  file         = {:pdf-files/McCulloch1988 - Neurocomputing_ Foundations of Research.pdf:PDF},
  groups       = {Machine Learning, Neural Networks},
  numpages     = {13},
  owner        = {flo},
  publisher    = {Springer Nature},
  timestamp    = {2016.02.08},
}

@InProceedings{Mead90,
  author    = {Carver Mead},
  title     = {Neuromorphic electronic systems},
  booktitle = {Proceedings of the IEEE},
  date      = {1990},
  volume    = {78},
  number    = {10},
  pages     = {1629--1636},
  file      = {:pdf-files/Mead90 - Neuromorphic Electronic Systems.pdf:PDF},
  groups    = {Neuromorphic Hardware},
  owner     = {flo},
  timestamp = {2016.01.18},
}

@Book{Mead1989,
  author    = {Mead, Carver},
  title     = {{A}nalog {VLSI} and {N}eural {S}ystems},
  date      = {1989},
  publisher = {Addison-Wesley Longman Publishing Co., Inc.},
  location  = {Boston, MA, USA},
  isbn      = {0-201-05992-4},
  groups    = {Neuromorphic Hardware},
  owner     = {flo},
  timestamp = {2016.03.10},
}

@InCollection{Meftah2013,
  author    = {Meftah, Boudjelal and L{\'e}zoray, Olivier and Chaturvedi, Soni and Khurshid, AleefiaA. and Benyettou, Abdelkader},
  title     = {{Image Processing with Spiking Neuron Networks}},
  booktitle = {Artificial Intelligence, Evolutionary Computing and Metaheuristics},
  date      = {2013},
  editor    = {Yang, Xin-She},
  language  = {English},
  volume    = {427},
  series    = {Studies in Computational Intelligence},
  publisher = {Springer Berlin Heidelberg},
  isbn      = {978-3-642-29693-2},
  pages     = {525--544},
  doi       = {10.1007/978-3-642-29694-9_20},
  file      = {:pdf-files/Meftah2013 - Image Processing with Spiking Neuron Networks.pdf:PDF},
  groups    = {Neuromorphic Vision, Spiking Neural Networks},
  owner     = {flo},
  timestamp = {2016.01.21},
}

@InProceedings{Merolla2011,
  author    = {P. Merolla and J. Arthur and F. Akopyan and N. Imam and R. Manohar and D. S. Modha},
  title     = {A digital neurosynaptic core using embedded crossbar memory with 45pJ per spike in 45nm},
  booktitle = {2011 IEEE Custom Integrated Circuits Conference (CICC)},
  date      = {2011},
  pages     = {1--4},
  doi       = {10.1109/CICC.2011.6055294},
  abstract  = {The grand challenge of neuromorphic computation is to develop a flexible brain-like architecture capable of a wide array of real-time applications, while striving towards the ultra-low power consumption and compact size of the human brain-within the constraints of existing silicon and post-silicon technologies. To this end, we fabricated a key building block of a modular neuromorphic architecture, a neurosynaptic core, with 256 digital integrate-and-fire neurons and a 1024x256 bit SRAM crossbar memory for synapses using IBM's 45nm SOI process. Our fully digital implementation is able to leverage favorable CMOS scaling trends, while ensuring one-to-one correspondence between hardware and software. In contrast to a conventional von Neumann architecture, our core tightly integrates computation (neurons) alongside memory (synapses), which allows us to implement efficient fan-out (communication) in a naturally parallel and event-driven manner, leading to ultra-low active power consumption of 45pJ/spike. The core is fully configurable in terms of neuron parameters, axon types, and synapse states and is thus amenable to a wide range of applications. As an example, we trained a restricted Boltzmann machine offline to perform a visual digit recognition task, and mapped the learned weights to our chip.},
  file      = {:pdf-files/Merolla2011 - A Digital Neurosynaptic Core Using Embedded Crossbar Memory with 45pJ Per Spike in 45nm.pdf:PDF},
  groups    = {TrueNorth},
  issn      = {0886-5930},
  keywords  = {CMOS digital integrated circuits;SRAM chips;low-power electronics;neural chips;CMOS scaling trends;SRAM crossbar memory;axon types;digit recognition task;digital integrate-and-fire neurons;digital neurosynaptic core;embedded crossbar memory;modular neuromorphic architecture;neuron parameters;restricted Boltzmann machine;silicon-on-insulator;size 45 nm;synapse states;von Neumann architecture;Computational modeling;Computer architecture;Hardware;Nerve fibers;Neuromorphics;Software},
  owner     = {flo},
  timestamp = {2017.12.20},
}

@Article{Meyer2016,
  author       = {Dominik Meyer and Johannes Feldmaier and Hao Shen},
  title        = {Reinforcement {L}earning in {}Conflicting {E}nvironments for {A}utonomous {V}ehicles},
  journaltitle = {arXiv e-prints},
  date         = {2016},
  file         = {:pdf-files/Meyer2016 - Reinforcement Learning in Conflicting Environments for Autonomous Vehicles.pdf:PDF},
  groups       = {ReinforcementLearning},
  owner        = {flo},
  timestamp    = {2016.10.27},
}

@InCollection{Mikolov2013,
  author    = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  title     = {Distributed Representations of Words and Phrases and their Compositionality},
  booktitle = {Advances in Neural Information Processing Systems 26},
  date      = {2013},
  editor    = {C. J. C. Burges and L. Bottou and M. Welling and Z. Ghahramani and K. Q. Weinberger},
  publisher = {Curran Associates, Inc.},
  pages     = {3111--3119},
  url       = {http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf},
  file      = {:pdf-files/Mikolov2013 - Distributed Representations of Words and Phrases and Their Compositionality.pdf:PDF},
  groups    = {Word Embedding, Vector Symbolic Architectures, Deep Neural Networks},
  owner     = {flo},
  timestamp = {2017.06.29},
}

@Book{Minsky1969,
  author    = {M. Minsky and S. Papert},
  title     = {Perceptrons},
  date      = {1969},
  publisher = {Cambridge, MA: MIT Press},
  groups    = {Neural Networks},
  owner     = {flo},
  timestamp = {2016.02.10},
}

@Article{Mirus2018a,
  author       = {Florian Mirus and Cristian Axenie and Terrence C. Stewart and J{\"o}rg Conradt},
  title        = {Neuromorphic sensorimotor adaptation for robotic mobile manipulation: From sensing to behaviour},
  journaltitle = {Cognitive Systems Research},
  date         = {2018},
  volume       = {50},
  pages        = {52--66},
  issn         = {1389-0417},
  doi          = {10.1016/j.cogsys.2018.03.006},
  url          = {http://www.sciencedirect.com/science/article/pii/S1389041717300955},
  abstract     = {We propose a neuromorphic approach to perception, reasoning and motor control using Spiking Neural Networks in mobile robotics. We demonstrate this by using a mobile robotic manipulator solving a pick-and-place task. All sensory data is provided by spike-based silicon retina cameras - eDVS (embedded Dynamic Vision Sensor) - and all reasoning and motor control is implemented in Spiking Neural Networks. For the given scenario, the robot is capable of detecting a sequence of objects blinking at different frequencies, finding one object that is not in the right place of the sequence, picking up this object and moving it to its correct position. Such a scenario demonstrates how to build large-scale networks solving a high-level cognitive task by combining several smaller networks responsible for low-level tasks. Importantly, here we focus only on generating a neural network that is capable of performing the task. This will be the basis of future work using neural network learning algorithms to improve task performance. The long-term goal is to learn sophisticated behaviours by experience while at the same time being able to introduce expert knowledge for intermediate tasks that can be used to initialize the network or to speed up the learning process.},
  file         = {:pdf-files/Mirus2018a - Neuromorphic Sensorimotor Adaptation for Robotic Mobile Manipulation_ from Sensing to Behaviour.pdf:PDF},
  groups       = {Neuromorphic Robotics},
  keywords     = {Mobile robotics, Spiking Neural Networks, Cognitive robotics, Neuromorphic sensing},
  owner        = {flo},
  timestamp    = {2018.03.29},
}

@InProceedings{Mirus2018,
  author    = {Florian Mirus and Terrence C. Stewart and J\"org Conradt},
  title     = {Towards cognitive automotive environment modelling: reasoning based on vector representations},
  booktitle = {26th European Symposium on Artificial Neural Networks, {ESANN} 2018, Bruges, Belgium},
  date      = {2018},
  pages     = {55--60},
  abstract  = {In this paper, we propose a novel approach to knowledge representation for automotive environment modelling based on Vector Symbolic Architectures (VSAs). We build a vector representation describing structured information and relations within the current scene based on high-level object-lists perceived by individual sensors. Such a representation can be applied to different tasks with little modifications. In a sample instantiation, we focus on two example tasks, namely driving context classification and simple behavior prediction, to demonstrate the general applicability of our approach. Allowing efficient implementation in Spiking Neural Networks (SNNs), we envision to improve task performance of our approach through online-learning.},
  file      = {:pdf-files/Mirus2018 - Towards Cognitive Automotive Environment Modelling_ Reasoning Based on Vector Representations.pdf:PDF},
  owner     = {flo},
  timestamp = {2018.03.05},
  year      = {2018},
}

@Book{Mitchell1997,
  author    = {Mitchell, Thomas M.},
  title     = {Machine Learning},
  date      = {1997},
  edition   = {1},
  publisher = {McGraw-Hill, Inc.},
  location  = {New York, NY, USA},
  isbn      = {9780070428072},
  file      = {:pdf-files/Mitchell1997 - Machine Learning.pdf:PDF},
  groups    = {Machine Learning},
  owner     = {flo},
  timestamp = {2016.01.28},
}

@Article{Mnih2016,
  author       = {Volodymyr Mnih and Adri{\`a} Puigdom{\`e}nech Badia and Mehdi Mirza and Alex Graves and Timothy P. Lillicrap and Tim Harley and David Silver and Koray Kavukcuoglu},
  title        = {Asynchronous {M}ethods for {D}eep {R}einforcement {L}earning},
  journaltitle = {Computing Research Repository (CoRR)},
  date         = {2016},
  volume       = {abs/1602.01783},
  url          = {http://arxiv.org/abs/1602.01783},
  file         = {:pdf-files/Mnih2016 - Asynchronous Methods for Deep Reinforcement Learning.pdf:PDF},
  groups       = {ReinforcementLearning, Deep Neural Networks},
  owner        = {flo},
  timestamp    = {2016.11.03},
}

@Article{Mnih2015,
  author       = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  title        = {Human-level control through deep reinforcement learning},
  journaltitle = {Nature},
  date         = {2015},
  volume       = {518},
  number       = {7540},
  pages        = {529--533},
  issn         = {0028-0836},
  doi          = {10.1038/nature14236},
  comment      = {Nature paper by DeepMind on reinforcement learning directly from sensor input to actions to play atari},
  file         = {:pdf-files/Mnih2015 - Human Level Control through Deep Reinforcement Learning.pdf:PDF},
  groups       = {ReinforcementLearning, Deep Neural Networks},
  owner        = {flo},
  publisher    = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  timestamp    = {2016.10.19},
}

@Article{Mohan2014,
  author       = {{Mohan}, R.},
  title        = {Deep Deconvolutional Networks for Scene Parsing},
  journaltitle = {ArXiv e-prints},
  date         = {2014},
  eprint       = {1411.4101},
  eprintclass  = {stat.ML},
  eprinttype   = {arXiv},
  file         = {:pdf-files/Mohan2014 - Deep Deconvolutional Networks for Scene Parsing.pdf:PDF},
  groups       = {Deep Neural Networks},
  keywords     = {Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning},
  owner        = {flo},
  timestamp    = {2016.06.10},
}

@Article{Moore1998,
  author       = {G. E. Moore},
  title        = {{Cramming More Components Onto Integrated Circuits}},
  journaltitle = {Proceedings of the IEEE},
  date         = {1998},
  volume       = {86},
  number       = {1},
  pages        = {82--85},
  issn         = {0018-9219},
  doi          = {10.1109/JPROC.1998.658762},
  abstract     = {Not Available},
  comment      = {Moore's Law: the number of transistors in a dense integrated circuit doubles approximately every two years},
  file         = {:pdf-files/Moore1998 - Cramming More Components onto Integrated Circuits.pdf:PDF},
  groups       = {Computing and GPU},
  keywords     = {Aerospace electronics;Costs;Home computing;Integrated circuit reliability;Integrated circuit technology;Portable computers;Semiconductor films;Space technology;Switches;Telephony},
  owner        = {flo},
  timestamp    = {2016.03.10},
}

@InProceedings{Moore2012,
  author    = {S. W. Moore and P. J. Fox and S. J. T. Marsh and A. T. Markettos and A. Mujumdar},
  title     = {Bluehive - A field-programable custom computing machine for extreme-scale real-time neural network simulation},
  booktitle = {Field-Programmable Custom Computing Machines (FCCM), 2012 IEEE 20th Annual International Symposium on},
  date      = {2012},
  pages     = {133--140},
  doi       = {10.1109/FCCM.2012.32},
  abstract  = {Bluehive is a custom 64-FPGA machine targeted at scientific simulations with demanding communication requirements. Bluehive is designed to be extensible with a reconfigurable communication topology suited to algorithms with demanding high-bandwidth and low-latency communication, something which is unattainable with commodity GPGPUs and CPUs. We demonstrate that a spiking neuron algorithm can be efficiently mapped to Bluehive using Bluespec System Verilog by taking a communication-centric approach. This contrasts with many FPGA-based neural systems which are very focused on parallel computation, resulting in inefficient use of FPGA resources. Our design allows 64k neurons with 64M synapses per FPGA and is scalable to a large number of FPGAs.},
  file      = {:pdf-files/Moore2012 - Bluehive a Field Programable Custom Computing Machine for Extreme Scale Real Time Neural Network Simulation.pdf:PDF},
  groups    = {Neuromorphic Hardware},
  keywords  = {electronic engineering computing;field programmable gate arrays;graphics processing units;hardware description languages;neural nets;64-FPGA machine;Bluespec system Verilog;CPU;FPGA resources;FPGA-based neural systems;GPGPU;communication-centric approach;extreme-scale real-time neural network simulation;field-programable custom computing machine;high-bandwidth communication;low-latency communication;reconfigurable communication topology;spiking neuron algorithm;Bandwidth;Delay;Equations;Field programmable gate arrays;Mathematical model;Neurons;Programming;FPGA;neural network;simulation},
  owner     = {flo},
  timestamp = {2016.03.10},
}

@Book{Moravec1988,
  author    = {Moravec, Hans},
  title     = {Mind {C}hildren: {T}he {F}uture of {R}obot and {H}uman {I}ntelligence},
  date      = {1988},
  publisher = {Harvard University Press},
  location  = {Cambridge, MA, USA},
  isbn      = {0-674-57616-0},
  comment   = {Reference for Moracev's paradox: 

"Encoded in the large, highly evolved sensory and motor portions of the human brain is a billion years of experience about the nature of the world and how to survive in it. The deliberate process we call reasoning is, I believe, the thinnest veneer of human thought, effective only because it is supported by this much older and much more powerful, though usually unconscious, sensorimotor knowledge. We are all prodigious olympians in perceptual and motor areas, so good that we make the difficult look easy. Abstract thought, though, is a new trick, perhaps less than 100 thousand years old. We have not yet mastered it. It is not all that intrinsically difficult; it just seems so when we do it."},
  groups    = {Machine Learning},
  owner     = {flo},
  timestamp = {2018.01.10},
}

@InProceedings{Mueggler2014,
  author    = {Elias Mueggler and Basil Huber and Davide Scaramuzza},
  title     = {Event-based, 6-{DOF} pose tracking for high-speed maneuvers},
  booktitle = {2014 {IEEE/RSJ} International Conference on Intelligent Robots and Systems, Chicago, IL, USA, September 14-18, 2014},
  date      = {2014},
  pages     = {2761--2768},
  doi       = {10.1109/IROS.2014.6942940},
  file      = {:pdf-files/Mueggler2014 - Event Based, 6 DOF Pose Tracking for High Speed Maneuvers.pdf:PDF},
  groups    = {Neuromorphic Robotics, Neuromorphic Vision, Neuromorphic Hardware},
  owner     = {flo},
  timestamp = {2016.01.18},
}

@Unpublished{Mueggler2016,
  author    = {Elias Mueggler and Henri Rebecq and Guillermo Gallego and Tobi Delbruck and Davide Scaramuzza},
  title     = {The {E}vent-{C}amera {D}ataset and {S}imulator: {E}vent-based {D}ata for {P}ose {E}stimation, {V}isual {O}dometry, and {SLAM}},
  date      = {2016},
  note      = {under review in arXiv},
  url       = {http://rpg.ifi.uzh.ch/davis_data.html},
  file      = {:pdf-files/Mueggler2016 - The Event Camera Dataset and Simulator_ Event Based Data for Pose Estimation, Visual Odometry, and SLAM.pdf:PDF},
  groups    = {Neuromorphic Vision},
  owner     = {flo},
  timestamp = {2016.11.03},
}

@Article{Mulas2016,
  author       = {Mulas, Marcello and Waniek, Nicolai and Conradt, Jorg},
  title        = {Hebbian plasticity realigns grid cell activity with external sensory cues in continuous attractor models},
  journaltitle = {Frontiers in Computational Neuroscience},
  date         = {2016},
  volume       = {10},
  number       = {13},
  issn         = {1662-5188},
  doi          = {10.3389/fncom.2016.00013},
  abstract     = {After the discovery of grid cells, which are an essential component to understand how the mammalian brain encodes spatial information, three main classes of computational models were proposed in order to explain their working principles. Amongst them, the one based on continuous attractor networks (CAN), is promising in terms of biological plausibility and suitable for robotic applications. However, in its current formulation, it is unable to reproduce important electrophysiological findings and cannot be used to perform path integration for long periods of time. In fact, in absence of an appropriate resetting mechanism, the accumulation of errors over time due to the noise intrinsic in velocity estimation and neural computation prevents CAN models to reproduce stable spatial grid patterns. In this paper, we propose an extension of the CAN model using Hebbian plasticity to anchor grid cell activity to environmental landmarks. To validate our approach we used as input to the neural simulations both artificial data and real data recorded from a robotic setup. The additional neural mechanism can not only anchor grid patterns to external sensory cues but also recall grid patterns generated in previously explored environments. These results might be instrumental for next generation bio-inspired robotic navigation algorithms that take advantage of neural computation in order to cope with complex and dynamic environments.},
  file         = {:pdf-files/Mulas2016 - Hebbian Plasticity Realigns Grid Cell Activity with External Sensory Cues in Continuous Attractor Models.pdf:PDF},
  groups       = {Biology, Neural Modelling},
  owner        = {flo},
  timestamp    = {2016.04.06},
}

@Article{Muller2001,
  author       = {Muller, K. and Mika, S. and Ratsch, G. and Tsuda, K. and Scholkopf, Bernhard},
  title        = {An introduction to kernel-based learning algorithms},
  journaltitle = {Neural Networks, IEEE Transactions on},
  date         = {2001},
  volume       = {12},
  number       = {2},
  pages        = {181--201},
  issn         = {1045-9227},
  doi          = {10.1109/72.914517},
  abstract     = {This paper provides an introduction to support vector machines, kernel Fisher discriminant analysis, and kernel principal component analysis, as examples for successful kernel-based learning methods. We first give a short background about Vapnik-Chervonenkis theory and kernel feature spaces and then proceed to kernel based learning in supervised and unsupervised scenarios including practical and algorithmic considerations. We illustrate the usefulness of kernel algorithms by discussing applications such as optical character recognition and DNA analysis},
  file         = {:pdf-files/Muller2001 - An Introduction to Kernel Based Learning Algorithms.pdf:PDF},
  groups       = {Machine Learning, SVM},
  keywords     = {learning (artificial intelligence);learning automata;neural nets;optical character recognition;pattern classification;principal component analysis;DNA analysis;Mercer kernel;Vapnik-Chervonenkis theory;kernel Fisher discriminant analysis;learning algorithms;mathematical programming;optical character recognition;principal component analysis;support vector machines;Algorithm design and analysis;Character recognition;DNA;Kernel;Optical character recognition software;Pattern analysis;Principal component analysis;Support vector machine classification;Support vector machines;Time series analysis},
  owner        = {flo},
  timestamp    = {2016.02.11},
}

@InProceedings{Mundy2015,
  author    = {Andrew Mundy and James Knight and Terrence C. Stewart and Steve Furber},
  title     = {An efficient {SpiNNaker} implementation of the Neural Engineering Framework},
  booktitle = {2015 International Joint Conference on Neural Networks ({IJCNN})},
  year      = {2015},
  date      = {2015},
  publisher = {{IEEE}},
  pages     = {1--8},
  doi       = {10.1109/ijcnn.2015.7280390},
  abstract  = {By building and simulating neural systems we hope to understand how the brain may work and use this knowledge to build neural and cognitive systems to tackle engineering problems. The Neural Engineering Framework (NEF) is a hypothesis about how such systems may be constructed and has recently been used to build the world's first functional brain model, Spaun. However, while the NEF simplifies the design of neural networks, simulating them using standard computer hardware is still computationally expensive - often running far slower than biological real-time and scaling very poorly: problems the SpiNNaker neuromorphic simulator was designed to solve. In this paper we (1) argue that employing the same model of computation used for simulating general purpose spiking neural networks on SpiNNaker for NEF models results in suboptimal use of the architecture, and (2) provide and evaluate an alternative simulation scheme which overcomes the memory and compute challenges posed by the NEF. This proposed method uses factored weight matrices to reduce memory usage by around 90\% and, in some cases, simulate 2000 neurons on a processing core - double the SpiNNaker architectural target.},
  file      = {:pdf-files/Mundy2015 - An Efficient SpiNNaker Implementation of the Neural Engineering Framework.pdf:PDF},
  groups    = {SpiNNaker, Nengo},
  issn      = {2161-4393},
  keywords  = {digital simulation;neural net architecture;NEF models;Spaun;SpiNNaker architectural target;SpiNNaker neuromorphic simulator;biological real-time;brain;cognitive systems;efficient SpiNNaker implementation;factored weight matrices;functional brain model;memory usage;neural engineering framework;neural systems;simulation scheme;standard computer hardware;Biological information theory;Biological system modeling;Brain modeling;Computational modeling;Delays;Mice;Neurons},
  owner     = {flo},
  timestamp = {2016.02.18},
}

@Article{Murthy1998,
  author       = {Murthy, Sreerama K.},
  title        = {{Automatic Construction of Decision Trees from Data: A Multi-Disciplinary Survey}},
  journaltitle = {Data Mining and Knowledge Discovery},
  year         = {1998},
  date         = {1998},
  volume       = {2},
  number       = {4},
  pages        = {345--389},
  issn         = {1384-5810},
  doi          = {10.1023/A:1009744630224},
  acmid        = {593472},
  file         = {:pdf-files/Murthy1998 - Automatic Construction of Decision Trees from Data_ a Multi Disciplinary Survey.pdf:PDF},
  groups       = {Machine Learning, DecisionTrees},
  issue_date   = {December 1998},
  keywords     = {classification, data compaction, tree-structured classifiers},
  location     = {Hingham, MA, USA},
  numpages     = {45},
  owner        = {flo},
  publisher    = {Kluwer Academic Publishers},
  timestamp    = {2016.02.09},
}

@Article{Nakano2015,
  author       = {Takashi Nakano and Makoto Otsuka and Junichiro Yoshimoto and Kenji Doya},
  title        = {A Spiking Neural Network Model of Model-Free Reinforcement Learning with High-Dimensional Sensory Input and Perceptual Ambiguity},
  journal      = {{PLOS} {ONE}},
  journaltitle = {{PLOS} {ONE}},
  year         = {2015},
  date         = {2015},
  editor       = {Thomas Wennekers},
  volume       = {10},
  number       = {3},
  pages        = {1--18},
  doi          = {10.1371/journal.pone.0115620},
  abstract     = {<p>A theoretical framework of reinforcement learning plays an important role in understanding action selection in animals. Spiking neural networks provide a theoretically grounded means to test computational hypotheses on neurally plausible algorithms of reinforcement learning through numerical simulation. However, most of these models cannot handle observations which are noisy, or occurred in the past, even though these are inevitable and constraining features of learning in real environments. This class of problem is formally known as partially observable reinforcement learning (PORL) problems. It provides a generalization of reinforcement learning to partially observable domains. In addition, observations in the real world tend to be rich and high-dimensional. In this work, we use a spiking neural network model to approximate the free energy of a restricted Boltzmann machine and apply it to the solution of PORL problems with high-dimensional observations. Our spiking network model solves maze tasks with perceptually ambiguous high-dimensional observations without knowledge of the true environment. An extended model with working memory also solves history-dependent tasks. The way spiking neural networks handle PORL problems may provide a glimpse into the underlying laws of neural information processing which can only be discovered through such a top-down approach.</p>},
  file         = {:pdf-files/Nakano2015 - A Spiking Neural Network Model of Model Free Reinforcement Learning with High Dimensional Sensory Input and Perceptual Ambiguity.pdf:PDF},
  groups       = {ReinforcementLearning, Spiking Neural Networks},
  owner        = {flo},
  publisher    = {Public Library of Science ({PLoS})},
  timestamp    = {2016.10.26},
}

@Misc{TrafficStatistics,
  author    = {{National Highway Traffic Safety Administration}},
  title     = {{National Highway Traffic Safety Administration Statistics}},
  year      = {2016},
  date      = {2016},
  url       = {http://www-fars.nhtsa.dot.gov/Main/index.aspx},
  groups    = {Autonomous Driving},
  owner     = {flo},
  timestamp = {2016.03.31},
}

@Article{Nere2012,
  author       = {Andrew Nere and Umberto Olcese and David Balduzzi and Giulio Tononi},
  title        = {A Neuromorphic Architecture for Object Recognition and Motion Anticipation Using Burst-{STDP}},
  journal      = {{PLoS} {ONE}},
  journaltitle = {PLoS ONE},
  year         = {2012},
  date         = {2012},
  editor       = {Thomas Wennekers},
  volume       = {7},
  number       = {5},
  pages        = {1--17},
  doi          = {10.1371/journal.pone.0036958},
  abstract     = {In this work we investigate the possibilities offered by a minimal framework of artificial spiking neurons to be deployed <italic>in silico</italic>. Here we introduce a hierarchical network architecture of spiking neurons which learns to recognize moving objects in a visual environment and determine the correct motor output for each object. These tasks are learned through both supervised and unsupervised spike timing dependent plasticity (STDP). STDP is responsible for the strengthening (or weakening) of synapses in relation to pre- and post-synaptic spike times and has been described as a Hebbian paradigm taking place both <italic>in vitro</italic> and <italic>in vivo</italic>. We utilize a variation of STDP learning, called burst-STDP, which is based on the notion that, since spikes are expensive in terms of energy consumption, then strong bursting activity carries more information than single (sparse) spikes. Furthermore, this learning algorithm takes advantage of homeostatic renormalization, which has been hypothesized to promote memory consolidation during NREM sleep. Using this learning rule, we design a spiking neural network architecture capable of object recognition, motion detection, attention towards important objects, and motor control outputs. We demonstrate the abilities of our design in a simple environment with distractor objects, multiple objects moving concurrently, and in the presence of noise. Most importantly, we show how this neural network is capable of performing these tasks using a simple leaky-integrate-and-fire (LIF) neuron model with binary synapses, making it fully compatible with state-of-the-art digital neuromorphic hardware designs. As such, the building blocks and learning rules presented in this paper appear promising for scalable fully neuromorphic systems to be implemented in hardware chips.},
  file         = {:pdf-files/Nere2012 - A Neuromorphic Architecture for Object Recognition and Motion Anticipation Using Burst STDP.pdf:PDF},
  groups       = {Neuromorphic Computing},
  owner        = {flo},
  publisher    = {Public Library of Science},
  timestamp    = {2016.02.16},
}

@InProceedings{Neubert2016,
  author    = {Neubert, P. and Schubert, S. and Protzel, P.},
  title     = {Learning Vector Symbolic Architectures for Reactive Robot Behaviours},
  booktitle = {Proc. of International Conference on Intelligent Robots and Systems (IROS), Workshop on Machine Learning Methods for High-Level Cognitive Capabilities in Robotics},
  date      = {2016},
  abstract  = {Vector Symbolic Architectures (VSA) combine a hypervector space and a set of operations on these vectors. Hypervectors provide powerful and noise-robust representations and VSAs are associated with promising theoretical properties for approaching high-level cognitive tasks. However, a major drawback of VSAs is the lack of opportunities to learn them from training data. Their power is merely an effect of good (and elaborate) design rather than learning. We exploit high-level knowledge about the structure of reactive robot problems to learn a VSA based on training data. We demonstrate preliminary results on a simple navigation task. Given a successful demonstration of a navigation run by pairs of sensor input and actuator output, the system learns a single hypervector that encodes this reactive behaviour. When executing (and combining) such VSA-based behaviours, the advantages of hypervectors (i.e. the representational power and robustness to noise) are preserved. Moreover, a particular beauty of this approach is that it can learn encodings for behaviours that have exactly the same form (a hypervector) no matter how complex the sensor input or the behaviours are.},
  file      = {:pdf-files/Neubert2016 - Learning Vector Symbolic Architectures for Reactive Robot Behaviours.pdf:PDF},
  groups    = {Vector Symbolic Architectures},
  owner     = {flo},
  timestamp = {2017.05.04},
}

@Article{vonNeumann1993,
  author       = {John von Neumann},
  title        = {First draft of a report on the {EDVAC}},
  journaltitle = {IEEE Annals of the History of Computing},
  date         = {1993},
  volume       = {15},
  number       = {4},
  pages        = {27--75},
  issn         = {1058-6180},
  doi          = {10.1109/85.238389},
  abstract     = {The first draft of a report on the EDVAC written by John von Neumann is presented. This first draft contains a wealth of information, and it had a pervasive influence when it was first written. Most prominently, Alan Turing cites it in his proposal for the Pilot automatic computing engine (ACE) as the definitive source for understanding the nature and design of a general-purpose digital computer.<>},
  file         = {:pdf-files/vonNeumann1993 - First Draft of a Report on the EDVAC.pdf:PDF},
  groups       = {Computing and GPU},
  keywords     = {digital computers;history;EDVAC;automatic computing engine;general-purpose digital computer;history;Electrical engineering;Engines;Forward contracts;History;Laboratories;Mathematics;Pain;Physics computing;Proposals;Statistics},
  owner        = {flo},
  timestamp    = {2016.05.23},
}

@InProceedings{Nguyen2015,
  author       = {Nguyen, Anh and Yosinski, Jason and Clune, Jeff},
  title        = {Deep {N}eural {N}etworks are {E}asily {F}ooled: {H}igh {C}onfidence {P}redictions for {U}nrecognizable {I}mages},
  booktitle    = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  date         = {2015},
  organization = {IEEE},
  url          = {http://www.evolvingai.org/fooling},
  file         = {:pdf-files/Nguyen2015 - Deep Neural Networks Are Easily Fooled_ High Confidence Predictions for Unrecognizable Images.pdf:PDF},
  groups       = {Deep Neural Networks},
  owner        = {flo},
  timestamp    = {2018.01.10},
}

@Misc{NHTSA_Autonomous_Vehicle_Policy,
  author    = {{NHTSA ({N}ational {H}ighway {T}raffic {S}afety {A}dministration)}},
  title     = {Preliminary {S}tatement of {P}olicy {C}oncerning {A}utomated {V}ehicles},
  date      = {2013},
  url       = {http://www.nhtsa.gov/staticfiles/rulemaking/pdf/Automated_Vehicles_Policy.pdf},
  comment   = {contains definitions of different levels of autonomy for self-driving cars},
  file      = {:pdf-files/NHTSA_Autonomous_Vehicle_Policy - Preliminary Statement of Policy Concerning Automated Vehicles.pdf:PDF},
  groups    = {Autonomous Driving},
  owner     = {flo},
  timestamp = {2016.10.14},
}

@Online{NobelPriceMed2014,
  author    = {{Nobel {P}rize}},
  title     = {The {N}obel {P}rize in {P}hysiology or {M}edicine},
  date      = {2014},
  url       = {http://www.nobelprize.org/nobel_prizes/medicine/laureates/2014/press.html},
  urldate   = {2018-04-05},
  groups    = {Biology},
  owner     = {flo},
  timestamp = {2016.04.06},
}

@Article{Norton2017,
  author       = {Adam Norton and Willard Ober and Lisa Baraniecki and Eric McCann and Jean Scholtz and David Shane and Anna Skinner and Robert Watson and Holly Yanco},
  title        = {Analysis of human-robot interaction at the DARPA Robotics Challenge Finals},
  journaltitle = {The International Journal of Robotics Research},
  date         = {2017},
  volume       = {36},
  number       = {5-7},
  pages        = {483--513},
  doi          = {10.1177/0278364916688254},
  eprint       = {https://doi.org/10.1177/0278364916688254},
  abstract     = {In June 2015, the Defense Advanced Research Projects Agency (DARPA) Robotics Challenge (DRC) Finals were held in Pomona, California. The DRC Finals served as the third phase of the program designed to test the capabilities of semi-autonomous, remote humanoid robots to perform disaster response tasks with degraded communications. All competition teams were responsible for developing their own interaction method to control their robot. Of the 23 teams in the competition, 20 consented to participate in this study of human-robot interaction (HRI). The evaluation team observed the consenting teams during task execution in their control rooms (with the operators), and all 23 teams were observed on the field during the public event (with the robot). A variety of data were collected both before the competition and on-site. Each participating team's interaction methods were distilled into a set of characteristics pertaining to the robot, operator strategies, control methods, and sensor fusion. Each task was decomposed into subtasks that were classified according to the complexity of the mobility and/or manipulation actions being performed. Performance metrics were calculated regarding the number of task attempts, performance time, and critical incidents, which were then correlated to each team's interaction methods. The results of this analysis suggest that a combination of HRI characteristics, including balancing the capabilities of the operator with those of the robot and multiple sensor fusion instances with variable reference frames, positively impacted task performance. A set of guidelines for designing HRI with remote, semi-autonomous humanoid robots is proposed based on these results.},
  file         = {:pdf-files/Norton2017 - Analysis of Human Robot Interaction at the DARPA Robotics Challenge Finals.pdf:PDF},
  groups       = {Robotics},
  owner        = {flo},
  timestamp    = {2018.01.19},
}

@Article{OConnor2013,
  author       = {O'Connor, Peter and Neil, Daniel and Liu, Shih-Chii and Delbruck, Tobi and Pfeiffer, Michael},
  title        = {{Real-Time Classification and Sensor Fusion with a Spiking Deep Belief Network}},
  journaltitle = {Frontiers in Neuroscience},
  date         = {2013},
  volume       = {7},
  number       = {178},
  issn         = {1662-453X},
  doi          = {10.3389/fnins.2013.00178},
  abstract     = {Deep Belief Networks (DBNs) have recently shown impressive performance on a broad range of classification problems. Their generative properties allow better understanding of the performance, and provide a simpler solution for sensor fusion tasks. However, because of their inherent need for feedback and parallel update of large numbers of units, DBNs are expensive to implement on serial computers. This paper proposes a method based on the Siegert approximation for
 Integrate-and-Fire neurons to map an offline-trained DBN onto an efficient event-driven spiking neural network suitable for hardware implementation. The method is demonstrated in simulation and by a real-time implementation of a 3-layer network with 2694 neurons used for visual classification of MNIST handwritten digits with input from a 128 $\times$ 128 Dynamic Vision Sensor (DVS) silicon retina, and sensory-fusion using additional input from a 64-channel AER-EAR silicon cochlea. The system is implemented through the open-source software in the jAER project and runs in real-time on a laptop computer. It is demonstrated that the system can recognize digits in the presence of distractions, noise, scaling, translation and rotation, and that the degradation of recognition performance by using an event-based approach is less than 1\%. Recognition is achieved in an average of 5.8 ms after the onset of the presentation of a digit. By cue integration from both silicon retina and cochlea outputs we show that the system can be biased to select the correct digit from otherwise ambiguous input.},
  file         = {:pdf-files/OConnor2013 - Real Time Classification and Sensor Fusion with a Spiking Deep Belief Network.pdf:PDF},
  groups       = {Spiking Neural Networks},
  owner        = {flo},
  timestamp    = {2016.01.18},
}

@Article{OKeefe1998,
  author       = {J. O{\textquotesingle}Keefe and N. Burgess and J. G. Donnett and K. J. Jeffery and E. A. Maguire},
  title        = {Place cells, navigational accuracy, and the human hippocampus.},
  journal      = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  journaltitle = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  year         = {1998},
  date         = {1998},
  volume       = {353},
  number       = {1373},
  pages        = {1333--1340},
  issn         = {1471-2970},
  doi          = {10.1098/rstb.1998.0287},
  url          = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1692339/},
  abstract     = {The hippocampal formation in both rats and humans is involved in spatial navigation. In the rat, cells coding for places, directions, and speed of movement have been recorded from the hippocampus proper and/or the neighbouring subicular complex. Place fields of a group of the hippocampal pyramidal cells cover the surface of an environment but do not appear to do so in any systematic fashion. That is, there is no topographical relation between the anatomical location of the cells within the hippocampus and the place fields of these cells in an environment. Recent work shows that place cells are responding to the summation of two or more Gaussian curves, each of which is fixed at a given distance to two or more walls in the environment. The walls themselves are probably identified by their allocentric direction relative to the rat and this information may be provided by the head direction cells. The right human hippocampus retains its role in spatial mapping as demonstrated by its activation during accurate navigation in imagined and virtual reality environments. In addition, it may have taken on wider memory functions, perhaps by the incorporation of a linear time tag which allows for the storage of the times of visits to particular locations. This extended system would serve as the basis for a spatio-temporal event or episodic memory system.},
  comment      = {9770226[pmid] 9770226[pmid]},
  file         = {:pdf-files/OKeefe1998 - Place Cells, Navigational Accuracy, and the Human Hippocampus..pdf:PDF},
  groups       = {Biology},
  owner        = {flo},
  publisher    = {The Royal Society},
  timestamp    = {2016.04.06},
}

@Book{OKeefe1978,
  author    = {John O'Keefe and Lynn Nadel},
  title     = {The Hippocampus as a Cognitive Map},
  date      = {1978},
  publisher = {Oxford University Press.},
  comment   = {original place cell reference},
  file      = {:pdf-files/OKeefe1978 - The Hippocampus As a Cognitive Map.pdf:PDF},
  groups    = {Biology},
  owner     = {flo},
  timestamp = {2016.04.06},
}

@Misc{Ogasawara2016,
  author    = {Ogasawara, T.},
  title     = {Vehicle driving environment recognition apparatus},
  date      = {2016},
  note      = {Ogasawara Patent2016},
  url       = {http://www.google.com.pg/patents/US9505338},
  groups    = {Situation/Context analysis},
  owner     = {flo},
  publisher = {Google Patents},
  timestamp = {2017.11.15},
}

@Article{Ohn-Bar2015,
  author       = {Eshed Ohn-Bar and Ashish Tawari and Sujitha Martin and Mohan M. Trivedi},
  title        = {On surveillance for safety critical events: In-vehicle video networks for predictive driver assistance systems},
  journaltitle = {Computer Vision and Image Understanding},
  year         = {2015},
  date         = {2015},
  volume       = {134},
  pages        = {130--140},
  doi          = {10.1016/j.cviu.2014.10.003},
  booktitle    = {Computer Vision and Image Understanding},
  file         = {:pdf-files/Ohn-Bar2015 - On Surveillance for Safety Critical Events_ in Vehicle Video Networks for Predictive Driver Assistance Systems.pdf:PDF},
  groups       = {Behaviour analysis},
  owner        = {flo},
  publisher    = {Elsevier {BV}},
  timestamp    = {2017.09.20},
}

@Article{Ohn-Bar2017,
  author       = {Eshed Ohn-Bar and Mohan M. Trivedi},
  title        = {Are All Objects Equal? Deep Spatio-Temporal Importance Prediction in Driving Videos},
  journaltitle = {Pattern Recognition},
  date         = {2017},
  file         = {:pdf-files/Ohn-Bar2017 - Are All Objects Equal_ Deep Spatio Temporal Importance Prediction in Driving Videos.pdf:PDF},
  groups       = {Behaviour analysis},
  owner        = {flo},
  timestamp    = {2017.09.20},
}

@Article{Olshausen1996,
  author       = {Olshausen, B. A. and Field, D. J.},
  title        = {Emergence of {S}imple-{C}ell {R}eceptive {F}ield {P}roperties by {L}earning a {S}parse {C}ode for {N}atural {I}mages},
  journaltitle = {Nature},
  date         = {1996},
  volume       = {381},
  pages        = {607--609},
  comment      = {Sparse Coding reference},
  file         = {:pdf-files/Olshausen1996 - Emergence of Simple Cell Receptive Field Properties by Learning a Sparse Code for Natural Images.pdf:PDF},
  groups       = {Biology},
  owner        = {flo},
  timestamp    = {2016.04.21},
}

@Article{Orchard2015,
  author       = {Garrick Orchard and Ajinkya Jayawant and Gregory Cohen and Nitish V. Thakor},
  title        = {{C}onverting {S}tatic {I}mage {D}atasets to {S}piking {N}euromorphic {D}atasets {U}sing {S}accades},
  journaltitle = {Frontiers in Neuroscience},
  date         = {2015},
  volume       = {9},
  number       = {00437},
  doi          = {10.3389/fnins.2015.00437},
  url          = {http://www.frontiersin.org/Journal/Abstract.aspx?s=755&name=neuromorphic_engineering&ART_DOI=10.3389/fnins.2015.00437},
  abstract     = {Creating datasets for Neuromorphic Vision is a challenging task. A lack of available recordings from Neuromorphic Vision sensors means that data must typically be recorded specifically for dataset creation rather than collecting and labeling existing data. The task is further complicated by a desire to simultaneously provide traditional frame-based recordings to allow for direct comparison with traditional Computer Vision algorithms. Here we propose a method for converting existing Computer Vision static image datasets into Neuromorphic Vision datasets using an actuated pan-tilt camera platform. Moving the sensor rather than the scene or image is a more biologically realistic approach to sensing and eliminates timing artifacts introduced by monitor updates when simulating motion on a computer monitor. We present conversion of two popular image datasets (MNIST and Caltech101) which have played important roles in the development of Computer Vision, and we provide performance metrics on these datasets using spike-based recognition algorithms. This work contributes datasets for future use in the field, as well as results from spike-based algorithms against which future works can compare. Furthermore, by converting datasets already popular in Computer Vision, we enable more direct comparison with frame-based approaches},
  file         = {:pdf-files/Orchard2015 - Converting Static Image Datasets to Spiking Neuromorphic Datasets Using Saccades.pdf:PDF},
  groups       = {Neuromorphic Vision, Spiking Neural Networks},
  owner        = {flo},
  timestamp    = {2016.01.26},
}

@PhdThesis{Ortiz2014,
  author      = {Michael Garcia Ortiz},
  title       = {Prediction of Driver Behaviour},
  institution = {Universit\"at Bielefeld},
  date        = {2014},
  file        = {:pdf-files/Ortiz2014 - Prediction of Driver Behaviour.pdf:PDF},
  groups      = {Autonomous Driving, Behaviour analysis},
  owner       = {flo},
  timestamp   = {2018.02.20},
}

@InProceedings{GarciaOrtiz2011,
  author    = {M. Garcia Ortiz and J. Fritsch and F. Kummert and A. Gepperth},
  title     = {Behavior prediction at multiple time-scales in inner-city scenarios},
  booktitle = {2011 IEEE Intelligent Vehicles Symposium (IV)},
  date      = {2011},
  pages     = {1068--1073},
  doi       = {10.1109/IVS.2011.5940524},
  abstract  = {We present a flexible and scalable architecture that can learn to predict the future behavior of a vehicle in inner-city traffic. While behavior prediction studies have mainly been focusing on lane change events on highways, we apply our approach to a simple inner-city scenario: approaching a traffic light. Our system employs dynamic information about the current ego-vehicle state as well as static information about the scene, in this case position and state of nearby traffic lights.},
  file      = {:pdf-files/GarciaOrtiz2011 - Behavior Prediction at Multiple Time Scales in Inner City Scenarios.pdf:PDF},
  groups    = {Behaviour analysis},
  issn      = {1931-0587},
  keywords  = {behavioural sciences;learning (artificial intelligence);prediction theory;road traffic;road vehicles;behavior prediction;dynamic information;dynamic inner-city traffic;ego vehicle state;highway;multiclass learning problem;static information;traffic light;Actuators;Driver circuits;Learning systems;Neurons;Prediction algorithms;Training;Trajectory},
  owner     = {flo},
  timestamp = {2017.09.20},
}

@InProceedings{Padilla2014,
  author    = {D. E. Padilla and M. D. McDonnell},
  title     = {A Neurobiologically Plausible Vector Symbolic Architecture},
  booktitle = {2014 IEEE International Conference on Semantic Computing},
  date      = {2014},
  pages     = {242--245},
  doi       = {10.1109/ICSC.2014.40},
  abstract  = {Vector Symbolic Architectures (VSA) are approaches to representing symbols and structured combinations of symbols as high-dimensional vectors. They have applications in machine learning and for understanding information processing in neurobiology. VSAs are typically described in an abstract mathematical form in terms of vectors and operations on vectors. In this work, we show that a machine learning approach known as hierarchical temporal memory, which is based on the anatomy and function of mammalian neocortex, is inherently capable of supporting important VSA functionality. This follows because the approach learns sequences of semantics-preserving sparse distributed representations.},
  file      = {:pdf-files/Padilla2014 - A Neurobiologically Plausible Vector Symbolic Architecture.pdf:PDF},
  groups    = {Vector Symbolic Architectures},
  keywords  = {information retrieval;learning (artificial intelligence);VSA;abstract mathematical form;hierarchical temporal memory approach;high-dimensional vectors;information processing;machine learning;mammalian neocortex;neurobiologically plausible vector symbolic architecture;semantics-preserving sparse distributed representations;Computer architecture;Indexes;Probes;Semantics;Sparse matrices;Training;Vectors;hierarchical temporal memory;natural language processing;semantic symbols;sparse distributed representations;vector symbolic architecture},
  owner     = {flo},
  timestamp = {2017.04.26},
}

@InCollection{Paugam2009,
  author    = {H{\'{e}}l{\`{e}}ne Paugam-Moisy and Sander Bohte},
  title     = {Computing with Spiking Neuron Networks},
  booktitle = {Handbook of Natural Computing},
  year      = {2012},
  date      = {2009},
  editor    = {G. Rozenberg, T. Back, J. Kok},
  language  = {en},
  publisher = {Springer Berlin Heidelberg},
  pages     = {335--376},
  doi       = {10.1007/978-3-540-92910-9_10},
  url       = {http://liris.cnrs.fr/publis/?id=4305},
  file      = {:pdf-files/Paugam2009 - Handbook of Natural Computing.pdf:PDF},
  groups    = {Spiking Neural Networks},
  owner     = {flo},
  timestamp = {2016.01.18},
}

@Online{ArtificialBrainsWebsite,
  author    = {James Pearn},
  title     = {Artificial {Brains}},
  url       = {http://www.artificialbrains.com/},
  urldate   = {2017-12-20},
  owner     = {flo},
  timestamp = {2017.12.20},
}

@Article{Pecevski2011,
  author       = {Dejan Pecevski and Lars Buesing and Wolfgang Maass},
  title        = {Probabilistic Inference in General Graphical Models through Sampling in Stochastic Networks of Spiking Neurons},
  journal      = {{PLoS} Computational Biology},
  journaltitle = {{PLoS} Computational Biology},
  year         = {2011},
  date         = {2011},
  editor       = {Olaf Sporns},
  volume       = {7},
  number       = {12},
  pages        = {1--25},
  doi          = {10.1371/journal.pcbi.1002294},
  abstract     = {<title>Author Summary</title> <p>Experimental data from neuroscience have provided substantial knowledge about the intricate structure of cortical microcircuits, but their functional role, i.e. the computational calculus that they employ in order to interpret ambiguous stimuli, produce predictions, and derive movement plans has remained largely unknown. Earlier assumptions that these circuits implement a logic-like calculus have run into problems, because logical inference has turned out to be inadequate to solve inference problems in the real world which often exhibits substantial degrees of uncertainty. In this article we propose an alternative theoretical framework for examining the functional role of precisely structured motifs of cortical microcircuits and dendritic computations in complex neurons, based on probabilistic inference through sampling. We show that these structural details endow cortical columns and areas with the capability to represent complex knowledge about their environment in the form of higher order dependencies among salient variables. We show that it also enables them to use this knowledge for probabilistic inference that is capable to deal with uncertainty in stored knowledge and current observations. We demonstrate in computer simulations that the precisely structured neuronal microcircuits enable networks of spiking neurons to solve through their inherent stochastic dynamics a variety of complex probabilistic inference tasks.</p>},
  file         = {:pdf-files/Pecevski2011 - Probabilistic Inference in General Graphical Models through Sampling in Stochastic Networks of Spiking Neurons.pdf:PDF},
  groups       = {Bayesian Inference with Spiking Neurons, Spiking Neural Networks},
  owner        = {flo},
  publisher    = {Public Library of Science},
  timestamp    = {2016.08.10},
}

@InProceedings{Pedroni2013,
  author    = {Bruno U. Pedroni and Srinjoy Das and Emre Neftci and Kenneth Kreutz-Delgado and Gert Cauwenberghs},
  title     = {Neuromorphic adaptations of restricted Boltzmann machines and deep belief networks},
  booktitle = {The 2013 International Joint Conference on Neural Networks ({IJCNN})},
  year      = {2013},
  date      = {2013},
  publisher = {{IEEE}},
  pages     = {1--6},
  doi       = {10.1109/ijcnn.2013.6707067},
  abstract  = {Restricted Boltzmann Machines (RBMs) and Deep Belief Networks (DBNs) have been demonstrated to perform efficiently on a variety of applications, such as dimensionality reduction and classification. Implementation of RBMs on neuromorphic platforms, which emulate large-scale networks of spiking neurons, has significant advantages from concurrency and low-power perspectives. This work outlines a neuromorphic adaptation of the RBM, which uses a recently proposed neural sampling algorithm (Buesing et al. 2011), and examines its algorithmic efficiency. Results show the feasibility of such alterations, which will serve as a guide for future implementation of such algorithms in neuromorphic very large scale integration (VLSI) platforms.},
  file      = {:pdf-files/Pedroni2013 - Neuromorphic Adaptations of Restricted Boltzmann Machines and Deep Belief Networks.pdf:PDF},
  groups    = {Neuromorphic Computing, Deep Neural Networks},
  issn      = {2161-4393},
  keywords  = {Boltzmann machines;belief networks;sampling methods;DBN;RBM;deep belief networks;dimensionality reduction;large-scale spiking neuron networks;neural sampling algorithm;neuromorphic VLSI platforms;neuromorphic adaptations;neuromorphic platforms;neuromorphic very large scale integration platforms;restricted Boltzmann machines;Accuracy;Bayes methods;Hardware;Machine learning algorithms;Neuromorphics;Neurons;Training},
  owner     = {flo},
  timestamp = {2016.02.18},
}

@InProceedings{Pennington2014,
  author    = {Jeffrey Pennington and Richard Socher and Christopher D. Manning},
  title     = {{GloVe}: {G}lobal {V}ectors for {W}ord {R}epresentation},
  booktitle = {Empirical Methods in Natural Language Processing (EMNLP)},
  date      = {2014},
  pages     = {1532--1543},
  url       = {http://www.aclweb.org/anthology/D14-1162},
  file      = {:pdf-files/Pennington2014 - GloVe_ Global Vectors for Word Representation.pdf:PDF},
  groups    = {Word Embedding},
  owner     = {flo},
  timestamp = {2017.06.29},
}

@Misc{Petrovskaya2011,
  author    = {Anna Petrovskaya and Mathias Perrollas and Luciano Oliveira and Luciano Spinello and Rudolph Triebel and Ros Makris and John-David Yoder and Christian Laugier and Urbano Nunes},
  title     = {{Awareness of Road Scene Participants for Autonomous Driving}},
  date      = {2011},
  file      = {:pdf-files/Petrovskaya2011 - Awareness of Road Scene Participants for Autonomous Driving.pdf:PDF},
  groups    = {Object Recognition},
  owner     = {flo},
  timestamp = {2015.12.10},
}

@InCollection{Petrovskaya2009,
  author               = {Petrovskaya, Anna and Thrun, Sebastian},
  title                = {{Efficient Techniques for Dynamic Vehicle Detection}},
  booktitle            = {Experimental Robotics},
  date                 = {2009},
  editor               = {Khatib, Oussama and Kumar, Vijay and Pappas, George J.},
  volume               = {54},
  publisher            = {Springer Berlin Heidelberg},
  location             = {Berlin, Heidelberg},
  chapter              = {10},
  pages                = {79--91},
  doi                  = {10.1007/978-3-642-00196-3\_10},
  url                  = {http://dx.doi.org/10.1007/978-3-642-00196-3\_10},
  abstract             = {Fast detection of moving vehicles is crucial for safe autonomous urban driving. We present the vehicle detection algorithm developed for our entry in the Urban Grand Challenge, an autonomous driving race organized by the {U.S}. Government in 2007. The algorithm provides reliable detection of moving vehicles from a high-speed moving platform using laser range finders. We present the notion of motion evidence, which allows us to overcome the low signal-to-noise ratio that arises during rapid detection of moving vehicles in noisy urban environments. We also present and evaluate an array of optimization techniques that enable accurate detection in real time. Experimental results show empirical validation on data from the most challenging situations presented at the Urban Grand Challenge as well as other urban settings.},
  citeulike-article-id = {10132276},
  citeulike-linkout-0  = {http://dx.doi.org/10.1007/978-3-642-00196-3\_10},
  file                 = {:pdf-files/Petrovskaya2009 - Efficient Techniques for Dynamic Vehicle Detection.pdf:PDF},
  groups               = {Object Recognition},
  keywords             = {autonomous-vehicle, detection, estimation, tracking},
  owner                = {flo},
  posted-at            = {2011-12-15 20:10:17},
  timestamp            = {2016.01.18},
}

@Article{Petrovskaya2009a,
  author       = {Petrovskaya, Anna and Thrun, Sebastian},
  title        = {Model based vehicle detection and tracking for autonomous urban driving},
  journaltitle = {Autonomous Robots},
  date         = {2009},
  volume       = {26},
  number       = {2},
  pages        = {123--139},
  issn         = {1573-7527},
  doi          = {10.1007/s10514-009-9115-1},
  abstract     = {Situational awareness is crucial for autonomous driving in urban environments. This paper describes the moving vehicle detection and tracking module that we developed for our autonomous driving robot Junior. The robot won second place in the Urban Grand Challenge, an autonomous driving race organized by the U.S. Government in 2007. The module provides reliable detection and tracking of moving vehicles from a high-speed moving platform using laser range finders. Our approach models both dynamic and geometric properties of the tracked vehicles and estimates them using a single Bayes filter per vehicle. We present the notion of motion evidence, which allows us to overcome the low signal-to-noise ratio that arises during rapid detection of moving vehicles in noisy urban environments. Furthermore, we show how to build consistent and efficient 2D representations out of 3D range data and how to detect poorly visible black vehicles. Experimental validation includes the most challenging conditions presented at the Urban Grand Challenge as well as other urban settings.},
  file         = {:pdf-files/Petrovskaya2009a - Model Based Vehicle Detection and Tracking for Autonomous Urban Driving.pdf:PDF},
  groups       = {Object Recognition},
  owner        = {flo},
  timestamp    = {2016.01.18},
}

@InProceedings{Piatkowska2012,
  author    = {E. Piatkowska and A. N. Belbachir and S. Schraml and M. Gelautz},
  title     = {Spatiotemporal multiple persons tracking using {Dynamic Vision Sensor}},
  booktitle = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  date      = {2012},
  pages     = {35--40},
  doi       = {10.1109/CVPRW.2012.6238892},
  abstract  = {Although motion analysis has been extensively investigated in the literature and a wide variety of tracking algorithms have been proposed, the problem of tracking objects using the Dynamic Vision Sensor requires a slightly different approach. Dynamic Vision Sensors are biologically inspired vision systems that asynchronously generate events upon relative light intensity changes. Unlike conventional vision systems, the output of such sensor is not an image (frame) but an address events stream. Therefore, most of the conventional tracking algorithms are not appropriate for the DVS data processing. In this paper, we introduce algorithm for spatiotemporal tracking that is suitable for Dynamic Vision Sensor. In particular, we address the problem of multiple persons tracking in the occurrence of high occlusions. We investigate the possibility to apply Gaussian Mixture Models for detection, description and tracking objects. Preliminary results prove that our approach can successfully track people even when their trajectories are intersecting.},
  file      = {:pdf-files/Piatkowska2012 - Spatiotemporal Multiple Persons Tracking Using Dynamic Vision Sensor.pdf:PDF},
  groups    = {Neuromorphic Vision},
  issn      = {2160-7508},
  keywords  = {Gaussian processes;image motion analysis;image sensors;object detection;object tracking;DVS data processing;Gaussian mixture models;biologically inspired vision systems;dynamic vision sensor;motion analysis;object description;object detection;object tracking;occlusions;spatiotemporal multiple persons tracking;Clustering algorithms;Data models;Dynamics;Heuristic algorithms;Machine vision;Tracking;Voltage control},
  owner     = {flo},
  timestamp = {2016.03.10},
}

@InProceedings{Plate1997,
  author       = {Tony Plate},
  title        = {A common framework for distributed representation schemes for compositional structure},
  booktitle    = {Connectionist Systems for Knowledge Representation and Deduction},
  date         = {1997},
  editor       = {Frederic Maire and Ross Hayward and Joachim Diederich},
  organization = {Queensland University of Technology},
  pages        = {15--34},
  abstract     = {Over the last few years a number of schemes for encoding compositional structure
in distributed representations have been proposed, e.g., Smolensky's tensor products,
Pollack's RAAMs, Plate's HRRs, Halford et al's STAR model, and Kanerva's binary
spatter codes. All of these schemes can placed in a general framework involving su-
perposition and binding of patterns. Viewed in this way, it is often simple to decide
whether what can be achieved within one scheme will be able to be achieved in another.
Furthermore, placing these schemes in a general framework reveals unexplored regions
in which other related representation schemes with interesting properties.},
  file         = {:pdf-files/Plate1997 - A Common Framework for Distributed Representation Schemes for Compositional Structure.pdf:PDF},
  groups       = {Vector Symbolic Architectures},
  owner        = {flo},
  timestamp    = {2017.06.30},
}

@PhdThesis{Plate1994,
  author      = {Tony Plate},
  title       = {Distributed {R}epresentations and {N}ested {C}ompositional {S}tructure},
  institution = {University of Toronto},
  date        = {1994},
  file        = {:pdf-files/Plate1994 - Distributed Representations and Nested Compositional Structure.pdf:PDF},
  groups      = {Vector Symbolic Architectures},
  owner       = {flo},
  timestamp   = {2017.06.22},
}

@InProceedings{Plate1991,
  author    = {Tony Plate},
  title     = {Holographic Reduced Representations: Convolution Algebra for Compositional Distributed Representations},
  booktitle = {International Joint Conference on Artificial Intelligence},
  date      = {1991},
  publisher = {Morgan Kaufmann},
  pages     = {30--35},
  file      = {:pdf-files/Plate1991 - Holographic Reduced Representations_ Convolution Algebra for Compositional Distributed Representations.pdf:PDF},
  groups    = {Vector Symbolic Architectures},
  owner     = {flo},
  timestamp = {2017.04.28},
}

@InCollection{Plate1994a,
  author    = {Plate, Tony A.},
  title     = {Estimating analogical similarity by dot-products of Holographic Reduced Representations},
  booktitle = {Advances in Neural Information Processing Systems 6},
  date      = {1994},
  editor    = {J. D. Cowan and G. Tesauro and J. Alspector},
  publisher = {Morgan-Kaufmann},
  pages     = {1109--1116},
  url       = {http://papers.nips.cc/paper/740-estimating-analogical-similarity-by-dot-products-of-holographic-reduced-representations.pdf},
  file      = {:pdf-files/Plate1994a - Estimating Analogical Similarity by Dot Products of Holographic Reduced Representations.pdf:PDF},
  groups    = {Vector Symbolic Architectures},
  owner     = {flo},
  timestamp = {2017.12.08},
}

@Book{Plate2003,
  author    = {Plate, Tony A.},
  title     = {Holographic {R}educed {R}epresentation: {D}istributed {R}epresentation for {C}ognitive {S}tructures},
  date      = {2003},
  publisher = {CSLI Publications},
  location  = {Stanford, CA, USA},
  isbn      = {1575864290},
  groups    = {Vector Symbolic Architectures},
  owner     = {flo},
  timestamp = {2017.10.10},
}

@Article{Ponulak2011,
  author               = {Ponulak, Filip and Kasinski, Andrzej},
  title                = {{Introduction to spiking neural networks: Information processing, learning and applications.}},
  journaltitle         = {Acta neurobiologiae experimentalis},
  date                 = {2011},
  volume               = {71},
  number               = {4},
  pages                = {409--433},
  issn                 = {1689-0035},
  url                  = {http://view.ncbi.nlm.nih.gov/pubmed/22237491},
  abstract             = {{ The concept that neural information is encoded in the firing rate of neurons has been the dominant paradigm in neurobiology for many years. This paradigm has also been adopted by the theory of artificial neural networks. Recent physiological experiments demonstrate, however, that in many parts of the nervous system, neural code is founded on the timing of individual action potentials. This finding has given rise to the emergence of a new class of neural models, called spiking neural networks. In this paper we summarize basic properties of spiking neurons and spiking networks. Our focus is, specifically, on models of spike-based information coding, synaptic plasticity and learning. We also survey real-life applications of spiking models. The paper is meant to be an introduction to spiking neural networks for scientists from various disciplines interested in spike-based neural processing. }},
  citeulike-article-id = {10365927},
  citeulike-linkout-0  = {http://view.ncbi.nlm.nih.gov/pubmed/22237491},
  citeulike-linkout-1  = {http://www.hubmed.org/display.cgi?uids=22237491},
  file                 = {:pdf-files/Ponulak2011 - Introduction to Spiking Neural Networks_ Information Processing, Learning and Applications..pdf:PDF},
  groups               = {Neural Modelling, Spiking Neural Networks},
  owner                = {flo},
  pmid                 = {22237491},
  posted-at            = {2014-02-06 10:48:36},
  timestamp            = {2016.04.11},
}

@Article{Posch2014,
  author       = {C. Posch and T. Serrano-Gotarredona and B. Linares-Barranco and T. Delbruck},
  title        = {Retinomorphic {E}vent-{B}ased {V}ision {S}ensors: {B}ioinspired {C}ameras {W}ith {S}piking {O}utput},
  journaltitle = {Proceedings of the IEEE},
  date         = {2014},
  volume       = {102},
  number       = {10},
  pages        = {1470--1484},
  issn         = {0018-9219},
  doi          = {10.1109/JPROC.2014.2346153},
  abstract     = {State-of-the-art image sensors suffer from significant limitations imposed by their very principle of operation. These sensors acquire the visual information as a series of "snapshot" images, recorded at discrete points in time. Visual information gets time quantized at a predetermined frame rate which has no relation to the dynamics present in the scene. Furthermore, each recorded frame conveys the information from all pixels, regardless of whether this information, or a part of it, has changed since the last frame had been acquired. This acquisition method limits the temporal resolution, potentially missing important information, and leads to redundancy in the recorded image data, unnecessarily inflating data rate and volume. Biology is leading the way to a more efficient style of image acquisition. Biological vision systems are driven by events happening within the scene in view, and not, like image sensors, by artificially created timing and control signals. Translating the frameless paradigm of biological vision to artificial imaging systems implies that control over the acquisition of visual information is no longer being imposed externally to an array of pixels but the decision making is transferred to the single pixel that handles its own information individually. In this paper, recent developments in bioinspired, neuromorphic optical sensing and artificial vision are presented and discussed. It is suggested that bioinspired vision systems have the potential to outperform conventional, frame-based vision systems in many application fields and to establish new benchmarks in terms of redundancy suppression and data compression, dynamic range, temporal resolution, and power efficiency. Demanding vision tasks such as real-time 3-D mapping, complex multiobject tracking, or fast visual feedback loops for sensory-motor action, tasks that often pose severe, sometimes insurmountable, challenges to conventional artificial vision systems, are in reach - sing bioinspired vision sensing and processing techniques.},
  comment      = {ATIS reference},
  file         = {:pdf-files/Posch2014 - Retinomorphic Event Based Vision Sensors_ Bioinspired Cameras with Spiking Output.pdf:PDF},
  groups       = {Neuromorphic Vision},
  keywords     = {cameras;data compression;image resolution;image sensors;optical sensors;3D mapping;artificial imaging system;artificial vision sensing;bioinspired camera;bioinspired neuromorphic optical sensing;biological vision system;complex multiobject tracking;data compression;decision making;fast visual feedback loop;frame-based vision system;image acquisition;image data recording;image sensor;retinomorphic event-based vision sensor;sensory-motor action;snapshot image series;temporal resolution;Biosensors;Cameras;Event recognition;Image sensors;Neuromorphic engineering;Neuromorphics;Photoreceptors;Retina;Time-domain anlaysis;Visualization;Address-event representation (AER);Address-event representation (AER);biomimetics;complementary metal-oxide-semiconductor (CMOS) image sensors;complementary metal-oxide-semiconductor (CMOS) image sensors;event-based vision;focal-plane processing;high dynamic range (HDR);neuromorphic electronics;neuromorphic engineering;silicon retina;time-domain correlated double sampling (TCDS);time-domain imaging;video compression},
  owner        = {flo},
  timestamp    = {2016.09.01},
}

@InProceedings{Preissl2012,
  author    = {Preissl, Robert and Wong, Theodore M. and Datta, Pallab and Flickner, Myron and Singh, Raghavendra and Esser, Steven K. and Risk, William P. and Simon, Horst D. and Modha, Dharmendra S.},
  title     = {Compass: {A} {S}calable {S}imulator for an {A}rchitecture for {C}ognitive {C}omputing},
  booktitle = {Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis},
  date      = {2012},
  series    = {SC '12},
  publisher = {IEEE Computer Society Press},
  location  = {Salt Lake City, Utah},
  isbn      = {978-1-4673-0804-5},
  pages     = {54:1--54:11},
  address   = {Los Alamitos, CA, USA},
  articleno = {54},
  file      = {:pdf-files/Preissl2012 - Compass_ a Scalable Simulator for an Architecture for Cognitive Computing.pdf:PDF},
  groups    = {TrueNorth, Simulators},
  numpages  = {11},
  owner     = {flo},
  timestamp = {2016.03.09},
}

@Article{Probst2015,
  author       = {Probst, Dimitri and Petrovici, Mihai Alexandru and Bytschok, Ilja and Bill, Johannes and Pecevski, Dejan and Schemmel, Johannes and Meier, Karlheinz},
  title        = {{Probabilistic Inference in Discrete Spaces Can Be Implemented into Networks of LIF Neurons}},
  journaltitle = {Frontiers in Computational Neuroscience},
  date         = {2015},
  volume       = {9},
  number       = {13},
  issn         = {1662-5188},
  doi          = {10.3389/fncom.2015.00013},
  abstract     = {The means by which cortical neural networks are able to efficiently solve inference problems remains an open question in computational neuroscience. Recently, abstract models of Bayesian computation in neural circuits have been proposed, but they lack a mechanistic interpretation at the single-cell level. In this article, we describe a complete theoretical framework for building networks of leaky integrate-and-fire neurons that can sample from arbitrary probability distributions over binary random variables. We test our framework for a model inference task based on a psychophysical phenomenon (the Knill-Kersten optical illusion) and further assess its performance when applied to randomly generated distributions. As the local computations performed by the network strongly depend on the interaction between neurons, we compare several types of couplings mediated by either single synapses or interneuron chains. Due to its robustness to substrate imperfections such as parameter noise and background noise correlations, our model is particularly interesting for implementation on novel, neuro-inspired computing architectures, which can thereby serve as a fast, low-power substrate for solving real-world inference problems.},
  file         = {:pdf-files/Probst2015 - Probabilistic Inference in Discrete Spaces Can Be Implemented into Networks of LIF Neurons.pdf:PDF},
  groups       = {Bayesian Inference with Spiking Neurons},
  owner        = {flo},
  timestamp    = {2016.03.10},
}

@Book{Purves2004,
  author    = {Purves, Dale and Augustine, George J. and Fitzpatrick, David and Hall, William C. and Lamantia, Anthony-Samuel and McNamara, James O. and Williams, S. Mark},
  title     = {Neuroscience},
  date      = {2004},
  edition   = {3},
  publisher = {Sinauer Associates, Inc},
  location  = {Sunderland, MA},
  file      = {:pdf-files/Purves2004 - Neuroscience.pdf:PDF},
  groups    = {Biology},
  keywords  = {neuroscience},
  owner     = {flo},
  timestamp = {2016.04.06},
}

@Article{Qiao2015,
  author       = {Qiao, Ning and Mostafa, Hesham and Corradi, Federico and Osswald, Marc and Stefanini, Fabio and Sumislawska, Dora and Indiveri, Giacomo},
  title        = {A {R}e-configurable {O}n-line {L}earning {S}piking {N}euromorphic {P}rocessor comprising 256 neurons and 128{K} synapses},
  journaltitle = {Frontiers in Neuroscience},
  date         = {2015},
  volume       = {9},
  number       = {141},
  issn         = {1662-453X},
  doi          = {10.3389/fnins.2015.00141},
  abstract     = {Implementing compact, low-power artificial neural processing systems with real-time on-line learning abilities is still an open challenge. In this paper we present a full-custom mixed-signal VLSI device with neuromorphic learning circuits that emulate the biophysics of real spiking neurons and dynamic synapses for exploring the properties of computational neuroscience models and for building brain-inspired computing systems. The proposed architecture allows the on-chip configuration of a wide range of network connectivities, including recurrent and deep networks, with short-term and long-term plasticity. The device comprises 128 K analog synapse and 256 neuron circuits with biologically plausible dynamics and bi-stable spike-based plasticity mechanisms that endow it with on-line learning abilities. In addition to the analog circuits, the device comprises also asynchronous digital logic circuits for setting different synapse and neuron properties as well as different network configurations. This prototype device, fabricated using a 180 nm 1P6M CMOS process, occupies an area of 51.4 mm2, and consumes approximately 4 mW for typical experiments, for example involving attractor networks. Here we describe the details of the overall architecture and of the individual circuits and present experimental results that showcase its potential. By supporting a wide range of cortical-like computational modules comprising plasticity mechanisms, this device will enable the realization of intelligent autonomous systems with on-line learning capabilities.},
  file         = {:pdf-files/Qiao2015 - A Re Configurable on Line Learning Spiking Neuromorphic Processor Comprising 256 Neurons and 128K Synapses.pdf:PDF},
  groups       = {Neuromorphic Hardware},
  owner        = {flo},
  timestamp    = {2016.03.09},
}

@Conference{Quigley2009,
  author      = {Morgan Quigley and Ken Conley and Brian P. Gerkey and Josh Faust and Tully Foote and Jeremy Leibs and Rob Wheeler and Andrew Y. Ng},
  title       = {R{O}{S}: an open-source {R}obot {O}perating {S}ystem},
  booktitle   = {ICRA Workshop on Open Source Software},
  date        = {2009},
  abstract    = {This paper gives an overview of ROS, an opensource robot operating system. ROS is not an operating system in the traditional sense of process management and scheduling; rather, it provides a structured communications layer above the host operating systems of a heterogenous compute cluster. In this paper, we discuss how ROS relates to existing robot software frameworks, and briefly overview some of the available application software which uses ROS.},
  attachments = {http://www.willowgarage.com/sites/default/files/icraoss09-ROS.pdf},
  file        = {:pdf-files/Quigley2009 - ROS_ an Open Source Robot Operating System.pdf:PDF},
  groups      = {Robotics},
  owner       = {flo},
  timestamp   = {2016.08.24},
}

@Article{Rachkovskij2001,
  author       = {D. A. Rachkovskij},
  title        = {Representation and processing of structures with binary sparse distributed codes},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  date         = {2001},
  volume       = {13},
  number       = {2},
  pages        = {261--276},
  issn         = {1041-4347},
  doi          = {10.1109/69.917565},
  abstract     = {The schemes for compositional distributed representations include those allowing on-the-fly construction of fixed dimensionality codevectors to encode structures of various complexity. Similarity of such codevectors takes into account both structural and semantic similarity of represented structures. We provide a comparative description of sparse binary distributed representation developed in the framework of the associative-projective neural network architecture and the more well known holographic reduced representations of T.A. Plate (1995) and binary spatter codes of P. Kanerva (1996). The key procedure in associative-projective neural networks is context-dependent thinning which binds codevectors and maintains their sparseness. The codevectors are stored in structured memory array which can be realized as distributed auto-associative memory. Examples of distributed representation of structured data are given. Fast estimation of the similarity of analogical episodes by the overlap of their codevectors is used in the modeling of analogical reasoning both for retrieval of analogs from memory and for analogical mapping},
  file         = {:pdf-files/Rachkovskij2001 - Representation and Processing of Structures with Binary Sparse Distributed Codes.pdf:PDF},
  groups       = {Vector Symbolic Architectures},
  keywords     = {associative processing;bibliographies;case-based reasoning;content-addressable storage;encoding;knowledge representation;neural nets;analogical episodes;analogical mapping;analogical reasoning;associative-projective neural network architecture;associative-projective neural networks;binary sparse distributed codes;binary spatter codes;comparative description;compositional distributed representations;context-dependent thinning;distributed auto-associative memory;fixed dimensionality codevectors;holographic reduced representations;on-the-fly construction;represented structures;semantic similarity;sparse binary distributed representation;structure processing;structured data;structured memory array;Artificial intelligence;Computational modeling;Cybernetics;Distributed computing;Helium;Holography;Humans;Neural networks;Neurons;Tensile stress},
  owner        = {flo},
  timestamp    = {2017.04.27},
}

@Unpublished{Rachkovskij2000,
  author    = {Dmitri A. Rachkovskij and Ernst M. Kussul},
  date      = {2000},
  title     = {Building large-scale hierarchical models of the world with binary sparse distributed representations},
  url       = {http://cogprints.org/1287/},
  abstract  = {Many researchers agree on the basic architecture of the "world model" where knowledge about the world required for organization of agent's intelligent behavior is represented. However, most proposals on possible implementation of such a model are far from being plausible both from computational and neurobiological points of view. 
Implementation ideas based on distributed connectionist representations offer a huge information capacity, flexibility of similarity representation, and possibility to use a distributed neural network memory. However, for a long time distributed representations suffered from the "superposition catastrophe". Local representations are vivid, pictorial and easily interpretable, allow for an easy manual construction of hierarchical structures and an economical computer simulation of toy tasks. The problems of local representations show up with scaling to the real world models, and it is unclear how to solve them under reasonable requirements imposed on memory size and speed. 
We discuss the architecture of Associative-Projective Neural Networks (APNNs) that is based on binary sparse distributed representations of fixed dimensionality for items of various complexity and generality, and provides a promise for scaling up to the full-sized model of the real world. An on-the-fly binding procedure proposed for APNNs overcomes the superposition catastrophe, permitting representation of the order and grouping of structure components. These representations allow a simple estimation of structures' similarity, as well as finding various kinds of associations based on their context-dependent similarity. Structured distributed auto-associative neural network is used as long-term memory, wherein representations of items organized into part-whole (compositional) and concept (generalization) hierarchies are built. Examples of schematic APNN architectures and processes for recognition, prediction, reaction, analogical reasoning, and other tasks required for functioning of an intelligent system, as well as APNN implementations, are considered.},
  file      = {:pdf-files/Rachkovskij2000 - Building Large Scale Hierarchical Models of the World with Binary Sparse Distributed Representations.pdf:PDF},
  groups    = {Vector Symbolic Architectures},
  keywords  = {analogy, analogical mapping,analogical retrieval, APNN, associative-projective neural networks, binary coding, binding, categories, chunking, compositional distributed representations, concepts, concept hierarchy, connectionist symbol processing, context-dependent thinning, distributed memory, distributed representations, Hebb, long-term memory, nested representations, neural assemblies, part-whole hierarchy, representation of structure, sparse coding, taxonomy hierarchy, thinning, working memory, world model},
  owner     = {flo},
  timestamp = {2017.05.03},
}

@Article{Rachkovskij2013,
  author       = {Dmitri A. Rachkovskij and Ernst M. Kussul and Tatiana N. Baidyk},
  date         = {2013},
  journaltitle = {Biologically Inspired Cognitive Architectures},
  title        = {Building a world model with structure-sensitive sparse binary distributed representations},
  doi          = {10.1016/j.bica.2012.09.004},
  issn         = {2212-683X},
  pages        = {64--86},
  url          = {http://www.sciencedirect.com/science/article/pii/S2212683X12000552},
  volume       = {3},
  abstract     = {We present a new cognitive architecture named Associative-Projective Neural Networks (APNNs). \{APNNs\} have a multi-module, multi-level, and multi-modal design that works with an original scheme of sparse binary distributed representations to construct world models of varied complexity required for both task-specific and more general cognitive modeling. \{APNNs\} provide scalability and flexibility due to a number of design features. Internal representations of \{APNNs\} are sparse binary vectors of fixed dimensionality for items of various complexity and generality. Representations of input scalars, vectors, or compositional relational structures are constructed on-the-fly, so that similar items produce representations similar in terms of vector dot-products. Thus, for example, similarity of relational structures (taking into account similarity of their components, their grouping and order) can be estimated by dot-products of their representations, without the need to follow edges or to match vertices of underlying graphs. Decoding distributed representations through the input representations is also possible. Storage, retrieval, and decoding of distributed representations are implemented by efficient auto-associative memories; using distributed memories based on the idea of Hebb's cell assemblies additionally provides a natural tool for emergence of generalization hierarchies. In addition, we consider how \{APNNs\} account for representation grounding, deal with recent challenges for distributed representations, and present some open problems.},
  file         = {:pdf-files/Rachkovskij2013 - Building a World Model with Structure Sensitive Sparse Binary Distributed Representations.pdf:PDF},
  groups       = {Vector Symbolic Architectures},
  keywords     = {Associative-Projective Neural Networks},
  owner        = {flo},
  timestamp    = {2017.04.26},
}

@PhdThesis{Rasmussen2014a,
  author      = {Rasmussen, Daniel},
  title       = {Hierarchical reinforcement learning in a biologically plausible neural architecture},
  institution = {University of Waterloo},
  date        = {2014},
  type        = {PhD thesis},
  url         = {http://hdl.handle.net/10012/8943},
  file        = {:pdf-files/Rasmussen2014a - Hierarchical Reinforcement Learning in a Biologically Plausible Neural Architecture.pdf:PDF;Rasmussen_Daniel.pdf:https\://uwspace.uwaterloo.ca/bitstream/handle/10012/8943/Rasmussen_Daniel.pdf:PDF},
  groups      = {ReinforcementLearning},
  owner       = {flo},
  timestamp   = {2016.10.19},
}

@InProceedings{Rasmussen2014,
  author    = {Rasmussen, Daniel and Eliasmith, Chris},
  title     = {A neural model of hierarchical reinforcement learning},
  booktitle = {Proceedings of the 36th Annual Conference of the Cognitive Science Society},
  date      = {2014},
  editor    = {Bello, Paul and Guarini, Marcello and McShane, Marjorie and Scassellati, Brian},
  publisher = {Cognitive Science Society},
  location  = {Austin},
  pages     = {1252--1257},
  url       = {https://mindmodeling.org/cogsci2014/papers/221/index.html},
  file      = {:pdf-files/Rasmussen2014 - A Neural Model of Hierarchical Reinforcement Learning.pdf:PDF;paper221.pdf:https\://mindmodeling.org/cogsci2014/papers/221/paper221.pdf:PDF},
  groups    = {ReinforcementLearning},
  owner     = {flo},
  timestamp = {2016.10.19},
}

@InProceedings{Rasouli_2017,
  author    = {Rasouli, Amir and Kotseruba, Iuliia and Tsotsos, John K.},
  title     = {Are They Going to Cross? A Benchmark Dataset and Baseline for Pedestrian Crosswalk Behavior},
  booktitle = {The IEEE International Conference on Computer Vision (ICCV) Workshops},
  date      = {2017},
  file      = {:pdf-files/Rasouli_2017 - Are They Going to Cross_ a Benchmark Dataset and Baseline for Pedestrian Crosswalk Behavior.pdf:PDF},
  groups    = {Behaviour analysis},
  owner     = {flo},
  timestamp = {2018.03.22},
}

@Article{Reichel2005,
  author       = {Reichel, Lukas and Liechti, David and Presser, Karl and Liu, Shih-Chii},
  title        = {{R}ange estimation on a robot using neuromorphic motion sensors},
  journaltitle = {Robotics and autonomous systems},
  date         = {2005},
  volume       = {51},
  number       = {2-3},
  pages        = {167--174},
  file         = {:pdf-files/Reichel2005 - Range Estimation on a Robot Using Neuromorphic Motion Sensors.pdf:PDF},
  groups       = {Neuromorphic Robotics, Neuromorphic Hardware},
  owner        = {flo},
  timestamp    = {2016.01.18},
}

@Article{ReverterValeiras2016,
  author       = {Reverter Valeiras, David and Orchard, Garrick and Ieng, Sio Hoi and Benosman, Ryad Benjamin},
  title        = {{N}euromorphic {E}vent-{B}ased 3{D} {P}ose {E}stimation},
  journaltitle = {Frontiers in Neuroscience},
  date         = {2016},
  volume       = {9},
  number       = {522},
  issn         = {1662-453X},
  doi          = {10.3389/fnins.2015.00522},
  abstract     = {Pose estimation is a fundamental step in many artificial vision tasks. It consists of estimating the 3D pose of an object with respect to a camera from the object's 2D projection. Current state of the art implementations operate on images. These implementations are computationally expensive, especially for real-time applications. Scenes with fast dynamics exceeding 30-60 Hz can rarely be processed in real-time using conventional hardware. This paper presents a new method for event-based 3D object pose estimation, making full use of the high temporal resolution (1 $\mu$s) of asynchronous visual events output from a single neuromorphic camera. Given an initial estimate of the pose, each incoming event is used to update the pose by combining both 3D and 2D criteria. We show that the asynchronous high temporal resolution of the neuromorphic camera allows us to solve the problem in an incremental manner, achieving real-time performance at an update rate of several hundreds kHz on a conventional laptop. We show that the high temporal resolution of neuromorphic cameras is a key feature for performing accurate pose estimation. Experiments are provided showing the performance of the algorithm on real data, including fast moving objects, occlusions, and cases where the neuromorphic camera and the object are both in motion.},
  file         = {:pdf-files/ReverterValeiras2016 - Neuromorphic Event Based 3D Pose Estimation.pdf:PDF},
  groups       = {Neuromorphic Vision},
  owner        = {flo},
  timestamp    = {2016.02.09},
}

@Article{Richert2011,
  author       = {Micah Richert and Jayram Moorkanikara Nageswaran and Nikil Dutt and Jeffrey L. Krichmar},
  title        = {An Efficient Simulation Environment for Modeling Large-Scale Cortical Processing},
  journal      = {Frontiers in Neuroinformatics},
  journaltitle = {Frontiers in Neuroinformatics},
  year         = {2011},
  date         = {2011},
  volume       = {5},
  number       = {19},
  issn         = {1662-5196},
  doi          = {10.3389/fninf.2011.00019},
  abstract     = {We have developed a spiking neural network simulator, which is both easy to use and computationally efficient, for the generation of large-scale computational neuroscience models. The simulator implements current or conductance based Izhikevich neuron networks, having spike-timing dependent plasticity and short-term plasticity. It uses a standard network construction interface. The simulator allows for execution on either GPUs or CPUs. The simulator, which is written in C/C++, allows for both fine grain and coarse grain specificity of a host of parameters. We demonstrate the ease of use and computational efficiency of this model by implementing a large-scale model of cortical areas V1, V4, and area MT. The complete model, which has 138,240 neurons and approximately 30 million synapses, runs in real-time on an off-the-shelf GPU. The simulator source code, as well as the source code for the cortical model examples is publicly available.},
  file         = {:pdf-files/Richert2011 - An Efficient Simulation Environment for Modeling Large Scale Cortical Processing.pdf:PDF},
  groups       = {Neural Modelling},
  owner        = {flo},
  publisher    = {Frontiers Media {SA}},
  timestamp    = {2016.01.18},
}

@Book{Rojas1996,
  author    = {Rojas, Ra{\'u}l},
  title     = {{Neural Networks: A Systematic Introduction}},
  date      = {1996},
  publisher = {Springer-Verlag New York, Inc.},
  location  = {New York, NY, USA},
  isbn      = {3-540-60505-3},
  file      = {:pdf-files/Rojas1996 - Neural Networks_ a Systematic Introduction.pdf:PDF},
  groups    = {Neural Networks},
  owner     = {flo},
  timestamp = {2016.01.18},
}

@Article{Rosenblatt58,
  author       = {Rosenblatt, Frank},
  title        = {The {P}erceptron: A Probabilistic Model for Information Storage and Organization in the Brain},
  journaltitle = {Psychological Review},
  date         = {1958},
  volume       = {65},
  number       = {6},
  pages        = {386--408},
  file         = {:pdf-files/Rosenblatt58 - The Perceptron_ a Probabilistic Model for Information Storage and Organization in the Brain.pdf:PDF},
  groups       = {Machine Learning, Neural Networks},
  keywords     = {imported},
  owner        = {flo},
  timestamp    = {2016.02.08},
}

@Article{Rouder2006,
  author       = {Jeffrey N. Rouder and Roger Ratcliff},
  date         = {2006},
  journaltitle = {Current Directions in Psychological Science},
  title        = {Comparing Exemplar- and Rule-Based Theories of Categorization},
  doi          = {10.1111/j.0963-7214.2006.00397.x},
  eprint       = {http://dx.doi.org/10.1111/j.0963-7214.2006.00397.x},
  number       = {1},
  pages        = {9--13},
  volume       = {15},
  abstract     = {We address whether human categorization behavior is based on abstracted rules or stored exemplars. Although predictions of both theories often mimic each other in many designs, they can be differentiated. Experimental data reviewed does not support either theory exclusively. We find participants use rules when the stimuli are confusable and exemplars when they are distinct. By drawing on the distinction between simple stimuli (such as lines of various lengths) and complex ones (such as words and objects), we offer a dynamic view of category learning. Initially, categorization is based on rules. During learning, suitable features for discriminating stimuli may be gradually learned. Then, stimuli can be stored as exemplars and used to categorize novel stimuli without recourse to rules.},
  file         = {:pdf-files/Rouder2006 - Comparing Exemplar and Rule Based Theories of Categorization.pdf:PDF},
  groups       = {Neuroscience},
  owner        = {flo},
  timestamp    = {2017.04.26},
}

@InCollection{Rudolph2017,
  author    = {Rudolph, Maja and Ruiz, Francisco and Athey, Susan and Blei, David},
  title     = {Structured {E}mbedding {M}odels for {G}rouped {D}ata},
  booktitle = {Advances in Neural Information Processing Systems 30},
  date      = {2017},
  editor    = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
  publisher = {Curran Associates, Inc.},
  pages     = {250--260},
  url       = {http://papers.nips.cc/paper/6629-structured-embedding-models-for-grouped-data.pdf},
  file      = {:pdf-files/Rudolph2017 - Structured Embedding Models for Grouped Data.pdf:PDF},
  groups    = {Word Embedding},
  owner     = {flo},
  timestamp = {2017.12.20},
}

@Article{Rumelhart1986,
  author       = {David E. Rumelhart and Geoffrey E. Hinton and Ronald J. Williams},
  title        = {Learning representations by back-propagating errors},
  journaltitle = {Nature},
  year         = {1986},
  date         = {1986},
  volume       = {323},
  number       = {6088},
  pages        = {533--536},
  doi          = {10.1038/323533a0},
  url          = {https://www.nature.com/articles/323533a0},
  file         = {:pdf-files/Rumelhart1988 - Neurocomputing_ Foundations of Research.pdf:PDF},
  groups       = {Machine Learning, Neural Networks},
  numpages     = {4},
  owner        = {flo},
  publisher    = {Springer Nature},
  timestamp    = {2016.02.03},
}

@Article{Suetfeld2017,
  author       = {S{\"u}tfeld, Leon R. and Gast, Richard and K{\"o}nig, Peter and Pipa, Gordon},
  title        = {Using {V}irtual {R}eality to {A}ssess {E}thical {D}ecisions in {R}oad {T}raffic {S}cenarios: {A}pplicability of {V}alue-of-{L}ife-{B}ased {M}odels and {I}nfluences of {T}ime {P}ressure},
  journaltitle = {Frontiers in Behavioral Neuroscience},
  date         = {2017},
  volume       = {11},
  pages        = {122},
  issn         = {1662-5153},
  doi          = {10.3389/fnbeh.2017.00122},
  abstract     = {Self-driving cars are posing a new challenge to our ethics. By using algorithms to make decisions in situations where harming humans is possible, probable, or even unavoidable, a self-driving car's ethical behavior comes pre-defined. Ad hoc decisions are made in milliseconds, but can be based on extensive research and debates. The same algorithms are also likely to be used in millions of cars at a time, increasing the impact of any inherent biases, and increasing the importance of getting it right. Previous research has shown that moral judgment and behavior are highly context-dependent, and comprehensive and nuanced models of the underlying cognitive processes are out of reach to date. Models of ethics for self-driving cars should thus aim to match human decisions made in the same context. We employed immersive virtual reality to assess ethical behavior in simulated road traffic scenarios, and used the collected data to train and evaluate a range of decision models. In the study, participants controlled a virtual car and had to choose which of two given obstacles they would sacrifice in order to spare the other. We randomly sampled obstacles from a variety of inanimate objects, animals and humans. Our model comparison shows that simple models based on one-dimensional value-of-life scales are suited to describe human ethical behavior in these situations. Furthermore, we examined the influence of severe time pressure on the decision-making process. We found that it decreases consistency in the decision patterns, thus providing an argument for algorithmic decision-making in road traffic. This study demonstrates the suitability of virtual reality for the assessment of ethical behavior in humans, delivering consistent results across subjects, while closely matching the experimental settings to the real world scenarios in question.},
  file         = {:pdf-files/Suetfeld2017 - Using Virtual Reality to Assess Ethical Decisions in Road Traffic Scenarios_ Applicability of Value of Life Based Models and Influences of Time Pressure.pdf:PDF},
  groups       = {Autonomous Driving},
  owner        = {flo},
  timestamp    = {2017.08.03},
}

@Article{Sabour2017,
  author       = {Sara Sabour and Nicholas Frosst and Geoffrey Hinton},
  title        = {Dynamic {R}outing between {C}apsules},
  journaltitle = {Computing Research Repository (CoRR)},
  year         = {2017},
  date         = {2017},
  url          = {https://arxiv.org/abs/1710.09829},
  abstract     = {A capsule is a group of neurons whose activity vector represents the instantiation
parameters of a specific type of entity such as an object or object part. We use the
length of the activity vector to represent the probability that the entity exists and its
orientation to represent the instantiation paramters. Active capsules at one level
make predictions, via transformation matrices, for the instantiation parameters of
higher-level capsules. When multiple predictions agree, a higher level capsule
becomes active. We show that a discrimininatively trained, multi-layer capsule
system achieves state-of-the-art performance on MNIST and is considerably better
than a convolutional net at recognizing highly overlapping digits. To achieve these
results we use an iterative routing-by-agreement mechanism: A lower-level capsule
prefers to send its output to higher level capsules whose activity vectors have a big
scalar product with the prediction coming from the lower-level capsule.},
  comment      = {https://www.youtube.com/watch?v=rTawFwUvnLE},
  file         = {:pdf-files/Sabour2017 - Dynamic Routing between Capsules.pdf:PDF},
  groups       = {Machine Learning},
  owner        = {flo},
  timestamp    = {2017.11.06},
}

@TechReport{SAE_J3016,
  author      = {SAE},
  title       = {J3016, Taxonomy and Definitions for Terms Related to Driving Automation Systems for On-Road Motor Vehicles},
  institution = {SAE International},
  date        = {2016},
  doi         = {10.4271/J3016_201609},
  url         = {https://www.sae.org/standards/content/j3016_201609/},
  urldate     = {02.02.2018},
  file        = {:pdf-files/SAE_J3016 - J3016, Taxonomy and Definitions for Terms Related to Driving Automation Systems for on Road Motor Vehicles.pdf:PDF},
  groups      = {Autonomous Driving},
  owner       = {flo},
  timestamp   = {2018.02.02},
  year        = {2016},
}

@InCollection{Sahlgren2008,
  author               = {Sahlgren, Magnus and Holst, Anders and Kanerva, Pentti},
  title                = {{Permutations as a means to encode order in word space}},
  booktitle            = {Proceedings of the 30th Annual Conference of the Cognitive Science Society},
  date                 = {2008},
  editor               = {Sloutsky, V. and Love, B. and Mcrae, K.},
  publisher            = {Cognitive Science Society},
  location             = {Austin, TX},
  pages                = {1300--1305},
  url                  = {http://www.sics.se/\~{}mange/papers/permutationsCogSci08.pdf},
  abstract             = {We show that sequence information can be encoded into high-
dimensional fixed-width vectors using permutations of coor-
dinates. Computational models of language often represent
words with high-dimensional semantic vectors compiled from
word-use statistics. A word's semantic vector usually encodes
the contexts in which the word appears in a large body of text
but ignores word order. However, word order often signals a
word's grammatical role in a sentence and thus tells of the
word's meaning. Jones and Mewhort (2007) show that word or-
der can be included in the semantic vectors using holographic
reduced representation and convolution. We show here that the
order information can be captured also by permuting of vec-
tor coordinates, thus providing a general and computationally
light alternative to convolution.},
  citeulike-article-id = {3132971},
  citeulike-linkout-0  = {http://www.sics.se/\~{}mange/papers/permutationsCogSci08.pdf},
  file                 = {:pdf-files/Sahlgren2008 - Permutations As a Means to Encode Order in Word Space.pdf:PDF},
  groups               = {Vector Symbolic Architectures},
  keywords             = {distributional-similarity},
  owner                = {flo},
  posted-at            = {2008-08-18 16:01:17},
  timestamp            = {2017.06.30},
}

@Article{Samsonovich2012,
  author       = {Alexei V. Samsonovich},
  title        = {On a roadmap for the {BICA} Challenge},
  journaltitle = {Biologically Inspired Cognitive Architectures},
  date         = {2012},
  volume       = {1},
  pages        = {100--107},
  issn         = {2212-683X},
  doi          = {10.1016/j.bica.2012.05.002},
  url          = {http://www.sciencedirect.com/science/article/pii/S2212683X12000126},
  abstract     = {The \{BICA\} Challenge is the challenge to create a general-purpose, real-life computational equivalent of the human mind using an approach based on biologically inspired cognitive architectures (BICA). To solve it, we need to understand at a computational level how natural intelligent systems develop their cognitive, metacognitive and learning functions. The solution is expected to lead us to a breakthrough to intelligent agents integrated into the human society as its members. This outcome has the potential to solve many problems of the modern world. The article starts from the roadmap proposed by Dr. James Albus for a national program unifying artificial intelligence, neuroscience and cognitive science. The \{BICA\} Challenge is introduced in this context as a waypoint on the expanded roadmap. The gap between the state of the art and challenge demands is analyzed. Specific problems and barriers are identified, an approach to overcoming them is proposed, and an ultimate practical criterion for success is formulated. It is estimated that the \{BICA\} Challenge can be solved within a decade.},
  file         = {:pdf-files/Samsonovich2012 - On a Roadmap for the BICA Challenge.pdf:PDF},
  groups       = {Vector Symbolic Architectures, Neuroscience},
  keywords     = {Human-level AI},
  owner        = {flo},
  timestamp    = {2017.05.03},
}

@Article{Sandin2014,
  author       = {Sandin, F. and Khan, A. I. and Dyer, A. G. and Amin, A. H. M. and Indiveri, G. and Chicca, Elisabetta and Osipov, E.},
  title        = {{Concept Learning in Neuromorphic Vision Systems: What Can We Learn from Insects?}},
  journaltitle = {Journal of Software Engineering and Applications},
  date         = {2014},
  volume       = {7},
  number       = {5},
  pages        = {387--395},
  doi          = {10.4236/jsea.2014.75035},
  abstract     = {Vision systems that enable collision avoidance, localization and navigation in complex and uncertain environments are common in biology, but are extremely challenging to mimic in artificial electronic systems, in particular when size and power limitations apply. The development of neuromorphic electronic systems implementing models of biological sensory-motor systems in silicon is one promising approach to addressing these challenges. Concept learning is a central part of animal cognition that enables appropriate motor response in novel situations by generalization of former experience, possibly from a few examples. These aspects make concept learning a challenging and important problem. Learning methods in computer vision are typically inspired by mammals, but recent studies of insects motivate an interesting complementary research direction. There are several remarkable results showing that honeybees can learn to master abstract concepts, providing a road map for future work to allow direct comparisons between bio-inspired computing architectures and information processing in miniaturized "real" brains. Considering that the brain of a bee has less than 0.01\% as many neurons as a human brain, the task to infer a minimal architecture and mechanism of concept learning from studies of bees appears well motivated. The relatively low complexity of insect sensory-motor systems makes them an interesting model for the further development of bio-inspired computing architectures, in particular for resource-constrained applications such as miniature robots, wireless sensors and handheld or wearable devices. Work in that direction is a natural step towards understanding and making use of prototype circuits for concept learning, which eventually may also help us to understand the more complex learning circuits of the human brain. By adapting concept learning mechanisms to a polymorphic computing framework we could possibly create large-scale decentralized computer vision systems, for example in the form of wireless sensor networks.},
  file         = {:pdf-files/Sandin2014 - Concept Learning in Neuromorphic Vision Systems_ What Can We Learn from Insects_.pdf:PDF},
  groups       = {Neuromorphic Computing, Vector Symbolic Architectures},
  keyword      = {Concept Learning, Computer Vision, Computer Architecture, Neuromorphic Engineering, Insect},
  owner        = {flo},
  publisher    = {Scientific Research Publishing, Inc,},
  timestamp    = {2017.06.19},
}

@InProceedings{Saner2014,
  author    = {Saner, Daniel and Wang, Oliver and Heinzle, Simon and Pritch, Yael and Smolic, Aljoscha and Sorkine-Hornung, Alexander and Gross, Markus},
  title     = {{H}igh-{S}peed {O}bject {T}racking {U}sing an {A}synchronous {T}emporal {C}ontrast {S}ensor},
  booktitle = {{VMV} 2014: Vision, Modeling {\&} Visualization, Darmstadt, Germany, 2014. Proceedings},
  date      = {2014},
  publisher = {European Association for Computer Graphics},
  file      = {:pdf-files/Saner2014 - High Speed Object Tracking Using an Asynchronous Temporal Contrast Sensor.pdf:PDF},
  groups    = {Neuromorphic Vision},
  owner     = {flo},
  timestamp = {2016.01.26},
}

@Article{Santoro2017,
  author       = {{Santoro}, A. and {Raposo}, D. and {Barrett}, D.~G.~T. and {Malinowski}, M. and {Pascanu}, R. and {Battaglia}, P. and {Lillicrap}, T.},
  title        = {{A simple neural network module for relational reasoning}},
  journaltitle = {ArXiv e-prints},
  date         = {2017},
  eprint       = {1706.01427},
  url          = {https://arxiv.org/abs/1706.01427},
  file         = {:pdf-files/Santoro2017 - A Simple Neural Network Module for Relational Reasoning.pdf:PDF},
  groups       = {Deep Neural Networks},
  keywords     = {Computer Science - Computation and Language, Computer Science - Learning},
  owner        = {flo},
  timestamp    = {2017.07.05},
}

@InCollection{Schapire2003,
  author    = {Robert E. Schapire},
  title     = {The Boosting Approach to Machine Learning: An Overview},
  booktitle = {Nonlinear Estimation and Classification},
  year      = {2003},
  date      = {2003},
  editor    = {Denison, David D. and Hansen, Mark H. and Holmes, Christopher C. and Mallick, Bani and Yu, Bin},
  publisher = {Springer New York},
  location  = {New York, NY},
  isbn      = {978-0-387-21579-2},
  chapter   = {The Boosting Approach to Machine Learning: An Overview},
  pages     = {149--171},
  doi       = {10.1007/978-0-387-21579-2_9},
  file      = {:pdf-files/Schapire2003 - Nonlinear Estimation and Classification.pdf:PDF},
  groups    = {Machine Learning, Boosting},
  owner     = {flo},
  timestamp = {2016.02.09},
}

@InCollection{Schapire2013,
  author    = {Robert E. Schapire},
  title     = {Explaining {AdaBoost}},
  booktitle = {Empirical Inference},
  year      = {2013},
  date      = {2013},
  editor    = {Sch{\"o}lkopf, Bernhard and Luo, Zhiyuan and Vovk, Vladimir},
  publisher = {Springer Berlin Heidelberg},
  location  = {Berlin, Heidelberg},
  isbn      = {978-3-642-41136-6},
  pages     = {37--52},
  doi       = {10.1007/978-3-642-41136-6_5},
  file      = {:pdf-files/Schapire2013 - Empirical Inference_ Festschrift in Honor of Vladimir N. Vapnik.pdf:PDF},
  groups    = {Machine Learning, Boosting},
  owner     = {flo},
  timestamp = {2016.02.09},
}

@InProceedings{Schemmel2010,
  author    = {Schemmel, J. and Br{\"u}derle, D. and Gr{\"u}bl, A. and Hock, M. and Meier, K. and Millner, S.},
  title     = {A wafer-scale neuromorphic hardware system for large-scale neural modeling},
  booktitle = {Circuits and Systems (ISCAS), Proceedings of 2010 IEEE International Symposium on},
  date      = {2010},
  pages     = {1947--1950},
  doi       = {10.1109/ISCAS.2010.5536970},
  abstract  = {Modeling neural tissue is an important tool to investigate biological neural networks. Until recently, most of this modeling has been done using numerical methods. In the European research project "FACETS" this computational approach is complemented by different kinds of neuromorphic systems. A special emphasis lies in the usability of these systems for neuroscience. To accomplish this goal an integrated software/hardware framework has been developed which is centered around a unified neural system description language, called PyNN, that allows the scientist to describe a model and execute it in a transparent fashion on either a neuromorphic hardware system or a numerical simulator. A very large analog neuromorphic hardware system developed within FACETS is able to use complex neural models as well as realistic network topologies, i.e. it can realize more than 10000 synapses per neuron, to allow the direct execution of models which previously could have been simulated numerically only.},
  comment   = {FACETS-Project, Brain-ScaleS},
  file      = {:pdf-files/Schemmel2010 - A Wafer Scale Neuromorphic Hardware System for Large Scale Neural Modeling.pdf:PDF},
  groups    = {Neuromorphic Hardware},
  keywords  = {complex networks;neural nets;neurophysiology;European research project;FACETS project;PyNN language;biological neural networks;large scale neural modeling;neural tissue;neuroscience;wafer scale neuromorphic hardware system;Biological neural networks;Biological system modeling;Biological tissues;Biology computing;Hardware;Large-scale systems;Neuromorphics;Numerical simulation;Semiconductor device modeling;Usability},
  owner     = {flo},
  timestamp = {2016.02.18},
}

@InProceedings{Schmuedderich2015,
  author    = {Jens Schm{\"u}dderich AND Sven Rebhan AND Thomas Weisswange AND Marcus Kleinehagenbrock AND Robert Kastner AND Morimichi Nishigaki AND Shunsuke Kusuhara AND Hiroyuki Kamiya AND Naoki Mori AND Shinnosuke Ishida},
  booktitle = {Future Active Safety Technology Towards zero traffic accidents (FAST-zero)},
  date      = {2015},
  title     = {A novel approach to driver behavior prediction using scene context and physical evidence for intelligent Adaptive Cruise Control (i-ACC)},
  publisher = {FISITA},
  abstract  = {Conventional driver assistance systems react to another traffic participant{\textquoteright}s behavior as soon as it becomes apparent. In other words, they react as soon as the host vehicle{\textquoteright}s sensors detect the start of another vehicle{\textquoteright}s change of behavior. ACC systems, for example, react to a cutting-in vehicle when the sensors measure a significant lateral motion or displacement. However, a change of behavior is usually the effect of adapting to the current driving situation, i.e. a driver will change lane to overtake a slower vehicle driving ahead of him. Therefore attentive drivers are well capable of foreseeing or predicting another vehicle{\textquoteright}s behavior before this behavior actually starts. To bridge this gap between technical systems and human capabilities, future active safety technology should therefore base upon prediction to offer what we call {\textquotedblleft}assistance beyond sensing{\textquotedblright}.
In this contribution we will present a novel approach for the prediction of other vehicles{\textquoteright} behaviors. This approach combines a prediction based on the contextual situation of the predicted vehicle with physical evidence of its movement. The prediction based on the contextual situation, which we call context-based prediction, builds relations between vehicles and the infrastructure. These relations are evaluated by calculating features indicative for a future behavior. One indicator for example, evaluates if a vehicle is significantly faster than its predecessor and if there is a gap available on the neighboring lane into which the vehicle could cut-in. A suited combination of the resulting indicators leads to confidence scores for a set of future behavior alternatives. This kind of prediction explicitly excludes the phenomenological appearance of a behavior. That means, the prediction of a cut-in bases on the relations between the cutting-in vehicle and its surroundings, but it excludes any information about lateral displacement or a physical motion trajectory. As an effect, this kind of prediction approach is capable of predicting behaviors multiple seconds before they even start, but it requires a correct detection of the scene context.
The detection of the scene context poses an additional challenge for the sensor system. To achieve a reliable estimate of future behaviors in all cases, an additional physical prediction approach is used. This physical prediction compares a history of recently measured vehicle positions to a set of trajectories, each representative for a set of different behaviors. The pointwise comparison results in a likelihood estimate for each behavior from a set of different behavior options. This prediction approach is capable of reliably predicting a behavior as soon as it started and it does not require further context information. In this contribution we will show a novel combination of the context-based and physical prediction, characterized in keeping each prediction self-contained to trigger subtle host vehicle actions, but also combining the predictions to a most reliable, early prediction, which is used to trigger effective host vehicle actions for keeping the driver safe and comfortable.
In Honda{\textquoteright}s new intelligent Adaptive Cruise Control this prediction is used to trigger a two staged braking maneuver if a vehicle on the neighboring lane is predicted to cut-in: If only one of the prediction algorithms predicts a cut-in, a mild braking is applied, comparable to a driver releasing the gas pedal. By design, this is usually the case for early predictions calculated by the context-based prediction algorithm. As soon as both prediction algorithms predict a cut-in, the braking force is increased as required to stay safely behind the cutting-in vehicle.
In this contribution we will present a quantitative evaluation of the proposed prediction method. To this means, we extracted 15.000km from our recordings of driving with a prototype vehicle equipped with i-ACC on European highways. This subset is a representative sample in terms of varying traffic density, weather conditions, and driving style. To measure the proficiency of the proposed prediction system we evaluated two different aspects {\textendash} the prediction accuracy and the prediction horizon, i.e. the timespan before a cut-in for which an accurate prediction can be achieved.
The prediction accuracy is evaluated by Receiver-Operating-Characteristics (ROC). Therefore the prediction of cut-ins is considered as classification problem and a variable threshold is applied to the confidence values for a predicted cut-in behavior. If the prediction confidence exceeds the chosen threshold, the algorithm predicts a cut-in, otherwise it predicts no cut-in. The resulting prediction is compared to manually annotated ground-truth of cut-ins and leads to a true-positive-rate and a false-positive per hour score. By varying the threshold an optimal trade-off between true-positive-rate and false positives per hour is chosen. In this publication we chose a threshold leading to a true positive rate of 85\% of all targeted situations at one false positive in 10hours. It has to be noted, that in all these false-positive cases only one of the two prediction algorithms predicts a cut-in. Thus the resulting false-positive braking maneuvers are only mild and not strong.
To evaluate the prediction horizon we annotated the time of the cut-in by selecting the point in time when the right tire of the cutting-in vehicle touches the right lane marker. This point resembles the time when the best currently commercially available competitor system reacts to the cut-in. We measure the time between this annotated cut-in and the first positive prediction defined by the threshold chosen above. This evaluation shows that our system predicts a cut-in on average 2.4s before the annotation point. The maximum achieved prediction horizon is 7.2s before the annotation point. An analysis also indicates a dependence of the prediction time horizon and the prediction accuracy: Decreasing the threshold leads to an increased prediction time horizon and increases true positive rate, but at the cost of increasing false-positives.
To summarize this contribution presents a novel approach for predicting other vehicles behavior by combining a context-based prediction with a physical prediction. The evaluation shows the efficiency of this proposed approach, which is now commercially available in the 2015 Honda CR-V. A companion paper with the title {\textquotedblleft}Introduction of Intelligent Adaptive Cruise Control (i-ACC) {\textendash} a predictive safety system{\textquotedblright} details the system embedding and presents a subjective user test.},
  file      = {:pdf-files/Schmuedderich2015 - A Novel Approach to Driver Behavior Prediction Using Scene Context and Physical Evidence for Intelligent Adaptive Cruise Control (i ACC).pdf:PDF},
  groups    = {Behaviour analysis},
  owner     = {flo},
  timestamp = {2017.11.15},
}

@Article{Schmidhuber2015,
  author       = {J{\"u}rgen Schmidhuber},
  title        = {{Deep Learning in Neural Networks: An Overview}},
  journaltitle = {Neural Networks},
  date         = {2015},
  volume       = {61},
  pages        = {85--117},
  note         = {Published online 2014; based on TR arXiv:1404.7828 [cs.NE]},
  doi          = {10.1016/j.neunet.2014.09.003},
  abstract     = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarises relevant work, much of it from the previous millennium. Shallow and deep learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning & evolutionary computation, and indirect search for short programs encoding deep and large networks.},
  file         = {:pdf-files/Schmidhuber2015 - Deep Learning in Neural Networks_ an Overview.pdf:PDF},
  groups       = {Machine Learning, Deep Neural Networks},
  owner        = {flo},
  timestamp    = {2016.01.28},
}

@Article{Schmidt2013,
  author       = {Robert Schmidt and Daniel K Leventhal and Nicolas Mallet and Fujun Chen and Joshua D Berke},
  title        = {Canceling actions involves a race between basal ganglia pathways},
  journal      = {Nature Neuroscience},
  journaltitle = {Nature neuroscience},
  year         = {2013},
  date         = {2013},
  volume       = {16},
  number       = {8},
  pages        = {1118--1124},
  issn         = {1546-1726},
  doi          = {10.1038/nn.3456},
  url          = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3733500/},
  abstract     = {Salient cues can prompt the rapid interruption of planned actions. It has been proposed that fast, reactive behavioral inhibition involves specific basal ganglia pathways, and we tested this by comparing activity in multiple rat basal ganglia structures during performance of a stop-signal task. Subthalamic nucleus (STN) neurons showed low-latency responses to Stop cues, irrespective of whether actions were successfully canceled or not. By contrast, neurons downstream in the substantia nigra pars reticulata (SNr) responded to Stop cues only in trials with successful cancellation. Recordings and simulations together indicate that this sensorimotor gating arises from the relative timing of two distinct inputs to neurons in the SNr dorsolateral "core" subregion: cue-related excitation from STN and movement-related inhibition from striatum. Our results support race models of action cancellation, with successful stopping requiring Stop cue information to be transmitted from STN to SNr before increased striatal input creates a point of no return.},
  comment      = {23852117[pmid] 23852117[pmid]
Review:
Race conditions in the brain (results from rat experiments)},
  file         = {:pdf-files/Schmidt2013 - Canceling Actions Involves a Race between Basal Ganglia Pathways.pdf:PDF},
  groups       = {Biology},
  owner        = {flo},
  publisher    = {Springer Nature},
  timestamp    = {2016.05.13},
}

@InProceedings{Schraml2010,
  author    = {Stephan Schraml and Ahmed Nabil Belbachir and Nenad Milosevic and Peter Schon},
  title     = {Dynamic stereo vision system for real-time tracking},
  booktitle = {Proceedings of 2010 {IEEE} International Symposium on Circuits and Systems},
  year      = {2010},
  date      = {2010},
  publisher = {{IEEE}},
  pages     = {1409--1412},
  doi       = {10.1109/ISCAS.2010.5537289},
  abstract  = {Biologically-inspired dynamic vision sensors have been introduced in 2002 which asynchronously detect the significant relative light intensity changes in a scene and output them in a form of Address-Event representation. These vision sensors capture dynamical discontinuities on-chip for a reduced data volume compared to that from intensity images. Therefore, they support detection, segmentation and tracking of moving objects in the Address-Event space by exploiting the generated events, as a reaction to intensity changes, resulting from the scene dynamics. Object tracking has been previously demonstrated and reported in scientific publications using monocular dynamic vision sensors. This paper contributes with presenting and demonstrating a tracking algorithm using the 3D sensing technology based on the stereo dynamic vision sensor. This system is capable of detecting and tracking persons within a 4m range at an effective refresh rate of the depth map of up to 200 per second. The 3D system is evaluated for people tracking and the tests showed that up to 60k Address-Events/s can be processed for real-time tracking.},
  file      = {:pdf-files/Schraml2010 - Dynamic Stereo Vision System for Real Time Tracking.pdf:PDF},
  groups    = {Neuromorphic Vision},
  keywords  = {image segmentation;object detection;optical sensors;stereo image processing;3D sensing technology;3D system;address-event representation;address-event space;biologically-inspired dynamic vision sensors;data volume reduction;dynamic stereo vision system;intensity images;light intensity changes;monocular dynamic vision sensors;moving object detection;moving object segmentation;moving object tracking;real-time tracking;scene dynamics;scientific publications;stereo dynamic vision sensor;tracking algorithm;Biosensors;Event detection;Image segmentation;Image sensors;Layout;Object detection;Real time systems;Space technology;Stereo vision;System testing},
  owner     = {flo},
  timestamp = {2016.02.18},
}

@InProceedings{Schulze2005,
  author    = {Schulze, Matthias and Noecker, Gerhard and B{\"o}hm, Konrad},
  title     = {PReVENT: A European program to improve active safety},
  booktitle = {Proc. of 5th International Conference on Intelligent Transportation Systems Telecommunications},
  date      = {2005},
  file      = {:pdf-files/Schulze2005 - PReVENT_ a European Program to Improve Active Safety.pdf:PDF},
  groups    = {Autonomous Driving},
  owner     = {flo},
  timestamp = {2018.02.23},
}

@Article{Serrano-Gotarredona2009,
  author       = {R. Serrano-Gotarredona and M. Oster and P. Lichtsteiner and A. Linares-Barranco and R. Paz-Vicente and F. Gomez-Rodriguez and L. Camunas-Mesa and R. Berner and M. Rivas-Perez and T. Delbruck and S. C. Liu and R. Douglas and P. Hafliger and G. Jimenez-Moreno and A. Civit Ballcels and T. Serrano-Gotarredona and A. J. Acosta-Jimenez and B. Linares-Barranco},
  title        = {{CAVIAR: A 45k Neuron, 5M Synapse, 12G Connects/s AER Hardware Sensory-Processing-Learning-Actuating System for High-Speed Visual Object Recognition and Tracking}},
  journaltitle = {IEEE Transactions on Neural Networks},
  date         = {2009},
  volume       = {20},
  number       = {9},
  pages        = {1417--1438},
  issn         = {1045-9227},
  doi          = {10.1109/TNN.2009.2023653},
  abstract     = {This paper describes CAVIAR, a massively parallel hardware implementation of a spike-based sensing-processing-learning-actuating system inspired by the physiology of the nervous system. CAVIAR uses the asynchronous address-event representation (AER) communication framework and was developed in the context of a European Union funded project. It has four custom mixed-signal AER chips, five custom digital AER interface components, 45 k neurons (spiking cells), up to 5 M synapses, performs 12 G synaptic operations per second, and achieves millisecond object recognition and tracking latencies.},
  comment      = {four year project funded by the European Union under the FP5-IST program in June 2002, within the "Lifelike perception systems" subprogram. Its main objective was to develop a bio-inspired multi-chip multi-layer hierarchical sensing/processing/actuation system where the chips communicate using an AER infrastructure.},
  file         = {:pdf-files/Serrano-Gotarredona2009 - CAVIAR_ a 45k Neuron, 5M Synapse, 12G Connects_s AER Hardware Sensory Processing Learning Actuating System for High Speed Visual Object Recognition and Tracking.pdf:PDF},
  groups       = {Neuromorphic Hardware},
  keywords     = {biocomputing;computer vision;feedforward;neurophysiology;object detection;object recognition;parallel architectures;CAVIAR;European Union funded project;asynchronous address-event representation communication framework;custom digital AER interface components;custom mixed-signal AER chips;high-speed visual object recognition;high-speed visual object tracking;nervous system;parallel hardware implementation;physiology;spike-based sensing-processing-learning-actuating system;Address-event representation (AER);neuromorphic chips;neuromorphic systems;vision;Action Potentials;Artificial Intelligence;Computers;Humans;Learning;Motion Perception;Neural Networks (Computer);Neurons;Pattern Recognition, Visual;Psychomotor Performance;Retina;Synapses;Time Factors;Vision, Ocular;Visual Perception},
  owner        = {flo},
  timestamp    = {2016.03.29},
}

@Article{Serrano-Gotarredona2013,
  author       = {T. Serrano-Gotarredona and B. Linares-Barranco},
  title        = {A 128x128 1.5\% {C}ontrast {S}ensitivity 0.9\% {FPN} 3 $\mu$s {L}atency 4 {mW} {A}synchronous {F}rame-{F}ree {D}ynamic {V}ision {S}ensor {U}sing {T}ransimpedance {P}reamplifiers},
  journaltitle = {IEEE Journal of Solid-State Circuits},
  date         = {2013},
  volume       = {48},
  number       = {3},
  pages        = {827--838},
  issn         = {0018-9200},
  doi          = {10.1109/JSSC.2012.2230553},
  abstract     = {Dynamic Vision Sensors (DVS) have recently appeared as a new paradigm for vision sensing and processing. They feature unique characteristics such as contrast coding under wide illumination variation, micro-second latency response to fast stimuli, and low output data rates (which greatly improves the efficiency of post-processing stages). They can track extremely fast objects (e.g., time resolution is better than 100 kFrames/s video) without special lighting
 conditions. Their availability has triggered a new range of vision applications in the fields of surveillance, motion analyses, robotics, and microscopic dynamic observations. One key DVS feature is contrast sensitivity, which has so far been reported to be in the 10-15\% range. In this paper, a novel pixel photo sensing and transimpedance pre-amplification stage makes it possible to improve by one order of magnitude contrast sensitivity (down to 1.5\%) and power (down to 4 mW), reduce the
 best reported FPN (Fixed Pattern Noise) by a factor of 2 (down to 0.9\%), while maintaining the shortest reported latency (3 $\mu$s) and good Dynamic Range (120 dB), and further reducing overall area (down to 30 $\times$ 31 $\mu$m per pixel). The only penalty is the limitation of intrascene Dynamic Range to 3 decades. A 128 $\times$ 128 DVS test prototype has been fabricated in standard 0.35 $\mu$m CMOS and extensive experimental characterization results are provided.},
  file         = {:pdf-files/Serrano-Gotarredona2013 - A 128x128 1.5% Contrast Sensitivity 0.9% FPN 3 $$s Latency 4 MW Asynchronous Frame Free Dynamic Vision Sensor Using Transimpedance Preamplifiers.pdf:PDF},
  groups       = {Neuromorphic Vision},
  keywords     = {CMOS image sensors;operational amplifiers;preamplifiers;CMOS process;FPN;asynchronous frame-free DVS;asynchronous frame-free dynamic vision sensor;contrast coding;contrast sensitivity;fixed pattern noise;illumination variation;lighting conditions;magnitude contrast sensitivity;microscopic dynamic observations;microsecond latency response;motion analyses;pixel photosensing;power 4 mW;robotics;size 0.35 mum;time 3 mus;transimpedance preamplification stage;transimpedance preamplifiers;Arrays;Dynamic range;Lighting;Robot sensing systems;Sensitivity;Transistors;Voltage control;Address-event-representation;contrast sensitivity;dynamic vision sensor;event-based vision;frame-free vision sensor;high-speed vision;temporal contrast retina;vision sensor},
  owner        = {flo},
  timestamp    = {2016.04.13},
}

@InProceedings{Serrano-Gotarredona2015,
  author    = {Serrano-Gotarredona, T. and Linares-Barranco, B. and Galluppi, F. and Plana, L. and Furber, S.},
  title     = {{ConvNets} experiments on {SpiNNaker}},
  booktitle = {Circuits and Systems (ISCAS), 2015 IEEE International Symposium on},
  date      = {2015},
  pages     = {2405--2408},
  doi       = {10.1109/ISCAS.2015.7169169},
  abstract  = {The SpiNNaker Hardware platform allows emulating generic neural network topologies, where each neuron-to-neuron connection is defined by an independent synaptic weight. Consequently, weight storage requires an important amount of memory in the case of generic neural network topologies. This is solved in SpiNNaker by encapsulating with each SpiNNaker chip (which includes 18 ARM cores) a 128MB DRAM chip within the same package. However, ConvNets (Convolutional Neural Network) posses "weight sharing" property, so that many neuron-to-neuron connections share the same weight value. Therefore, a very reduced amount of memory is required to define all synaptic weights, which can be stored on local SRAM DTCM (data-tightly-coupled-memory) at each ARM core. This way, DRAM can be used extensively to store traffic data for off-line analyses. We show an implementation of a 5-layer ConvNet for symbol recognition. Symbols are obtained with a DVS camera. Neurons in the ConvNet operate in an event-driven fashion, and synapses operate instantly. With this approach it was possible to allocate up to 2048 neurons per ARM core, or equivalently 32k neurons per SpiNNaker chip.},
  file      = {:pdf-files/Serrano-Gotarredona2015 - ConvNets Experiments on SpiNNaker.pdf:PDF},
  groups    = {SpiNNaker},
  keywords  = {DRAM chips;SRAM chips;neural chips;5-layer ConvNet;ARM core;DRAM chip;DVS camera;SpiNNaker chip;SpiNNaker hardware platform;convolutional neural network;data-tightly-coupled-memory;generic neural network topology;independent synaptic weight;local SRAM DTCM;neuron-to-neuron connection;off-line analyses;storage capacity 128 Mbit;symbol recognition;traffic data;weight sharing property;weight storage;Biological neural networks;Boards;Convolution;Neurons;Robot sensing systems;Sociology;Statistics;Convolutional Neural Networks;Event-driven Computation;Object Recognition;SpiNNaker Platform},
  owner     = {flo},
  timestamp = {2016.02.18},
}

@Article{Sharma2016,
  author       = {Sugandha Sharma and Sean Aubin and Chris Eliasmith},
  title        = {Large-scale cognitive model design using the {N}engo neural simulator},
  journal      = {Biologically Inspired Cognitive Architectures},
  journaltitle = {Biologically Inspired Cognitive Architectures},
  year         = {2016},
  date         = {2016},
  volume       = {17},
  pages        = {86--100},
  issn         = {2212-683X},
  doi          = {10.1016/j.bica.2016.05.001},
  url          = {http://www.sciencedirect.com/science/article/pii/S2212683X16300317},
  abstract     = {The Neural Engineering Framework (NEF) and Semantic Pointer Architecture (SPA) provide the theoretical underpinnings of the neural simulation environment Nengo. Nengo has recently been used to build Spaun, a state-of-the-art, large-scale neural model that performs motor, perceptual, and cognitive functions with spiking neurons (Eliasmith et al., 2012). In this tutorial we take the reader through the steps needed to create two simpler, illustrative cognitive models. The purpose of this tutorial is to simultaneously introduce the reader to the \{SPA\} and its implementation in Nengo.},
  file         = {:pdf-files/Sharma2016 - Large Scale Cognitive Model Design Using the Nengo Neural Simulator.pdf:PDF;sharma.2016.pdf:http\://compneuro.uwaterloo.ca/files/publications/sharma.2016.pdf:PDF},
  groups       = {Nengo},
  owner        = {flo},
  publisher    = {Elsevier {BV}},
  timestamp    = {2016.08.23},
}

@InProceedings{Sharp2013,
  author    = {Sharp, T. and Furber, S.},
  title     = {Correctness and performance of the {SpiNNaker} architecture},
  booktitle = {The 2013 International Joint Conference on Neural Networks (IJCNN)},
  date      = {2013},
  pages     = {1--8},
  doi       = {10.1109/IJCNN.2013.6706988},
  abstract  = {SpiNNaker is a computer architecture designed to simulate many millions of neurons in real-time, using very many low-power processors and biologically inspired communications. This paper demonstrates that prototype SpiNNaker hardware correctly and quickly simulates networks of point neurons with respect to established reference simulators. Models of increasing complexity are presented and the simulation results obtained from SpiNNaker, NEST and Brian are shown to correlate. An execution profile is sketched of real-time simulation on SpiNNaker, and it is shown to outperform NEST using similar computational resources on a standard benchmark model.},
  file      = {:pdf-files/Sharp2013 - Correctness and Performance of the SpiNNaker Architecture.pdf:PDF},
  groups    = {SpiNNaker},
  issn      = {2161-4393},
  keywords  = {computer architecture;neural nets;Brian;NEST;SpiNNaker architecture;biologically inspired communication;computer architecture;low-power processor;neurons;Computational modeling;Correlation;Firing;Neurons;Pipelines;Program processors;Throughput},
  owner     = {flo},
  timestamp = {2016.02.18},
}

@Article{Shelhamer2016,
  author       = {Evan Shelhamer and Kate Rakelly and Judy Hoffman and Trevor Darrell},
  title        = {Clockwork {C}onvnets for {V}ideo {S}emantic {S}egmentation},
  journaltitle = {Computing Research Repository (CoRR)},
  date         = {2016},
  volume       = {abs/1608.03609},
  url          = {http://arxiv.org/abs/1608.03609},
  comment      = {caffe code for this paper can be found online at https://github.com/shelhamer/clockwork-fcn},
  file         = {:pdf-files/Shelhamer2016 - Clockwork Convnets for Video Semantic Segmentation.pdf:PDF},
  groups       = {Deep Neural Networks},
  owner        = {flo},
  timestamp    = {2016.10.26},
}

@Article{Shen2017,
  author       = {{Shen}, J. and {Pang}, R. and {Weiss}, R.~J. and {Schuster}, M. and {Jaitly}, N. and {Yang}, Z. and {Chen}, Z. and {Zhang}, Y. and {Wang}, Y. and {Skerry-Ryan}, R. and {Saurous}, R.~A. and {Agiomyrgiannakis}, Y. and {Wu}, Y.},
  title        = {{Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions}},
  journaltitle = {ArXiv e-prints},
  date         = {2017},
  eprint       = {1712.05884},
  comment      = {https://research.googleblog.com/2017/12/tacotron-2-generating-human-like-speech.html?m=1},
  file         = {:pdf-files/Shen2017 - Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions.pdf:PDF},
  groups       = {Deep Neural Networks},
  keywords     = {Computer Science - Computation and Language},
  owner        = {flo},
  timestamp    = {2018.01.14},
}

@Article{Silver2016,
  author       = {David Silver and Aja Huang and Chris J. Maddison and Arthur Guez and Laurent Sifre and George van den Driessche and Julian Schrittwieser and Ioannis Antonoglou and Veda Panneershelvam and Marc Lanctot and Sander Dieleman and Dominik Grewe and John Nham and Nal Kalchbrenner and Ilya Sutskever and Timothy Lillicrap and Madeleine Leach and Koray Kavukcuoglu and Thore Graepel and Demis Hassabis},
  title        = {Mastering the game of {G}o with deep neural networks and tree search},
  journal      = {Nature},
  journaltitle = {Nature},
  year         = {2016},
  date         = {2016},
  volume       = {529},
  number       = {7587},
  pages        = {484--489},
  issn         = {0028-0836},
  doi          = {10.1038/nature16961},
  abstract     = {The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses "value networks" to evaluate board positions and "policy networks" to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8\% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.},
  file         = {:pdf-files/Silver2016 - Mastering the Game of Go with Deep Neural Networks and Tree Search.pdf:PDF},
  groups       = {Deep Neural Networks},
  owner        = {flo},
  publisher    = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  timestamp    = {2016.04.13},
}

@Article{Silver2017,
  author       = {David Silver and Julian Schrittwieser and Karen Simonyan and Ioannis Antonoglou and Aja Huang and Arthur Guez and Thomas Hubert and Lucas Baker and Matthew Lai and Adrian Bolton and Yutian Chen and Timothy Lillicrap and Fan Hui and Laurent Sifre and George van den Driessche and Thore Graepel and Demis Hassabis},
  title        = {Mastering the game of {G}o without human knowledge},
  journal      = {Nature},
  journaltitle = {Nature},
  year         = {2017},
  date         = {2017},
  volume       = {550},
  number       = {7676},
  pages        = {354--359},
  issn         = {0028-0836},
  doi          = {10.1038/nature24270},
  abstract     = {A long-standing goal of artificial intelligence is an algorithm that learns, tabula rasa, superhuman proficiency in challenging domains. Recently, AlphaGo became the first program to defeat a world champion in the game of Go. The tree search in AlphaGo evaluated positions and selected moves using deep neural networks. These neural networks were trained by supervised learning from human expert moves, and by reinforcement learning from self-play. Here we introduce an
 algorithm based solely on reinforcement learning, without human data, guidance or domain knowledge beyond game rules. AlphaGo becomes its own teacher: a neural network is trained to predict AlphaGo's own move selections and also the winner of AlphaGo's games. This neural network improves the strength of the tree search, resulting in higher quality move selection and stronger self-play in the next iteration. Starting tabula rasa, our new program AlphaGo Zero achieved superhuman performance,
 winning 100-0 against the previously published, champion-defeating AlphaGo.},
  file         = {:pdf-files/Silver2017 - Mastering the Game of Go without Human Knowledge.pdf:PDF},
  groups       = {Deep Neural Networks},
  owner        = {flo},
  publisher    = {Springer Nature},
  timestamp    = {2017.10.30},
}

@Article{Simonyan2014,
  author       = {Karen Simonyan and Andrew Zisserman},
  title        = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  journaltitle = {Computing Research Repository (CoRR)},
  date         = {2014},
  volume       = {abs/1409.1556},
  eprint       = {1409.1556},
  eprinttype   = {arXiv},
  url          = {http://arxiv.org/abs/1409.1556},
  file         = {:pdf-files/Simonyan2014 - Very Deep Convolutional Networks for Large Scale Image Recognition.pdf:PDF},
  groups       = {Deep Neural Networks},
  owner        = {flo},
  timestamp    = {2018.01.17},
}

@Article{Smolensky1990,
  author       = {Paul Smolensky},
  title        = {Tensor {P}roduct {V}ariable {B}inding and the {R}epresentation of {S}ymbolic {S}tructures in {C}onnectionist {S}ystems},
  journal      = {Artificial Intelligence},
  journaltitle = {Artificial Intelligence},
  year         = {1990},
  date         = {1990},
  volume       = {46},
  number       = {1-2},
  pages        = {159--216},
  issn         = {0004-3702},
  doi          = {10.1016/0004-3702(90)90007-m},
  acmid        = {102425},
  file         = {:pdf-files/Smolensky1990 - Tensor Product Variable Binding and the Representation of Symbolic Structures in Connectionist Systems.pdf:PDF},
  groups       = {Vector Symbolic Architectures},
  issue_date   = {Nov. 1990},
  location     = {Essex, UK},
  numpages     = {58},
  owner        = {flo},
  publisher    = {Elsevier {BV}},
  timestamp    = {2017.06.21},
}

@Article{Srinivasa2012,
  author       = {N. Srinivasa and J. M. Cruz-Albrecht},
  title        = {{Neuromorphic Adaptive Plastic Scalable Electronics: Analog Learning Systems}},
  journaltitle = {IEEE Pulse},
  date         = {2012},
  volume       = {3},
  number       = {1},
  pages        = {51--56},
  issn         = {2154-2287},
  doi          = {10.1109/MPUL.2011.2175639},
  abstract     = {This article provides an overview of the HRL Systems of Neuromorphic Adaptive Plastic Scalable Electronics (SyNAPSE) project and progress made thus far. The multifaceted SyNAPSE program seeks to advance the state of the art in biological algorithms and in developing a new generation of neuromorphic electronic machines necessary for the efficient implementation of these algorithms by drawing inspiration from biology.The fundamental premise of the HRL team to develop brain architecture and related tools has been to recognize that there was a sequence of evolutionary events by which the brain architecture evolved from a primitive brain into a modern brain.},
  comment      = {DARPA SyNAPSE project reference paper},
  file         = {:pdf-files/Srinivasa2012 - Neuromorphic Adaptive Plastic Scalable Electronics_ Analog Learning Systems.pdf:PDF},
  groups       = {TrueNorth},
  keywords     = {biomedical electronics;brain;neurophysiology;SyNAPSE;biological algorithms;brain architecture;evolutionary events;neuromorphic adaptive plastic scalable electronics;Adaptive systems;Artificial intelligence;Biological system modeling;Complexity theory;Intelligent systems;Neuromorphics;Programmable control;Research and development;Animals;Humans;Neural Networks (Computer);Software;Transfer (Psychology)},
  owner        = {flo},
  timestamp    = {2016.03.10},
}

@Article{Stallkamp2012,
  author       = {J. Stallkamp and M. Schlipsing and J. Salmen and C. Igel},
  title        = {Man vs. computer: Benchmarking machine learning algorithms for traffic sign recognition},
  journal      = {Neural Networks},
  journaltitle = {Neural Networks},
  year         = {2012},
  date         = {2012},
  volume       = {32},
  number       = {0},
  pages        = {323--332},
  issn         = {0893-6080},
  doi          = {10.1016/j.neunet.2012.02.016},
  url          = {http://www.sciencedirect.com/science/article/pii/S0893608012000457},
  comment      = {GTSRB Dataset reference},
  file         = {:pdf-files/Stallkamp2012 - Man Vs. Computer_ Benchmarking Machine Learning Algorithms for Traffic Sign Recognition.pdf:PDF},
  groups       = {Object Recognition, Machine Learning, Datasets},
  keywords     = {Traffic sign recognition},
  owner        = {flo},
  publisher    = {Elsevier {BV}},
  timestamp    = {2016.01.18},
}

@Article{Stanley2013,
  author       = {Garrett B Stanley},
  title        = {Reading and writing the neural code},
  journal      = {Nature Neuroscience},
  journaltitle = {Nature Neuroscience},
  year         = {2013},
  date         = {2013},
  volume       = {16},
  number       = {3},
  pages        = {259--263},
  issn         = {1097-6256},
  doi          = {10.1038/nn.3330},
  comment      = {10.1038/nn.3330},
  file         = {:pdf-files/Stanley2013 - Reading and Writing the Neural Code.pdf:PDF},
  groups       = {Biology},
  owner        = {flo},
  publisher    = {Springer Nature},
  timestamp    = {2016.04.21},
}

@Article{Stefanini2014,
  author       = {F. Stefanini and S. Sheik and E. Neftci and G. Indiveri},
  title        = {{PyNCS}: a microkernel for high-level definition and configuration of neuromorphic electronic systems},
  journaltitle = {Frontiers in Neuroinformatics},
  date         = {2014},
  volume       = {8},
  number       = {73},
  doi          = {10.3389/fninf.2014.00073},
  url          = {http://ncs.ethz.ch/pubs/pdf/Stefanini_etal14.pdf},
  abstract     = {Neuromorphic hardware offers an electronic substrate for the realization of asynchronous event-based sensory-motor systems and large-scale spiking neural network architectures. In order to characterize these systems, configure them, and carry out modeling experiments, it is often necessary to interface them to workstations. The software used for this purpose typically consists of a large monolithic block of code which is highly specific to the hardware setup used. While this approach can lead to highly integrated hardware/software systems, it hampers the development of modular and reconfigurable infrastructures thus preventing a rapid evolution of such systems. To alleviate this problem, we propose PyNCS, an open-source front-end for the definition of neural network models that is interfaced to the hardware through a set of Python Application Programming Interfaces (APIs). The design of PyNCS promotes modularity, portability and expandability and separates implementation from hardware description. The high-level front-end that comes with PyNCS includes tools to define neural network models as well as to create, monitor and analyze spiking data. Here we report the design philosophy behind the PyNCS framework and describe its implementation. We demonstrate its functionality with two representative case studies, one using an event-based neuromorphic vision sensor, and one using a set of multi-neuron devices for carrying out a cognitive decision-making task involving state-dependent computation. PyNCS, already applicable to a wide range of existing spike-based neuromorphic setups, will accelerate the development of hybrid software/hardware neuromorphic systems, thanks to its code flexibility. The code is open-source and available online at https://github.com/inincs/pyNCS.},
  file         = {:pdf-files/Stefanini2014 - PyNCS_ a Microkernel for High Level Definition and Configuration of Neuromorphic Electronic Systems.pdf:PDF},
  groups       = {Neuromorphic Computing, Neural Modelling},
  owner        = {flo},
  publisher    = {Frontiers Research Foundation},
  timestamp    = {2016.03.09},
}

@Article{Stewart2012,
  author       = {Stewart, Terrence and Bekolay, Trevor and Eliasmith, Chris},
  date         = {2012},
  journaltitle = {Frontiers in Neuroscience},
  title        = {Learning to Select Actions with Spiking Neurons in the Basal Ganglia},
  doi          = {10.3389/fnins.2012.00002},
  issn         = {1662-453X},
  pages        = {2},
  volume       = {6},
  abstract     = {We expand our existing spiking neuron model of decision making in the cortex and basal ganglia to include local learning on the synaptic connections between the cortex and striatum, modulated by a dopaminergic reward signal. We then compare this model to animal data in the bandit task, which is used to test rodent learning in conditions involving forced choice under rewards. Our results indicate a good match in terms of both behavioural learning results and spike patterns in the ventral striatum. The model successfully generalizes to learning the utilities of multiple actions, and can learn to choose different actions in different states. The purpose of our model is to provide both high-level behavioural predictions and low-level spike timing predictions while respecting known neurophysiology and neuroanatomy.},
  file         = {:pdf-files/Stewart2012 - Learning to Select Actions with Spiking Neurons in the Basal Ganglia.pdf:PDF},
  groups       = {Nengo},
  journal      = {Frontiers in Neuroscience},
  owner        = {flo},
  publisher    = {Frontiers Media {SA}},
  timestamp    = {2018.04.05},
  year         = {2012},
}

@InProceedings{Stewart2010,
  author    = {Terrence C. Stewart and Xuan Choo and Chris Eliasmith},
  title     = {Dynamic {B}ehaviour of a {S}piking {M}odel of {A}ction {S}election in the {B}asal {G}anglia},
  booktitle = {10th International Conference on Cognitive Modeling},
  date      = {2010},
  abstract  = {A fundamental process for cognition is action selection: choosing a particular action out of the many possible actions available. This process is widely believed to involve the basal ganglia, and we present here a model of action selection that uses spiking neurons and is in accordance with the connectivity and neuron types found in this area. Since the parameters of the model are set by neurological data, we can produce timing predictions for different action selection situations without requiring parameter tweaking. Our results show that, while an action can be selected in 14 milliseconds (or longer for actions with similar utilities), it requires 34-44 milliseconds to go from one simple action to the next. For complex actions (whose effect involves routing information between cortical areas), 59-73 milliseconds are needed. This suggests a change to the standard cognitive modelling approach of requiring 50 milliseconds for all types of actions.},
  file      = {:pdf-files/Stewart2010 - Dynamic Behaviour of a Spiking Model of Action Selection in the Basal Ganglia.pdf:PDF},
  groups    = {Nengo},
  owner     = {flo},
  timestamp = {2016.06.29},
}

@InProceedings{Stewart2013,
  author    = {Terrence C. Stewart and Chris Eliasmith},
  title     = {Parsing {S}equentially {P}resented {C}ommands in a {L}arge-{S}cale {B}iologically {R}ealistic {B}rain {M}odel},
  booktitle = {Proceedings of the 35th Annual Meeting of the Cognitive Science Society, CogSci 2013, Berlin, Germany, July 31 - August 3, 2013},
  date      = {2013},
  url       = {https://mindmodeling.org/cogsci2013/papers/0615/index.html},
  file      = {:pdf-files/Stewart2013 - Parsing Sequentially Presented Commands in a Large Scale Biologically Realistic Brain Model.pdf:PDF},
  groups    = {Nengo},
  owner     = {flo},
  timestamp = {2017.03.24},
}

@Proceedings{Stewart2008,
  title        = {Building production systems with realistic spiking neurons},
  date         = {2008},
  location     = {Washington, DC},
  author       = {Terrence C. Stewart and Chris Eliasmith},
  file         = {:pdf-files/Stewart2008 - Building Production Systems with Realistic Spiking Neurons.pdf:PDF},
  groups       = {Nengo, Spiking Neural Networks},
  journaltitle = {Cognitive Science Conference},
  owner        = {flo},
  timestamp    = {2016.08.11},
}

@Article{Stewart2016,
  author       = {Terrence C. Stewart and Ashley Kleinhans and Andrew Mundy and J{\"o}rg Conradt},
  title        = {Serendipitous Offline Learning in a Neuromorphic Robot},
  journal      = {Frontiers in Neurorobotics},
  journaltitle = {Frontiers in Neurorobotics},
  year         = {2016},
  date         = {2016},
  volume       = {10},
  number       = {1},
  issn         = {1662-5218},
  doi          = {10.3389/fnbot.2016.00001},
  abstract     = {We demonstrate a hybrid neuromorphic learning paradigm that learns complex sensorimotor mappings based on a small set of hard-coded reflex behaviors. A mobile robot is first controlled by a basic set of reflexive hand-designed behaviors. All sensor data is provided via a spike-based silicon retina camera (eDVS), and all control is implemented via spiking neurons simulated on neuromorphic hardware (SpiNNaker). Given this control system, the robot is capable of simple obstacle avoidance and random exploration. To train the robot to perform more complex tasks, we observe the robot and find instances where the robot accidentally performs the desired action. Data recorded from the robot during these times is then used to update the neural control system, increasing the likelihood of the robot performing that task in the future, given a similar sensor state. As an example application of this general-purpose method of training, we demonstrate the robot learning to respond to novel sensory stimuli (a mirror) by turning right if it is present at an intersection, and otherwise turning left. In general, this system can learn arbitrary relations between sensory input and motor behavior.},
  file         = {:pdf-files/Stewart2016 - Serendipitous Offline Learning in a Neuromorphic Robot.pdf:PDF},
  groups       = {Neuromorphic Robotics, Neuromorphic Hardware},
  owner        = {flo},
  publisher    = {Frontiers Media {SA}},
  timestamp    = {2016.05.10},
}

@Article{Stewart2011,
  author       = {Terrence C. Stewart and Yichuan Tang and Chris Eliasmith},
  title        = {A Biologically Realistic Cleanup Memory: Autoassociation in Spiking Neurons},
  journaltitle = {Cognitive Systems Research},
  date         = {2011},
  volume       = {12},
  pages        = {84--92},
  doi          = {10.1016/j.cogsys.2010.06.006},
  file         = {:pdf-files/Stewart2011 - A Biologically Realistic Cleanup Memory_ Autoassociation in Spiking Neurons.pdf:PDF},
  groups       = {Neural Modelling, Vector Symbolic Architectures},
  owner        = {flo},
  timestamp    = {2017.04.28},
}

@Article{Stewart2009,
  author       = {Stewart, Terrence C. and Tripp, Bryan and Eliasmith, Chris},
  title        = {Python scripting in the nengo simulator},
  journaltitle = {Frontiers in neuroinformatics},
  date         = {2009},
  volume       = {3},
  pages        = {7},
  issn         = {1662-5196},
  doi          = {10.3389/neuro.11.007.2009},
  file         = {:pdf-files/Stewart2009 - Python Scripting in the Nengo Simulator.pdf:PDF},
  groups       = {Nengo, Spiking Neural Networks},
  owner        = {flo},
  timestamp    = {2015.12.10},
}

@TechReport{StanfordAIReport2016,
  author      = {Peter Stone and Rodney Brooks and Erik Brynjolfsson and Ryan Calo and Oren Etzioni and Greg Hager and Julia Hirschberg and Shivaram Kalyanakrishnan and Ece Kamar and Sarit Kraus and Kevin Leyton-Brown and David Parkes and William Press and AnnaLee Saxenian and Julie Shah and Milind Tambe and Astro Teller},
  title       = {Artificial {I}ntelligence and {L}ife in 2030:{O}ne {H}undred {Y}ear {S}tudy on {A}rtificial {I}ntelligence},
  institution = {Stanford University},
  date        = {2016},
  url         = {https://ai100.stanford.edu/2016-report},
  file        = {:pdf-files/StanfordAIReport2016 - Artificial Intelligence and Life in 2030_One Hundred Year Study on Artificial Intelligence.pdf:PDF},
  groups      = {Machine Learning},
  owner       = {flo},
  timestamp   = {2016.09.01},
}

@InProceedings{Stromatias2013,
  author    = {Evangelos Stromatias and Francesco Galluppi and Cameron Patterson and Steve Furber},
  title     = {Power analysis of large-scale, real-time neural networks on {SpiNNaker}},
  booktitle = {The 2013 International Joint Conference on Neural Networks ({IJCNN})},
  year      = {2013},
  date      = {2013},
  publisher = {{IEEE}},
  pages     = {1--8},
  doi       = {10.1109/ijcnn.2013.6706927},
  abstract  = {Simulating large spiking neural networks is non trivial: supercomputers offer great flexibility at the price of power and communication overheads; custom neuromorphic circuits are more power efficient but less flexible; while alternative approaches based on GPGPUs and FPGAs, whilst being more readily available, show similar model specialization. As well as efficiency and flexibility, real time simulation is a desirable neural network characteristic, for example in cognitive robotics where embodied agents interact with the environment using low-power, event-based neuromorphic sensors. The SpiNNaker neuromimetic architecture has been designed to address these requirements, simulating large-scale heterogeneous models of spiking neurons in real-time, offering a unique combination of flexibility, scalability and power efficiency. In this work a 48-chip board is utilised to generate a SpiNNaker power estimation model, based on numbers of neurons, synapses and their firing rates. In addition, we demonstrate simulations capable of handling up to a quarter of a million neurons, 81 million synapses and 1.8 billion synaptic events per second, with the most complex simulations consuming less than 1 Watt per SpiNNaker chip.},
  file      = {:pdf-files/Stromatias2013 - Power Analysis of Large Scale, Real Time Neural Networks on SpiNNaker.pdf:PDF},
  groups    = {SpiNNaker},
  issn      = {2161-4393},
  keywords  = {application specific integrated circuits;neural chips;neural net architecture;power aware computing;48-chip board;SpiNNaker chip;SpiNNaker neuromimetic architecture;SpiNNaker power estimation model;application-specific integrated circuit;firing rates;large-scale heterogeneous models;large-scale real-time neural networks;power analysis;power efficiency;spiking neural networks;spiking neurons;synaptic events;Biological system modeling;Computational modeling;Equations;Mathematical model;Neurons;Sociology;Statistics},
  owner     = {flo},
  timestamp = {2016.02.18},
}

@InProceedings{Stromatias2015a,
  author    = {Evangelos Stromatias and Daniel Neil and Francesco Galluppi and Michael Pfeiffer and Shih-Chii Liu and Steve Furber},
  title     = {Scalable energy-efficient, low-latency implementations of trained spiking {D}eep {B}elief {N}etworks on {SpiNNaker}},
  booktitle = {2015 International Joint Conference on Neural Networks ({IJCNN})},
  year      = {2015},
  date      = {2015},
  publisher = {{IEEE}},
  pages     = {1--8},
  doi       = {10.1109/ijcnn.2015.7280625},
  abstract  = {Deep neural networks have become the state-of-the-art approach for classification in machine learning, and Deep Belief Networks (DBNs) are one of its most successful representatives. DBNs consist of many neuron-like units, which are connected only to neurons in neighboring layers. Larger DBNs have been shown to perform better, but scaling-up poses problems for conventional CPUs, which calls for efficient implementations on parallel computing architectures, in particular reducing the communication overhead. In this context we introduce a realization of a spike-based variation of previously trained DBNs on the biologically-inspired parallel SpiNNaker platform. The DBN on SpiNNaker runs in real-time and achieves a classification performance of 95\% on the MNIST handwritten digit dataset, which is only 0.06\% less than that of a pure software implementation. Importantly, using a neurally-inspired architecture yields additional benefits: during network run-time on this task, the platform consumes only 0.3 W with classification latencies in the order of tens of milliseconds, making it suitable for implementing such networks on a mobile platform. The results in this paper also show how the power dissipation of the SpiNNaker platform and the classification latency of a network scales with the number of neurons and layers in the network and the overall spike activity rate.},
  file      = {:pdf-files/Stromatias2015a - Scalable Energy Efficient, Low Latency Implementations of Trained Spiking Deep Belief Networks on SpiNNaker.pdf:PDF},
  groups    = {SpiNNaker, Deep Neural Networks, Spiking Neural Networks},
  keywords  = {belief networks;neural nets;parallel architectures;power aware computing;DBN;classification latency;deep belief network;neurally-inspired architecture;neuron-like unit;parallel SpiNNaker platform;power dissipation;Clocks;MATLAB;Neurons;Topology},
  owner     = {flo},
  timestamp = {2016.02.18},
}

@Article{Stromatias2015,
  author       = {Evangelos Stromatias and Daniel Neil and Michael Pfeiffer and Francesco Galluppi and Steve B. Furber and Shih-Chii Liu},
  title        = {{Robustness of spiking Deep Belief Networks to noise and reduced bit precision of neuro-inspired hardware platforms}},
  journal      = {Frontiers in Neuroscience},
  journaltitle = {Frontiers in Neuroscience},
  year         = {2015},
  date         = {2015},
  volume       = {9},
  number       = {222},
  issn         = {1662-453X},
  doi          = {10.3389/fnins.2015.00222},
  abstract     = {Increasingly large deep learning architectures, such as Deep Belief Networks (DBNs) are the focus of current machine learning research and achieve state-of-the-art results in different domains. However, both training and execution of large-scale Deep Networks require vast computing resources, leading to high power requirements and communication overheads. The on-going work on design and construction of spike-based hardware platforms offers an alternative for running deep neural networks with significantly lower power consumption, but has to overcome hardware limitations in terms of noise and limited weight precision, as well as noise inherent in the sensor signal. This article investigates how such hardware constraints impact the performance of spiking neural network implementations of DBNs. In particular, the influence of limited bit precision during execution and training, and the impact of silicon mismatch in the synaptic weight parameters of custom hybrid VLSI implementations is studied. Furthermore, the network performance of spiking DBNs is characterized with regard to noise in the spiking input signal. Our results demonstrate that spiking DBNs can tolerate very low levels of hardware bit precision down to almost two bits, and show that their performance can be improved by at least 30\% through an adapted training mechanism that takes the bit precision of the target platform into account. Spiking DBNs thus present an important use-case for large-scale hybrid analog-digital or digital neuromorphic platforms such as SpiNNaker, which can execute large but precision-constrained deep networks in real time.},
  file         = {:pdf-files/Stromatias2015 - Robustness of Spiking Deep Belief Networks to Noise and Reduced Bit Precision of Neuro Inspired Hardware Platforms.pdf:PDF},
  groups       = {Spiking Neural Networks},
  owner        = {flo},
  publisher    = {Frontiers Media {SA}},
  timestamp    = {2016.01.18},
}

@Book{Sutton1998,
  author    = {Sutton, Richard S. and Barto, Andrew G.},
  title     = {Introduction to {R}einforcement {L}earning},
  date      = {1998},
  edition   = {1},
  publisher = {MIT Press},
  location  = {Cambridge, MA, USA},
  isbn      = {0262193981},
  file      = {:pdf-files/Sutton1998 - Introduction to Reinforcement Learning.pdf:PDF},
  groups    = {ReinforcementLearning},
  owner     = {flo},
  timestamp = {2016.10.26},
}

@Article{Szegedy2016,
  author       = {Christian Szegedy and Sergey Ioffe and Vincent Vanhoucke},
  title        = {Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning},
  journaltitle = {Computing Research Repository (CoRR)},
  date         = {2016},
  volume       = {abs/1602.07261},
  eprint       = {1602.07261},
  eprinttype   = {arXiv},
  url          = {http://arxiv.org/abs/1602.07261},
  file         = {:pdf-files/Szegedy2016 - Inception V4, Inception ResNet and the Impact of Residual Connections on Learning.pdf:PDF},
  groups       = {Deep Neural Networks},
  owner        = {flo},
  timestamp    = {2018.01.17},
}

@Article{Szegedy2013,
  author       = {Christian Szegedy and Wojciech Zaremba and Ilya Sutskever and Joan Bruna and Dumitru Erhan and Ian J. Goodfellow and Rob Fergus},
  title        = {Intriguing properties of neural networks},
  journaltitle = {Computing Research Repository (CoRR)},
  date         = {2013},
  volume       = {abs/1312.6199},
  eprinttype   = {arXiv},
  url          = {http://arxiv.org/abs/1312.6199},
  file         = {:pdf-files/Szegedy2013 - Intriguing Properties of Neural Networks.pdf:PDF},
  groups       = {Deep Neural Networks},
  owner        = {flo},
  timestamp    = {2018.01.10},
}

@Article{Tait2016,
  author       = {{Tait}, A.~N. and {Zhou}, E. and {Ferreira de Lima}, T. and {Wu}, A.~X. and {Nahmias}, M.~A. and {Shastri}, B.~J. and {Prucnal}, P.~R.},
  title        = {{Neuromorphic Silicon Photonics}},
  journaltitle = {ArXiv e-prints},
  date         = {2016},
  eprint       = {1611.02272},
  eprintclass  = {q-bio.NC},
  eprinttype   = {arXiv},
  url          = {https://arxiv.org/abs/1611.02272},
  file         = {:pdf-files/Tait2016 - Neuromorphic Silicon Photonics.pdf:PDF},
  groups       = {Neuromorphic Computing},
  keywords     = {Quantitative Biology - Neurons and Cognition, Computer Science - Neural and Evolutionary Computing, Physics - Optics},
  owner        = {flo},
  timestamp    = {2016.12.05},
}

@Article{Tan2015,
  author       = {Tan, Cheston and Lallee, Stephane and Orchard, Garrick},
  title        = {{Benchmarking Neuromorphic Vision: Lessons Learnt from Computer Vision}},
  journaltitle = {Frontiers in Neuroscience},
  date         = {2015},
  volume       = {9},
  number       = {374},
  issn         = {1662-453X},
  doi          = {10.3389/fnins.2015.00374},
  abstract     = {Neuromorphic Vision sensors have improved greatly since the first silicon retina was presented almost three decades ago. They have recently matured to the point where they are commercially available and can be operated by laymen. However, despite improved availability of sensors, there remains a lack of good datasets, while algorithms for processing spike-based visual data are still in their infancy. On the other hand, frame-based computer vision algorithms are far more mature, thanks in part to widely accepted datasets which allow direct comparison between algorithms and encourage competition. We are presented with a unique opportunity to shape the development of Neuromorphic Vision benchmarks and challenges by leveraging what has been learnt from the use of datasets in frame-based computer vision. Taking advantage of this opportunity, in this paper we review the role that benchmarks and challenges have played in the advancement of frame-based computer vision, and suggest guidelines for the creation of Neuromorphic Vision benchmarks and challenges. We also discuss the unique challenges faced when benchmarking Neuromorphic Vision algorithms, particularly when attempting to provide direct comparison with frame-based computer vision.},
  file         = {:pdf-files/Tan2015 - Benchmarking Neuromorphic Vision_ Lessons Learnt from Computer Vision.pdf:PDF},
  groups       = {Neuromorphic Vision},
  owner        = {flo},
  timestamp    = {2016.01.18},
}

@InProceedings{Tanzmeister2014,
  author    = {Georg Tanzmeister and Julian Thomas and Dirk Wollherr and Martin Buss},
  title     = {Grid-based mapping and tracking in dynamic environments using a uniform evidential environment representation},
  booktitle = {2014 {IEEE} International Conference on Robotics and Automation, {ICRA} 2014, Hong Kong, China, May 31 - June 7, 2014},
  date      = {2014},
  pages     = {6090--6095},
  doi       = {10.1109/ICRA.2014.6907756},
  file      = {:pdf-files/Tanzmeister2014 - Grid Based Mapping and Tracking in Dynamic Environments Using a Uniform Evidential Environment Representation.pdf:PDF},
  groups    = {Environment Model},
  owner     = {flo},
  timestamp = {2015.12.14},
}

@Article{Tanzmeister2016,
  author       = {G. Tanzmeister and D. Wollherr and M. Buss},
  title        = {Grid-{B}ased {M}ulti-{R}oad-{C}ourse {E}stimation {U}sing {M}otion {P}lanning},
  journaltitle = {IEEE Transactions on Vehicular Technology},
  date         = {2016},
  volume       = {65},
  number       = {4},
  pages        = {1924--1935},
  issn         = {0018-9545},
  doi          = {10.1109/TVT.2015.2420752},
  abstract     = {Knowing the course of the road, together with the corresponding road boundaries is an essential component of many advanced driver-assistance systems and of autonomous vehicles. This work presents an indirect grid-based approach for road course estimation. Due to the grid representation, it is independent of specific features or particular sensors and is able to handle continuous as well as sparse road boundaries of arbitrary shape. Furthermore, the number of road courses in the scene is determined to detect road junctions and forks in the road, and the boundaries of each road course are individually estimated. The approach is based on local path planning and path clustering to find the principal moving directions through the environment. They separate the boundaries and are used for their extraction. The set of local paths and principal moving directions is reduced with approximate knowledge of the road velocity paired with system constraints, and validation and tracking assure the required robustness. Experimental results from autonomous navigation of a vehicle through an unmapped road construction site as well as quantitative evaluations demonstrate the performance of the method.},
  file         = {:pdf-files/Tanzmeister2016 - Grid Based Multi Road Course Estimation Using Motion Planning.pdf:PDF},
  groups       = {Environment Model},
  keywords     = {mobile robots;path planning;road vehicles;advanced driver-assistance systems;arbitrary shape;autonomous vehicles;grid-based multiroad-course estimation;local path planning;motion planning;path clustering;principal moving directions;quantitative evaluations;sparse road boundaries;Estimation;Planning;Roads;Sensors;Shape;Trajectory;Vehicles;Autonomous vehicles;drivable-region detection;road boundary detection;road course estimation},
  owner        = {flo},
  timestamp    = {2016.08.25},
}

@Article{Tapson2013,
  author       = {Jonathan C. Tapson and Greg K. Cohen and Saeed Afshar and Klaus M. Stiefel and Yossi Buskila and Runchun Mark Wang and Tara J. Hamilton and Andr{\'{e}} van Schaik},
  title        = {Synthesis of neural networks for spatio-temporal spike pattern recognition and processing},
  journal      = {Frontiers in Neuroscience},
  journaltitle = {Frontiers in Neuroscience},
  year         = {2013},
  date         = {2013},
  volume       = {7},
  number       = {153},
  issn         = {1662-453X},
  doi          = {10.3389/fnins.2013.00153},
  abstract     = {The advent of large scale neural computational platforms has highlighted the lack of algorithms for synthesis of neural structures to perform predefined cognitive tasks. The Neural Engineering Framework (NEF) offers one such synthesis, but it is most effective for a spike rate representation of neural information, and it requires a large number of neurons to implement simple functions. We describe a neural network synthesis method that generates synaptic connectivity for neurons which process time-encoded neural signals, and which makes very sparse use of neurons. The method allows the user to specify-arbitrarily-neuronal characteristics such as axonal and dendritic delays, and synaptic transfer functions, and then solves for the optimal input-output relationship using computed dendritic weights. The method may be used for batch or online learning and has an extremely fast optimization process. We demonstrate its use in generating a network to recognize speech which is sparsely encoded as spike times.},
  file         = {:pdf-files/Tapson2013 - Synthesis of Neural Networks for Spatio Temporal Spike Pattern Recognition and Processing.pdf:PDF},
  groups       = {Spiking Neural Networks},
  owner        = {flo},
  publisher    = {Frontiers Media {SA}},
  timestamp    = {2016.01.18},
}

@InProceedings{Teichman2011,
  author    = {Alex Teichman and Jesse Levinson and Sebastian Thrun},
  title     = {Towards 3{D} object recognition via classification of arbitrary object tracks},
  booktitle = {{IEEE} International Conference on Robotics and Automation, {ICRA} 2011, Shanghai, China, 9-13 May 2011},
  date      = {2011},
  pages     = {4034--4041},
  doi       = {10.1109/ICRA.2011.5979636},
  file      = {:pdf-files/Teichman2011 - Towards 3D Object Recognition Via Classification of Arbitrary Object Tracks.pdf:PDF},
  groups    = {Object Recognition},
  owner     = {flo},
  timestamp = {2015.12.14},
}

@Article{Thorpe1988,
  author       = {C. Thorpe and M. H. Hebert and T. Kanade and S. A. Shafer},
  title        = {Vision and navigation for the Carnegie-Mellon Navlab},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  date         = {1988},
  volume       = {10},
  number       = {3},
  pages        = {362--373},
  issn         = {0162-8828},
  doi          = {10.1109/34.3900},
  abstract     = {A distributed architecture articulated around the CODGER (communication database with geometric reasoning) knowledge database is described for a mobile robot system that includes both perception and navigation tools. Results are described for vision and navigation tests using a mobile testbed that integrates perception and navigation capabilities that are based on two types of vision algorithms: color vision for road following, and 3-D vision for obstacle detection and avoidance. The perception modules are integrated into a system that allows the vehicle to drive continuously in an actual outdoor environment. The resulting system is able to navigate continuously on roads while avoiding obstacles},
  file         = {:pdf-files/Thorpe1988 - Vision and Navigation for the Carnegie Mellon Navlab.pdf:PDF},
  groups       = {Autonomous Driving},
  keywords     = {artificial intelligence;computer architecture;computer vision;computerised navigation;computerised pattern recognition;robots;vehicles;3-D vision;CODGER;Carnegie-Mellon;Navlab;color vision;communication database with geometric reasoning;computer vision;computerised navigation;distributed architecture;knowledge database;mobile robot system;obstacle detection;perception modules;road following;Cameras;Computer architecture;Hardware;Laboratories;Machine vision;Mobile robots;Navigation;Roads;Robot sensing systems;Testing},
  owner        = {flo},
  timestamp    = {2018.02.15},
}

@Book{Thrun2005,
  author               = {Thrun, Sebastian and Burgard, Wolfram and Fox, Dieter},
  title                = {{Probabilistic Robotics (Intelligent Robotics and Autonomous Agents series)}},
  date                 = {2005},
  series               = {Intelligent robotics and autonomous agents},
  publisher            = {The MIT Press},
  isbn                 = {0262201623},
  abstract             = {{Probablistic robotics is a growing area in the subject, concerned with perception and control in the face of uncertainty and giving robots a level of robustness in real-world situations. This book introduces techniques and algorithms in the field.}},
  citeulike-article-id = {560702},
  day                  = {19},
  file                 = {:pdf-files/Thrun2005 - Probabilistic Robotics (Intelligent Robotics and Autonomous Agents Series).pdf:PDF},
  groups               = {Robotics},
  keywords             = {3i, 3r, algorithm-slam, book, exploration, filter-kalman, filter-kalman-extended, filter-kalman-unscented, filter-particle, filtering, localization, mapping, motion, probability, robotics},
  owner                = {flo},
  posted-at            = {2007-11-24 06:03:20},
  timestamp            = {2016.01.28},
}

@Misc{Thrun2006,
  author       = {Thrun, Sebastian and Montemerlo, Mike and Dahlkamp, Hendrik and Stavens, David and Aron, Andrei and Diebel, James and Fong, Philip and Gale, John and Halpenny, Morgan and Hoffmann, Gabriel and Lau, Kenny and Oakley, Celia and Palatucci, Mark and Pratt, Vaughan and Stang, Pascal and Strohband, Sven and Dupont, Cedric and Jendrossek, Lars-Erik and Koelen, Christian and Markey, Charles and Rummel, Carlo and van Niekerk, Joe and Jensen, Eric and Alessandrini, Philippe and Bradski, Gary and Davies, Bob and Ettinger, Scott and Kaehler, Adrian and Nefian, Ara and Mahoney, Pamela},
  editor       = {Karl Iagnemma and Martin Buehler},
  title        = {{S}tanley: {T}he {R}obot {T}hat {W}on the {D}{A}{R}{P}{A} {G}rand {C}hallenge: {R}esearch {A}rticles},
  year         = {2006},
  date         = {2006},
  location     = {Chichester, UK},
  doi          = {10.1002/rob.v23:9},
  acmid        = {1210482},
  file         = {:pdf-files/Thrun2006 - Stanley_ the Robot That Won the DARPA Grand Challenge_ Research Articles.pdf:PDF},
  groups       = {Autonomous Driving},
  issn         = {0741-2223},
  issue_date   = {September 2006},
  journaltitle = {J. Robot. Syst.},
  number       = {9},
  numpages     = {32},
  owner        = {flo},
  pages        = {661--692},
  publisher    = {Wiley},
  timestamp    = {2015.12.10},
  volume       = {23},
}

@Article{TishbyZ15,
  author       = {Naftali Tishby and Noga Zaslavsky},
  title        = {Deep Learning and the Information Bottleneck Principle},
  journaltitle = {Computing Research Repository (CoRR)},
  date         = {2015},
  volume       = {abs/1503.02406},
  url          = {http://arxiv.org/abs/1503.02406},
  abstract     = {Deep Neural Networks (DNNs) are analyzed via the theoretical framework of the information bottleneck (IB) principle. We first show that any DNN can be quantified by the mutual information between the layers and the input and output variables. Using this representation we can calculate the optimal information theoretic limits of the DNN and obtain finite sample generalization bounds. The advantage of getting closer to the theoretical limit is quantifiable both by the generalization bound and by the network's simplicity. We argue that both the optimal architecture, number of layers and features/connections at each layer, are related to the bifurcation points of the information bottleneck tradeoff, namely, relevant compression of the input layer with respect to the output layer. The hierarchical representations at the layered network naturally correspond to the structural phase transitions along the information curve. We believe that this new insight can lead to new optimality bounds and deep learning algorithms.},
  file         = {:pdf-files/TishbyZ15 - Deep Learning and the Information Bottleneck Principle.pdf:PDF},
  groups       = {Deep Neural Networks},
  owner        = {flo},
  timestamp    = {2017.10.12},
}

@Article{Treisman1999,
  author       = {Anne Treisman},
  title        = {Solutions to the Binding Problem},
  journal      = {Neuron},
  journaltitle = {Neuron},
  year         = {1999},
  date         = {1999},
  volume       = {24},
  number       = {1},
  pages        = {105--125},
  issn         = {0896-6273},
  doi          = {10.1016/s0896-6273(00)80826-0},
  booktitle    = {Neuron},
  comment      = {doi: 10.1016/S0896-6273(00)80826-0},
  file         = {:pdf-files/Treisman1999 - Solutions to the Binding Problem.pdf:PDF},
  groups       = {Neuroscience},
  owner        = {flo},
  publisher    = {Elsevier {BV}},
  timestamp    = {2018.02.05},
}

@Article{Urmson.2008,
  author       = {Chris Urmson and Joshua Anhalt and Drew Bagnell and Christopher Baker and Robert Bittner and M. N. Clark and John Dolan and Dave Duggins and Tugrul Galatali and Chris Geyer and Michele Gittleman and Sam Harbaugh and Martial Hebert and Thomas M. Howard and Sascha Kolski and Alonzo Kelly and Maxim Likhachev and Matt McNaughton and Nick Miller and Kevin Peterson and Brian Pilnick and Raj Rajkumar and Paul Rybski and Bryan Salesky and Young-Woo Seo and Sanjiv Singh and Jarrod Snider and Anthony Stentz and William {\textquotedblleft}Red{\textquotedblright} Whittaker and Ziv Wolkowicki and Jason Ziglar and Hong Bae and Thomas Brown and Daniel Demitrish and Bakhtiar Litkouhi and Jim Nickolaou and Varsha Sadekar and Wende Zhang and Joshua Struble and Michael Taylor and Michael Darms and Dave Ferguson},
  title        = {Autonomous driving in urban environments: {B}oss and the {U}rban {C}hallenge},
  journal      = {Journal of Field Robotics},
  journaltitle = {Journal of Field Robotics Special Issue on the 2007 DARPA Urban Challenge, Part I},
  year         = {2008},
  date         = {2008},
  editor       = {Martin Buehler, Karl Lagnemma, Sanjiv Singh},
  volume       = {25},
  number       = {8},
  pages        = {425--466},
  doi          = {10.1002/rob.20255},
  file         = {:pdf-files/Urmson.2008 - Autonomous Driving in Urban Environments_ Boss and the Urban Challenge.pdf:PDF},
  groups       = {Autonomous Driving},
  owner        = {flo},
  publisher    = {Wiley},
  timestamp    = {2015.12.10},
}

@Article{Vapnik1999,
  author       = {V.N. Vapnik},
  title        = {An overview of statistical learning theory},
  journaltitle = {{IEEE} Transactions on Neural Networks},
  year         = {1999},
  date         = {1999},
  volume       = {10},
  number       = {5},
  pages        = {988--999},
  issn         = {1045-9227},
  doi          = {10.1109/72.788640},
  abstract     = {Statistical learning theory was introduced in the late 1960's. Until the 1990's it was a purely theoretical analysis of the problem of function estimation from a given collection of data. In the middle of the 1990's new types of learning algorithms (called support vector machines) based on the developed theory were proposed. This made statistical learning theory not only a tool for the theoretical analysis but also a tool for creating practical algorithms for estimating multidimensional functions. This article presents a very general overview of statistical learning theory including both theoretical and algorithmic aspects of the theory. The goal of this overview is to demonstrate how the abstract learning theory established conditions for generalization which are more general than those discussed in classical statistical paradigms and how the understanding of these conditions inspired new algorithmic approaches to function estimation problems},
  file         = {:pdf-files/Vapnik1999 - An Overview of Statistical Learning Theory.pdf:PDF},
  groups       = {Machine Learning, SVM},
  keywords     = {estimation theory;generalisation (artificial intelligence);learning (artificial intelligence);statistical analysis;function estimation;generalization conditions;multidimensional function estimation;statistical learning theory;support vector machines;Algorithm design and analysis;Loss measurement;Machine learning;Multidimensional systems;Pattern recognition;Probability distribution;Risk management;Statistical learning;Support vector machines},
  owner        = {flo},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  timestamp    = {2016.02.11},
}

@Book{Vapnik1995,
  author    = {Vapnik, Vladimir N.},
  title     = {{The Nature of Statistical Learning Theory}},
  date      = {1995},
  publisher = {Springer-Verlag New York, Inc.},
  location  = {New York, NY, USA},
  isbn      = {0-387-94559-8},
  file      = {:pdf-files/Vapnik1995 - The Nature of Statistical Learning Theory.pdf:PDF},
  groups    = {Machine Learning, SVM},
  owner     = {flo},
  timestamp = {2016.02.09},
}

@TechReport{Voelker2017,
  author      = {Voelker, Aaron R and Gosmann, Jan and Stewart, Terrence C},
  title       = {Efficiently sampling vectors and coordinates from the n-sphere and n-ball},
  institution = {Centre for Theoretical Neuroscience},
  year        = {2017},
  date        = {2017},
  language    = {en},
  location    = {Waterloo, ON},
  doi         = {10.13140/rg.2.2.15829.01767/1},
  url         = {https://www.researchgate.net/publication/312056739_Efficiently_sampling_vectors_and_coordinates_from_the_n-sphere_and_n-ball},
  abstract    = {We provide a short proof that the uniform distribution of points for the n-ball is equivalent to the uniform distribution of points for the (n + 1)-sphere projected onto n dimensions. This implies the surprising result that one may uniformly sample the n-ball by instead uniformly sampling the (n + 1)-sphere and then arbitrarily discarding two coordinates. Consequently, any procedure for sampling coordinates from the uniform (n + 1)-sphere may be used to sample coordinates from the uniform n-ball without any modification. For purposes of the Semantic Pointer Architecture (SPA), these insights yield an efficient and novel procedure for sampling the dot-product of vectors-sampled from the uniform ball-with unit-length encoding vectors.},
  file        = {:pdf-files/Voelker2017 - Efficiently Sampling Vectors and Coordinates from the N Sphere and N Ball.pdf:PDF},
  groups      = {Vector Symbolic Architectures},
  owner       = {flo},
  publisher   = {Centre for Theoretical Neuroscience},
  timestamp   = {2017.11.23},
}

@TechReport{Vreeken2003,
  author      = {Vreeken, Jilles},
  title       = {Spiking neural networks, an introduction},
  institution = {Department of Information and Computing Sciences, Utrecht University},
  date        = {2003},
  number      = {UU-CS-2003-008},
  file        = {:pdf-files/Vreeken2003 - Spiking Neural Networks, an Introduction.pdf:PDF},
  groups      = {Spiking Neural Networks},
  owner       = {flo},
  pubcat      = {techreport},
  timestamp   = {2016.01.18},
  urlpdf      = {{http://www.cs.uu.nl/research/techreps/repo/CS-2003/2003-008.pdf}},
}

@Article{Walter2015,
  author       = {Florian Walter and Florian R{\"o}hrbein and Alois Knoll},
  title        = {Neuromorphic implementations of neurobiological learning algorithms for spiking neural networks},
  journal      = {Neural Networks},
  journaltitle = {Neural Networks},
  year         = {2015},
  date         = {2015},
  volume       = {72},
  pages        = {152--167},
  note         = {Neurobiologically Inspired Robotics: Enhanced Autonomy through Neuromorphic Cognition},
  issn         = {0893-6080},
  doi          = {10.1016/j.neunet.2015.07.004},
  file         = {:pdf-files/Walter2015 - Neuromorphic Implementations of Neurobiological Learning Algorithms for Spiking Neural Networks.pdf:PDF},
  groups       = {Neuromorphic Computing},
  owner        = {flo},
  publisher    = {Elsevier {BV}},
  timestamp    = {2016.03.03},
}

@InProceedings{Wang2008,
  author    = {Guosheng Wang},
  title     = {{A Survey on Training Algorithms for Support Vector Machine Classifiers}},
  booktitle = {2008 Fourth International Conference on Networked Computing and Advanced Information Management},
  year      = {2008},
  date      = {2008},
  volume    = {1},
  publisher = {{IEEE}},
  pages     = {123--128},
  doi       = {10.1109/ncm.2008.103},
  abstract  = {Learning from data is one of the basic ways humans perceive the world and acquire the knowledge. Support vector machine (SVM for short) has emerged as a good classification technique and achieved excellent generalization performance in a variety of applications. Training SVM on a dataset of huge size with millions of data is a challenging problem since it is computationally expensive and the memory requirement grows with the square of the number of training examples. This paper surveys SVM training algorithms and falls them into three groups. Moreover, recent advances such as finite Newton method and active learning algorithms are described.},
  file      = {:pdf-files/Wang2008 - A Survey on Training Algorithms for Support Vector Machine Classifiers.pdf:PDF},
  groups    = {Machine Learning, SVM},
  keywords  = {learning (artificial intelligence);pattern classification;support vector machines;data learning;support vector machine classification;training algorithm;Computer networks;Computer science;Convergence;Information management;Kernel;Management training;Optimization methods;Support vector machine classification;Support vector machines;Upper bound;Support vector machine;Survey;Training algorithm},
  owner     = {flo},
  timestamp = {2016.02.11},
}

@Article{Wang2015,
  author       = {Wang, Runchun Mark and Hamilton, Tara Julia and Tapson, Jonathan and van Schaik, Andr{\'e}},
  title        = {A neuromorphic implementation of multiple spike-timing synaptic plasticity rules for large-scale neural networks},
  journaltitle = {Frontiers in Neuroscience},
  date         = {2015},
  volume       = {9},
  number       = {180},
  issn         = {1662-453X},
  doi          = {10.3389/fnins.2015.00180},
  abstract     = {We present a neuromorphic implementation of multiple synaptic plasticity learning rules, which include both Spike Timing Dependent Plasticity (STDP) and Spike Timing Dependent Delay Plasticity (STDDP). We present a fully digital implementation as well as a mixed-signal implementation, both of which use a novel dynamic-assignment time-multiplexing approach and support up to 226 (64M) synaptic plasticity elements. Rather than implementing dedicated synapses for particular types of synaptic plasticity, we implemented a more generic synaptic plasticity adaptor array that is separate from the neurons in the neural network. Each adaptor performs synaptic plasticity according to the arrival times of the pre- and post-synaptic spikes assigned to it, and sends out a weighted or delayed pre-synaptic spike to the post-synaptic neuron in the neural network. This strategy provides great flexibility for building complex large-scale neural networks, as a neural network can be configured for multiple synaptic plasticity rules without changing its structure. We validate the proposed neuromorphic implementations with measurement results and illustrate that the circuits are capable of performing both STDP and STDDP. We argue that it is practical to scale the work presented here up to 236 (64G) synaptic adaptors on a current high-end FPGA platform.},
  file         = {:pdf-files/Wang2015 - A Neuromorphic Implementation of Multiple Spike Timing Synaptic Plasticity Rules for Large Scale Neural Networks.pdf:PDF},
  groups       = {Neuromorphic Computing},
  owner        = {flo},
  timestamp    = {2016.02.03},
}

@InProceedings{Wang2003,
  author    = {Yingxu Wang and Dong Liu},
  title     = {On information and knowledge representation in the brain},
  booktitle = {The Second IEEE International Conference on Cognitive Informatics, 2003. Proceedings.},
  date      = {2003},
  publisher = {{IEEE} Comput. Soc},
  pages     = {26--31},
  doi       = {10.1109/coginf.2003.1225947},
  abstract  = {The cognitive models of information representation and the capacity of human memory are fundamental research areas in cognitive informatics, which help to reveal the mechanism and potential of the brain. This paper develops the object-attribute-relation (OAR) model for describing information representation and storage in the brain. According to the OAR model, the human memory and knowledge are represented by relations, i.e. connections of synapses between neurons, rather than by the neurons themselves as the traditional container metaphor described. Based on the OAR model, the memory capacity of the human brain is calculated as in the order of 108432 bits. The determination of the magnitude of human memory capacity is not only theoretically significant in cognitive informatics, but also practically useful to estimate the human potential, as well as the gap between the natural and machine intelligence.},
  file      = {:pdf-files/Wang2003 - On Information and Knowledge Representation in the Brain.pdf:PDF},
  groups    = {Neuroscience},
  keywords  = {behavioural sciences computing;brain models;cognition;cognitive systems;computational complexity;knowledge representation;software engineering;OAR model;brain mechanism;cognitive informatics;cognitive models;connections of synapses;human memory;information representation;knowledge representation;machine intelligence;memory capacity;natural intelligence;neurons;object-attribute-relation;software engineering;storage in the brain;traditional container metaphor;Brain modeling;Cognitive informatics;Cognitive science;Humans;Information representation;Knowledge representation;Mathematical model;Mathematics;Neurons;Software engineering},
  owner     = {flo},
  timestamp = {2018.01.12},
}

@Article{Watkins1992,
  author       = {Christopher J.C.H. Watkins and Peter Dayan},
  title        = {Technical {N}ote: {Q}-{L}earning},
  journal      = {Machine Learning},
  journaltitle = {Machine Learning},
  year         = {1992},
  date         = {1992},
  volume       = {8},
  number       = {3/4},
  pages        = {279--292},
  issn         = {1573-0565},
  doi          = {10.1023/a:1022676722315},
  abstract     = {Q-learning (Watkins, 1989) is a simple way for agents to learn how to act optimally in controlled Markovian domains. It amounts to an incremental method for dynamic programming which imposes limited computational demands. It works by successively improving its evaluations of the quality of particular actions at particular states.},
  file         = {:pdf-files/Watkins1992 - Technical Note_ Q Learning.pdf:PDF},
  groups       = {ReinforcementLearning},
  owner        = {flo},
  publisher    = {Springer Nature},
  timestamp    = {2016.10.19},
}

@Online{Waymo,
  author    = {{Waymo LLC}},
  title     = {Waymo webpage},
  url       = {https://waymo.com/},
  urldate   = {2018-02-08},
  comment   = {Google car reference},
  groups    = {Autonomous Driving},
  owner     = {flo},
  timestamp = {2016.03.31},
}

@Article{Webster2002,
  author       = {Webster, Jane and Watson, Richard T.},
  title        = {Analyzing the Past to Prepare for the Future: Writing a Literature Review},
  journaltitle = {MIS Quarterly},
  date         = {2002},
  volume       = {26},
  number       = {2},
  pages        = {xiii--xxiii},
  issn         = {0276-7783},
  url          = {http://dl.acm.org/citation.cfm?id=2017160.2017162},
  acmid        = {2017162},
  file         = {:pdf-files/Webster2002 - Analyzing the Past to Prepare for the Future_ Writing a Literature Review.pdf:PDF},
  groups       = {Non-Technical},
  issue_date   = {June 2002},
  location     = {Minneapolis, MN, USA},
  owner        = {flo},
  publisher    = {Society for Information Management and The Management Information Systems Research Center},
  timestamp    = {2016.06.27},
}

@InProceedings{Weikersdorfer2014,
  author    = {David Weikersdorfer and David B. Adrian and Daniel Cremers and J{\"o}rg Conradt},
  title     = {Event-based {3D} {SLAM} with a depth-augmented {D}ynamic {V}ision {S}ensor},
  booktitle = {2014 {IEEE} International Conference on Robotics and Automation, {ICRA} 2014, Hong Kong, China, May 31 - June 7, 2014},
  date      = {2014},
  pages     = {359--364},
  doi       = {10.1109/ICRA.2014.6906882},
  file      = {:pdf-files/Weikersdorfer2014 - Event Based 3D SLAM with a Depth Augmented Dynamic Vision Sensor.pdf:PDF},
  groups    = {Neuromorphic Vision},
  owner     = {flo},
  timestamp = {2016.01.26},
}

@InProceedings{Weikersdorfer2012,
  author    = {David Weikersdorfer and J{\"o}rg Conradt},
  title     = {Event-based particle filtering for robot self-localization},
  booktitle = {2012 {IEEE} International Conference on Robotics and Biomimetics ({ROBIO})},
  year      = {2012},
  date      = {2012},
  publisher = {{IEEE}},
  pages     = {866--870},
  doi       = {10.1109/robio.2012.6491077},
  abstract  = {We propose a novel algorithm for robot self-localization using an embedded event-based sensor. This sensor produces a stream of events at microsecond time resolution which only represents pixel-level illumination changes in a scene, as e.g. caused by perceived motion. This is in contrast to classical image sensors, which wastefully transmit redundant information at a much lower frame rate. Our method adapts the commonly used Condensation Particle Filter Tracker to such event-based sensors. It works directly with individual, highly ambiguous pixel-events and does not employ event integration over time. The lack of complete discrete sensory measurements is addressed by applying an exponential decay model for hypotheses likelihood computation. The proposed algorithm demonstrates robust performance at low computation requirements; turning it suitable for implementation in embedded hardware on small autonomous robots. We evaluate our algorithm in a simulation environment and with experimental recorded data.},
  file      = {:pdf-files/Weikersdorfer2012 - Event Based Particle Filtering for Robot Self Localization.pdf:PDF},
  groups    = {Neuromorphic Vision},
  keywords  = {image motion analysis;image resolution;image sensors;particle filtering (numerical methods);robot vision;autonomous robot;condensation particle filter tracker;embedded event-based sensor;event-based particle filtering;exponential decay model;hypotheses likelihood computation;image sensor;microsecond time resolution;perceived motion;pixel-level illumination change;robot self-localization},
  owner     = {flo},
  timestamp = {2016.04.14},
}

@InProceedings{Weikersdorfer2013,
  author    = {David Weikersdorfer and Raoul Hoffmann and J{\"o}rg Conradt},
  title     = {Simultaneous {L}ocalization and {M}apping for {E}vent-{B}ased {V}ision {S}ystems},
  booktitle = {Computer Vision Systems - 9th International Conference, {ICVS} 2013, St. Petersburg, Russia, July 16-18, 2013. Proceedings},
  date      = {2013},
  pages     = {133--142},
  doi       = {10.1007/978-3-642-39402-7_14},
  abstract  = {We propose a novel method for vision based simultaneous localization and mapping (vSLAM) using a biologically inspired vision sensor that mimics the human retina. The sensor consists of a 128x128 ar- ray of asynchronously operating pixels, which independently emit events upon a temporal illumination change. Such a representation generates small amounts of data with high temporal precision; however, most classic computer vision algorithms need to be reworked as they require full RGB(-D) images at fixed frame rates. Our presented vSLAM algo- rithm operates on individual pixel events and generates high-quality 2D environmental maps with precise robot localizations. We evaluate our method with a state-of-the-art marker-based external tracking system and demonstrate real-time performance on standard computing hard- ware.},
  file      = {:pdf-files/Weikersdorfer2013 - Simultaneous Localization and Mapping for Event Based Vision Systems.pdf:PDF},
  groups    = {Neuromorphic Vision},
  owner     = {flo},
  timestamp = {2016.04.14},
}

@PhdThesis{Werbos1974,
  author               = {Werbos, Paul J.},
  title                = {{Beyond regression: new tools for prediction and analysis in the behavioral sciences}},
  institution          = {Harvard University},
  date                 = {1974},
  citeulike-article-id = {2893927},
  groups               = {Machine Learning},
  keywords             = {theory},
  owner                = {flo},
  posted-at            = {2008-06-14 01:04:16},
  timestamp            = {2016.02.03},
}

@Article{Westermann2007,
  author       = {Gert Westermann and Denis Mareschal and Mark H. Johnson and Sylvain Sirois and Michael W. Spratling and Michael S.C. Thomas},
  title        = {Neuroconstructivism},
  journal      = {Developmental Science},
  journaltitle = {Developmental Science},
  year         = {2007},
  date         = {2007},
  volume       = {10},
  number       = {1},
  pages        = {75--83},
  doi          = {10.1111/j.1467-7687.2007.00567.x},
  file         = {:pdf-files/Westermann2007 - Neuroconstructivism.pdf:PDF},
  groups       = {Neuroscience},
  owner        = {flo},
  publisher    = {Wiley},
  timestamp    = {2017.03.24},
}

@Article{Widdows2014,
  author       = {D. Widdows and T. Cohen},
  title        = {Reasoning with vectors: A continuous model for fast robust inference},
  journal      = {Logic Journal of {IGPL}},
  journaltitle = {Logic Journal of {IGPL}},
  year         = {2014},
  date         = {2014},
  volume       = {23},
  number       = {2},
  pages        = {141--173},
  issn         = {1368-9894},
  doi          = {10.1093/jigpal/jzu028},
  url          = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4646228/},
  abstract     = {This paper describes the use of continuous vector space models for reasoning with a formal knowledge base. The practical significance of these models is that they support fast, approximate but robust inference and hypothesis generation, which is complementary to the slow, exact, but sometimes brittle behavior of more traditional deduction engines such as theorem provers. The paper explains the way logical connectives can be used in semantic vector models, and summarizes the development of Predication-based Semantic Indexing, which involves the use of Vector Symbolic Architectures to represent the concepts and relationships from a knowledge base of subject-predicate-object triples. Experiments show that the use of continuous models for formal reasoning is not only possible, but already demonstrably effective for some recognized informatics tasks, and showing promise in other traditional problem areas. Examples described in this paper include: predicting new uses for existing drugs in biomedical informatics; removing unwanted meanings from search results in information retrieval and concept navigation; type-inference from attributes; comparing words based on their orthography; and representing tabular data, including modelling numerical values. The algorithms and techniques described in this paper are all publicly released and freely available in the Semantic Vectors open-source software package.()},
  comment      = {26582967[pmid]},
  file         = {:pdf-files/Widdows2014 - Reasoning with Vectors_ a Continuous Model for Fast Robust Inference.pdf:PDF},
  groups       = {Vector Symbolic Architectures},
  owner        = {flo},
  publisher    = {Oxford University Press ({OUP})},
  timestamp    = {2017.05.17},
}

@InProceedings{Williams2016,
  author    = {Paul Williams and Risto Miikkulainen},
  title     = {Grounding {L}anguage in {D}escriptions of {S}cenes},
  booktitle = {Proceedings of the 28th Annual Meeting of the Cognitive Science Society},
  date      = {2006},
  url       = {http://nn.cs.utexas.edu/?williams:cogsci06},
  file      = {:pdf-files/Williams2016 - Grounding Language in Descriptions of Scenes.pdf:PDF},
  groups    = {Vector Symbolic Architectures},
  owner     = {flo},
  timestamp = {2017.10.12},
}

@InCollection{Wilson2009,
  author               = {Wilson, Robert and Finkel, Leif},
  title                = {{A Neural Implementation of the Kalman Filter}},
  booktitle            = {Advances in Neural Information Processing Systems 22},
  date                 = {2009},
  editor               = {Bengio, Y. and Schuurmans, D. and Lafferty, J. and Williams, C. K. I. and Culotta, A.},
  pages                = {2062--2070},
  citeulike-article-id = {8352533},
  file                 = {:pdf-files/Wilson2009 - A Neural Implementation of the Kalman Filter.pdf:PDF},
  groups               = {Neuromorphic Computing, Neural Modelling},
  owner                = {flo},
  posted-at            = {2010-12-03 15:24:25},
  timestamp            = {2016.02.03},
}

@Misc{TORCS,
  author    = {Bernhard Wymann and Eric Espi{\'e} and Christophe Guionneau and Christos Dimitrakakis and R{\'e}mi Coulom and Andrew Sumner},
  title     = {{TORCS}, {T}he {O}pen {R}acing {C}ar {S}imulator},
  date      = {2014},
  url       = {http://www.torcs.org},
  groups    = {Autonomous Driving, Simulators},
  owner     = {flo},
  timestamp = {2016.11.02},
}

@InProceedings{Yamazaki2016,
  author    = {S. Yamazaki and C. Miyajima and E. Yurtsever and K. Takeda and M. Mori and K. Hitomi and M. Egawa},
  title     = {Integrating driving behavior and traffic context through signal symbolization},
  booktitle = {2016 IEEE Intelligent Vehicles Symposium (IV)},
  date      = {2016},
  pages     = {642--647},
  doi       = {10.1109/IVS.2016.7535455},
  abstract  = {This paper presents a novel method for integrating driving behavior and traffic context through signal symbolization in order to summarize driving semantics from sensor outputs. The method has been applied to risky lane change detection. Language models (nested Pitman-Yor language model) and speech recognition algorithms (hidden Markov Model) have been utilized for converting continuous sensor signals into a sequence of non-uniform segments (chunks). After symbolization, Latent Dirichlet Allocation (LDA) is used to integrate the symbolized driving behavior and the surrounding vehicle information for establishing the semantics of the driving scene. 988 lane changes of real-world highway driving are used for the evaluation. Risk level of each lane change rated by 10 subjects are used as ground truth. Best results have been obtained when driving behavior and surrounding vehicle information are integrated through co-occurrence chunking after independent symbolization of behavior and context signals.},
  file      = {:pdf-files/Yamazaki2016 - Integrating Driving Behavior and Traffic Context through Signal Symbolization.pdf:PDF},
  groups    = {Situation/Context analysis},
  keywords  = {behavioural sciences computing;computational linguistics;driver information systems;hidden Markov models;road traffic;sensors;speech recognition;LDA;co-occurrence chunking;continuous sensor signals;driving behavior;driving behavior integration;driving scene semantics;driving semantics;ground truth;hidden Markov model;lane change risk level;latent Dirichlet allocation;nested Pitman-Yor language model;nonuniform segment sequence;real-world highway driving;risky-lane change detection;sensor outputs;signal symbolization;speech recognition algorithms;surrounding vehicle information;traffic context integration;vehicle information;Intelligent vehicles},
  owner     = {flo},
  timestamp = {2017.11.15},
}

@InProceedings{Yee2011,
  author    = {Elias Yee and Jason Teo},
  title     = {Evolutionary spiking neural networks as racing car controllers},
  booktitle = {2011 11th International Conference on Hybrid Intelligent Systems (HIS)},
  year      = {2011},
  date      = {2011},
  publisher = {{IEEE}},
  pages     = {411--416},
  doi       = {10.1109/his.2011.6122141},
  abstract  = {The Izhikevich spiking neural network model is investigated as a method to develop controllers for a simple, but not trivial, car racing game, called TORCS. The controllers are evolved using Evolutionary Programming, and the performance of the best individuals is compared with the hand-coded controller included with the Simulated Car Racing Championship API. The results are promising, indicating that this neural network model can be applied to other games or control problems.},
  file      = {:pdf-files/Yee2011 - Evolutionary Spiking Neural Networks As Racing Car Controllers.pdf:PDF},
  groups    = {Autonomous Driving},
  keywords  = {automobiles;evolutionary computation;neurocontrollers;API;Izhikevich spiking neural network model;TORCS;car racing game;evolutionary programming;evolutionary spiking neural network;hand-coded controller;racing car controller;simulated car racing championship;Biological neural networks;Biological system modeling;Computational modeling;Electric potential;Games;Mathematical model;Neurons;Izhikevich neuron model;Spiking neural networks;TORCS;car racing;evolutionary programming;games},
  owner     = {flo},
  timestamp = {2017.03.15},
}

@Article{Zhang2000,
  author       = {G.P. Zhang},
  title        = {Neural networks for classification: a survey},
  journal      = {{IEEE} Transactions on Systems, Man and Cybernetics, Part C (Applications and Reviews)},
  journaltitle = {Systems, Man, and Cybernetics, Part C: Applications and Reviews, IEEE Transactions on},
  year         = {2000},
  date         = {2000},
  volume       = {30},
  number       = {4},
  pages        = {451--462},
  issn         = {1094-6977},
  doi          = {10.1109/5326.897072},
  abstract     = {Classification is one of the most active research and application areas of neural networks. The literature is vast and growing. This paper summarizes some of the most important developments in neural network classification research. Specifically, the issues of posterior probability estimation, the link between neural and conventional classifiers, learning and generalization tradeoff in classification, the feature variable selection, as well as the effect of misclassification costs are examined. Our purpose is to provide a synthesis of the published research in this area and stimulate further research interests and efforts in the identified topics},
  file         = {:pdf-files/Zhang2000 - Neural Networks for Classification_ a Survey.pdf:PDF},
  groups       = {Neural Networks},
  keywords     = {generalisation (artificial intelligence);learning (artificial intelligence);neural nets;pattern classification;classification;conventional classifiers;feature variable selection;generalization;learning;misclassification costs;neural classifiers;neural networks;posterior probability estimation;Costs;Decision making;Humans;Input variables;Medical diagnosis;Medical diagnostic imaging;Network synthesis;Neural networks;Probability;Speech recognition},
  owner        = {flo},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  timestamp    = {2016.02.09},
}

@Article{Zhao2015,
  author       = {Bo Zhao and Ruoxi Ding and Shoushun Chen and Bernabe Linares-Barranco and Huajin Tang},
  title        = {Feedforward Categorization on {AER} Motion Events Using Cortex-Like Features in a Spiking Neural Network},
  journal      = {{IEEE} Transactions on Neural Networks and Learning Systems},
  journaltitle = {IEEE Transactions on Neural Networks and Learning Systems},
  year         = {2015},
  date         = {2015},
  volume       = {26},
  number       = {9},
  pages        = {1963--1978},
  issn         = {2162-237X},
  doi          = {10.1109/tnnls.2014.2362542},
  abstract     = {This paper introduces an event-driven feedforward categorization system, which takes data from a temporal contrast address event representation (AER) sensor. The proposed system extracts bio-inspired cortex-like features and discriminates different patterns using an AER based tempotron classifier (a network of leaky integrate-and-fire spiking neurons). One of the system's most appealing characteristics is its event-driven processing, with both input and features taking the form of address events (spikes). The system was evaluated on an AER posture dataset and compared with two recently developed bio-inspired models. Experimental results have shown that it consumes much less simulation time while still maintaining comparable performance. In addition, experiments on the Mixed National Institute of Standards and Technology (MNIST) image dataset have demonstrated that the proposed system can work not only on raw AER data but also on images (with a preprocessing step to convert images into AER events) and that it can maintain competitive accuracy even when noise is added. The system was further evaluated on the MNIST dynamic vision sensor dataset (in which data is recorded using an AER dynamic vision sensor), with testing accuracy of 88.14\%.},
  file         = {:pdf-files/Zhao2015 - Feedforward Categorization on AER Motion Events Using Cortex like Features in a Spiking Neural Network.pdf:PDF},
  groups       = {Neuromorphic Vision, Spiking Neural Networks},
  keywords     = {neural nets;pattern classification;AER motion events;MNIST dynamic vision sensor dataset;Mixed National Institute of Standards and Technology;bio-inspired cortex-like features;event-driven feedforward categorization system;spiking neural network;temporal contrast address event representation sensor;tempotron classifier;Computer architecture;Convolution;Feature extraction;Feedforward neural networks;Kernel;Neurons;Visualization;Address event representation (AER);MNIST;event driven;feedforward categorization;spiking neural network;spiking neural network.},
  owner        = {flo},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  timestamp    = {2016.08.10},
}

@Article{Zhu2017,
  author       = {Hao Zhu and Ka-Veng Yuen and Lyudmila Mihaylova and Henry Leung},
  title        = {Overview of Environment Perception for Intelligent Vehicles},
  journal      = {{IEEE} Transactions on Intelligent Transportation Systems},
  journaltitle = {IEEE Transactions on Intelligent Transportation Systems},
  year         = {2017},
  date         = {2017},
  volume       = {18},
  number       = {10},
  pages        = {2584--2601},
  issn         = {1524-9050},
  doi          = {10.1109/tits.2017.2658662},
  abstract     = {This paper presents a comprehensive literature review on environment perception for intelligent vehicles. The state-of-the-art algorithms and modeling methods for intelligent vehicles are given, with a summary of their pros and cons. A special attention is paid to methods for lane and road detection, traffic sign recognition, vehicle tracking, behavior analysis, and scene understanding. In addition, we provide information about datasets, common performance analysis, and perspectives on future research directions in this area.},
  file         = {:pdf-files/Zhu2017 - Overview of Environment Perception for Intelligent Vehicles.pdf:PDF},
  groups       = {Autonomous Driving},
  keywords     = {intelligent transportation systems;object detection;road traffic;road vehicles;traffic engineering computing;environment perception;intelligent vehicles;lane detection;road detection;traffic sign recognition;vehicle tracking;Feature extraction;Intelligent sensors;Intelligent vehicles;Laser radar;Roads;Intelligent vehicles;environment perception and modeling;lane and road detection;scene understanding;traffic sign recognition;vehicle tracking and behavior analysis},
  owner        = {flo},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  timestamp    = {2018.02.15},
}

@Article{Schroeder2014,
  author       = {Tobias Schr{\"o}der and Terrence C. Stewart and Paul Thagard},
  title        = {Intention, Emotion, and Action: A Neural Theory Based on Semantic Pointers},
  journal      = {Cognitive Science},
  journaltitle = {Cognitive Science},
  year         = {2013},
  date         = {2014},
  volume       = {38},
  number       = {5},
  pages        = {851--880},
  doi          = {10.1111/cogs.12100},
  eprint       = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.12100},
  abstract     = {We propose a unified theory of intentions as neural processes that integrate representations of states of affairs, actions, and emotional evaluation. We show how this theory provides answers to philosophical questions about the concept of intention, psychological questions about human behavior, computational questions about the relations between belief and action, and neuroscientific questions about how the brain produces actions. Our theory of intention ties together biologically plausible mechanisms for belief, planning, and motor control. The computational feasibility of these mechanisms is shown by a model that simulates psychologically important cases of intention.},
  file         = {:pdf-files/Schroeder2014 - Intention, Emotion, and Action_ a Neural Theory Based on Semantic Pointers.pdf:PDF},
  groups       = {Vector Symbolic Architectures},
  keywords     = {Intention, Emotion, Action, Implementation intentions, Automatic, Deliberative, Planning, Neural engineering framework, Semantic pointers},
  owner        = {flo},
  publisher    = {Wiley},
  timestamp    = {2018.05.25},
}

@Article{Davies2018,
  author       = {Davies, M. and Srinivasa, N. and Lin, T. H. and Chinya, G. and Cao, Y. and Choday, S. H. and Dimou, G. and Joshi, P. and Imam, N. and Jain, S. and Liao, Y. and Lin, C. K. and Lines, A. and Liu, R. and Mathaikutty, D. and McCoy, S. and Paul, A. and Tse, J. and Venkataramanan, G. and Weng, Y. H. and Wild, A. and Yang, Y. and Wang, H.},
  title        = {Loihi: A Neuromorphic Manycore Processor with On-Chip Learning},
  journaltitle = {IEEE Micro},
  date         = {2018},
  volume       = {38},
  number       = {1},
  pages        = {82--99},
  issn         = {0272-1732},
  abstract     = {Loihi is a 60-mm^2 chip fabricated in Intels 14-nm process that advances the state-of-the-art modeling of spiking neural networks in silicon. It integrates a wide range of novel features for the field, such as hierarchical connectivity, dendritic compartments, synaptic delays, and, most importantly, programmable synaptic learning rules. Running a spiking convolutional form of the Locally Competitive Algorithm, Loihi can solve LASSO optimization problems with over three orders of magnitude superior energy-delay-product compared to conventional solvers running on a CPU iso-process/voltage/area. This provides an unambiguous example of spike-based computation, outperforming all known conventional solutions.},
  call-number  = {38},
  file         = {:pdf-files/Davies2018 - Loihi_ a Neuromorphic Manycore Processor with on Chip Learning.pdf:PDF},
  groups       = {Neuromorphic Hardware, Loihi},
  keywords     = {circuit optimisation, integrated circuit modelling, learning (artificial intelligence), microprocessor chips, multiprocessing systems, neural chips, CPU iso-process-voltage-area, Intels process, LASSO optimization problems, Loihi, dendritic compartments, hierarchical connectivity, locally competitive algorithm, magnitude superior energy-delay-product, neuromorphic manycore processor, on-chip learning, programmable synaptic learning rules, size 14 nm, spike-based computation, spiking neural networks, synaptic delays, Algorithm design and analysis, Biological neural networks, Computational modeling, Computer architecture, Neuromorphics, Neurons, artificial intelligence, machine learning, neuromorphic computing},
  owner        = {flo},
  timestamp    = {2018.05.31},
}

@Article{Edwards2015,
  author       = {Edwards, Chris},
  title        = {Growing {P}ains for {D}eep {L}earning},
  journaltitle = {Communications of the ACM},
  date         = {2015},
  volume       = {58},
  number       = {7},
  pages        = {14--16},
  issn         = {0001-0782},
  doi          = {10.1145/2771283},
  acmid        = {2771283},
  groups       = {Deep Neural Networks},
  location     = {New York, NY, USA},
  owner        = {flo},
  publisher    = {ACM},
  timestamp    = {2018.05.31},
}

@InProceedings{Cassidy2013,
  author       = {Cassidy, A. S. and Merolla, P. and Arthur, J. V. and Esser, S. K. and Jackson, B. and Alvarez-Icaza, R. and Datta, P. and Sawada, J. and Wong, T. M. and Feldman, V. and Amir, A. and Rubin, D. B. D. and Akopyan, F. and McQuinn, E. and Risk, W. P. and Modha, D. S.},
  title        = {Cognitive computing building block: A versatile and efficient digital neuron model for neurosynaptic cores},
  booktitle    = {The 2013 International Joint Conference on Neural Networks (IJCNN)},
  date         = {2013},
  pages        = {1--10},
  abstract     = {Marching along the DARPA SyNAPSE roadmap, IBM unveils a trilogy of innovations towards the TrueNorth cognitive computing system inspired by the brain's function and efficiency. Judiciously balancing the dual objectives of functional capability and implementation/operational cost, we develop a simple, digital, reconfigurable, versatile spiking neuron model that supports one-to-one equivalence between hardware and simulation and is implementable using only 1272 ASIC gates. Starting with the classic leaky integrate-and-fire neuron, we add: (a) configurable and reproducible stochasticity to the input, the state, and the output; (b) four leak modes that bias the internal state dynamics; (c) deterministic and stochastic thresholds; and (d) six reset modes for rich finite-state behavior. The model supports a wide variety of computational functions and neural codes. We capture 50+ neuron behaviors in a library for hierarchical composition of complex computations and behaviors. Although designed with cognitive algorithms and applications in mind, serendipitously, the neuron model can qualitatively replicate the 20 biologically-relevant behaviors of a dynamical neuron model.},
  file         = {:pdf-files/Cassidy2013 - Cognitive Computing Building Block_ a Versatile and Efficient Digital Neuron Model for Neurosynaptic Cores.pdf:PDF},
  groups       = {TrueNorth},
  issn         = {2161-4393},
  journaltitle = {The 2013 International Joint Conference on Neural Networks (IJCNN)},
  keywords     = {application specific integrated circuits, cognition, logic gates, neural chips, stochastic processes, ASIC gates, DARPA SyNAPSE roadmap, IBM, TrueNorth cognitive computing system, biologically-relevant behaviors, brain efficiency, brain function, cognitive computing building block, configurable stochasticity, deterministic thresholds, digital neuron model, digital spiking neuron model, dynamical neuron model, finite-state behavior, hierarchical composition, internal state dynamics, leak modes, leaky integrate-and-fire neuron, neural codes, neuron behaviors, neurosynaptic cores, one-to-one equivalence, reconfigurable spiking neuron model, reproducible stochasticity, reset modes, stochastic thresholds, versatile spiking neuron model, Computational modeling, Electric potential, Libraries, Mathematical model, Nerve fibers, Stochastic processes},
  owner        = {flo},
  timestamp    = {2018.05.31},
}

@Article{Painkras2013,
  author       = {Painkras, E. and Plana, L. A. and Garside, J. and Temple, S. and Galluppi, F. and Patterson, C. and Lester, D. R. and Brown, A. D. and Furber, S. B.},
  title        = {SpiNNaker: A 1-W 18-Core System-on-Chip for Massively-Parallel Neural Network Simulation},
  journaltitle = {IEEE Journal of Solid-State Circuits},
  date         = {2013},
  volume       = {48},
  number       = {8},
  pages        = {1943--1953},
  issn         = {0018-9200},
  abstract     = {The modelling of large systems of spiking neurons is computationally very demanding in terms of processing power and communication. SpiNNaker - Spiking Neural Network architecture - is a massively parallel computer system designed to provide a cost-effective and flexible simulator for neuroscience experiments. It can model up to a billion neurons and a trillion synapses in biological real time. The basic building block is the SpiNNaker Chip Multiprocessor (CMP), which is a custom-designed globally asynchronous locally synchronous (GALS) system with 18 ARM968 processor nodes residing in synchronous islands, surrounded by a lightweight, packet-switched asynchronous communications infrastructure. In this paper, we review the design requirements for its very demanding target application, the SpiNNaker micro-architecture and its implementation issues. We also evaluate the SpiNNaker CMP, which contains 100 million transistors in a 102-mm<sup>2</sup> die, provides a peak performance of 3.96 GIPS, and has a peak power consumption of 1 W when all processor cores operate at the nominal frequency of 180 MHz. SpiNNaker chips are fully operational and meet their power and performance requirements.},
  call-number  = {48},
  file         = {:pdf-files/Painkras2013 - SpiNNaker_ a 1 W 18 Core System on Chip for Massively Parallel Neural Network Simulation.pdf:PDF},
  groups       = {SpiNNaker},
  keywords     = {microprocessor chips, neural net architecture, parallel architectures, system-on-chip, ARM968 processor node, CMP, SpiNNaker chip multiprocessor, cost effective simulator, custom designed globally asynchronous locally synchronous system, flexible simulator, massively parallel neural network simulation, neuroscience experiment, packet switched asynchronous communications, parallel computer system, power 1 W, spiking neural network architecture, spiking neuron, synchronous island, system-on-chip, Biological system modeling, Brain modeling, Computational modeling, Hardware, Neurons, System-on-chip, Asynchronous interconnect, chip multiprocessor, energy efficiency, globally asynchronous locally synchronous (GALS), network-on-chip, neuromorphic hardware, real-time simulation, spiking neural networks (SNNs)},
  owner        = {flo},
  timestamp    = {2018.05.31},
}

@InProceedings{Navaridas2009,
  author    = {Navaridas, Javier and Luj\'{a}n, Mikel and Miguel-Alonso, Jose and Plana, Luis A. and Furber, Steve},
  title     = {Understanding the Interconnection Network of SpiNNaker},
  booktitle = {Proceedings of the 23rd International Conference on Supercomputing},
  date      = {2009},
  series    = {ICS '09},
  publisher = {ACM},
  location  = {Yorktown Heights, NY, USA},
  isbn      = {978-1-60558-498-0},
  pages     = {286--295},
  doi       = {10.1145/1542275.1542317},
  acmid     = {1542317},
  address   = {New York, NY, USA},
  file      = {:pdf-files/Navaridas2009 - Understanding the Interconnection Network of SpiNNaker.pdf:PDF},
  groups    = {SpiNNaker},
  keywords  = {analytical evaluation, biologically inspired architecture, fault tolerance, interconnection networks, massively parallel architecture, performance evaluation, real-time applications, spiking neurons, systems on chip},
  numpages  = {10},
  owner     = {flo},
  timestamp = {2018.05.31},
}

@InProceedings{Patterson2002,
  author    = {E. K. Patterson and S. Gurbuz and Z. Tufekci and J. N. Gowdy},
  title     = {{CUAVE}: A new audio-visual database for multimodal human-computer interface research},
  booktitle = {{IEEE} International Conference on Acoustics Speech and Signal Processing},
  year      = {2002},
  date      = {2002},
  volume    = {2},
  publisher = {{IEEE}},
  pages     = {II-2017-II-2020},
  doi       = {10.1109/icassp.2002.5745028},
  abstract  = {Multimodal signal processing has become an important topic of research for overcoming certain problems of audio-only speech processing. Audio-visual speech recognition is one area with great potential. Difficulties due to background noise and multiple speakers are significantly reduced by the additional information provided by extra visual features. Despite a few efforts to create databases in this area, none has emerged as a standard for comparison for several possible reasons. This paper seeks to introduce a new audiovisual database that is flexible and fairly comprehensive, yet easily available to researchers on one DVD. The CUAVE database is a speaker-independent corpus of over 7,000 utterances of both connected and isolated digits. It is designed to meet several goals that are discussed in this paper. The most notable are availability of the database, flexibility for use of the audio-visual data, and realistic considerations in the recordings (such as speaker movement). Another important focus of the database is the inclusion of pairs of simultaneous speakers, the first documented database of this kind. The overall goal of this project is to facilitate more widespread audio-visual research through an easily available database. For information on obtaining CUAVE, please visit our webpage (http://ece.clemson.edu/speech).},
  file      = {:pdf-files/Patterson2002 - CUAVE_ a New Audio Visual Database for Multimodal Human Computer Interface Research.pdf:PDF},
  groups    = {Datasets},
  issn      = {1520-6149},
  keywords  = {Databases;Ear;Visualization},
  owner     = {flo},
  timestamp = {2018.05.31},
}

@Article{Schmitt2017,
  author       = {Sebastian Schmitt and Johann Klaehn and Guillaume Bellec and Andreas Gr{\"{u}}bl and Maurice Guettler and Andreas Hartel and Stephan Hartmann and Dan Husmann de Oliveira and Kai Husmann and Vitali Karasenko and Mitja Kleider and Christoph Koke and Christian Mauch and Eric M{\"{u}}ller and Paul M{\"{u}}ller and Johannes Partzsch and Mihai A. Petrovici and Stefan Schiefer and Stefan Scholze and Bernhard Vogginger and Robert A. Legenstein and Wolfgang Maass and Christian Mayr and Johannes Schemmel and Karlheinz Meier},
  title        = {Neuromorphic Hardware In The Loop: Training a Deep Spiking Network on the BrainScaleS Wafer-Scale System},
  journaltitle = {Computing Research Repository (CoRR)},
  date         = {2017},
  volume       = {abs/1703.01909},
  eprinttype   = {arXiv},
  url          = {http://arxiv.org/abs/1703.01909},
  file         = {:pdf-files/Schmitt2017 - Neuromorphic Hardware in the Loop_ Training a Deep Spiking Network on the BrainScaleS Wafer Scale System.pdf:PDF},
  groups       = {Neuromorphic Hardware},
  owner        = {flo},
  timestamp    = {2018.05.31},
}

@InProceedings{Schemmel2008,
  author       = {Schemmel, J. and Fieres, J. and Meier, K.},
  title        = {Wafer-scale integration of analog neural networks},
  booktitle    = {2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence)},
  date         = {2008},
  pages        = {431--438},
  abstract     = {This paper introduces a novel design of an artificial neural network tailored for wafer-scale integration. The presented VLSI implementation includes continuous-time analog neurons with up to 16 k inputs. A novel interconnection and routing scheme allows the mapping of a multitude of network models derived from biology on the VLSI neural network while maintaining a high resource usage. A single 20 cm wafer contains about 60 million synapses. The implemented neurons are highly accelerated compared to biological real time. The power consumption of the dense interconnection network providing the necessary communication bandwidth is a critical aspect of the system integration. A novel asynchronous low-voltage signaling scheme is presented that makes the wafer-scale approach feasible by limiting the total power consumption while simultaneously providing a flexible, programmable network topology.},
  file         = {:pdf-files/Schemmel2008 - Wafer Scale Integration of Analog Neural Networks.pdf:PDF},
  groups       = {Neuromorphic Hardware},
  issn         = {2161-4393},
  journaltitle = {2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence)},
  keywords     = {analogue integrated circuits, integrated circuit interconnections, network routing, neural chips, wafer-scale integration, VLSI implementation, artificial neural network, asynchronous low-voltage signaling scheme, continuous-time analog neural networks, interconnection network, interconnection-routing scheme, power consumption, programmable network topology, wafer-scale integration, Artificial neural networks, Biological system modeling, Computational biology, Energy consumption, Neural networks, Neurons, Routing, Semiconductor device modeling, Very large scale integration, Wafer scale integration},
  owner        = {flo},
  timestamp    = {2018.05.31},
}

@Article{Merolla2014,
  author       = {P. Merolla and J. Arthur and R. Alvarez and J. M. Bussat and K. Boahen},
  title        = {A {M}ulticast {T}ree {R}outer for {M}ultichip {N}euromorphic {S}ystems},
  journaltitle = {IEEE Transactions on Circuits and Systems I: Regular Papers},
  date         = {2014},
  volume       = {61},
  number       = {3},
  pages        = {820--833},
  issn         = {1549-8328},
  doi          = {10.1109/TCSI.2013.2284184},
  file         = {:pdf-files/Merolla2014 - A Multicast Tree Router for Multichip Neuromorphic Systems.pdf:PDF},
  groups       = {Neuromorphic Hardware},
  keywords     = {VLSI;broadcasting;elemental semiconductors;microprocessor chips;multicast communication;multiprocessor interconnection networks;neural nets;silicon;telecommunication network routing;Neurogrid;Si;asynchronous VLSI implementation;computational units;deadlock-free multicast packet routing;downward phase;header compact;memory look-ups;million-neuron neuromorphic system;multicast tree router;multichip neuromorphic systems;one-to-many routing;packet branching;packet broadcasting;silicon-neuron array;subtree root;upward phase;wormhole router;Arrays;Neuromorphics;Neurons;Random access memory;Routing;System recovery;Unicast;Asynchronous;VLSI;deadlock;multicast;neuromorphic;router;tree network},
  owner        = {flo},
  timestamp    = {2018.05.31},
}

@Article{Schwartz1990,
  author       = {Schwartz, Tom J.},
  title        = {A Neural Chips Survey},
  journaltitle = {AI Expert},
  date         = {1990},
  volume       = {5},
  number       = {12},
  pages        = {34--38},
  issn         = {0888-3785},
  url          = {http://dl.acm.org/citation.cfm?id=95986.95993},
  acmid        = {95993},
  groups       = {Neuromorphic Hardware},
  issue_date   = {Dec. 1990},
  location     = {San Francisco, CA, USA},
  numpages     = {5},
  owner        = {flo},
  publisher    = {Miller Freeman, Inc.},
  timestamp    = {2018.06.08},
}

@InProceedings{Holler1989,
  author    = {Holler and Tam and Castro and Benson},
  title     = {An Electrically Trainable Artificial Neural Network (ETANN) with 10240 "Floating Gate" Synapses},
  booktitle = {International Joint Conference on Neural Networks},
  year      = {1989},
  date      = {1989},
  editor    = {Morgan, Nelson},
  publisher = {{IEEE}},
  location  = {Piscataway, NJ, USA},
  isbn      = {0-8186-2029-3},
  pages     = {50--55},
  doi       = {10.1109/ijcnn.1989.118698},
  url       = {https://ieeexplore.ieee.org/document/118698/},
  acmid     = {104167},
  groups    = {Neuromorphic Hardware},
  numpages  = {6},
  owner     = {flo},
  timestamp = {2018.06.08},
}

@InProceedings{Agranat1990,
  author       = {A.J. Agranat and C.F. Neugebauer and A. Yariv},
  title        = {A {CCD} based neural network integrated circuit with 64K analog programmable synapses},
  booktitle    = {1990 {IJCNN} International Joint Conference on Neural Networks},
  year         = {1990},
  date         = {1990},
  organization = {IEEE},
  publisher    = {{IEEE}},
  pages        = {551--555},
  doi          = {10.1109/ijcnn.1990.137623},
  groups       = {Neuromorphic Hardware},
  owner        = {flo},
  timestamp    = {2018.06.08},
}

@Book{Bracewell2000,
  author    = {Bracewell, R.N.},
  title     = {The Fourier Transform and Its Applications},
  date      = {2000},
  series    = {Electrical engineering series},
  publisher = {McGraw Hill},
  isbn      = {9780073039381},
  url       = {https://books.google.de/books?id=ZNQQAQAAIAAJ},
  file      = {:pdf-files/Bracewell2000 - The Fourier Transform and Its Applications.pdf:PDF},
  groups    = {Vector Symbolic Architectures},
  lccn      = {99021139},
  owner     = {flo},
  timestamp = {2018.06.08},
}

@Article{Levy2015,
  author       = {Levy, Omer and Goldberg, Yoav and Dagan, Ido},
  title        = {Improving Distributional Similarity with Lessons Learned from Word Embeddings},
  journaltitle = {Transactions of the Association for Computational Linguistics},
  date         = {2015},
  volume       = {3},
  pages        = {211--225},
  issn         = {2307-387X},
  url          = {https://transacl.org/ojs/index.php/tacl/article/view/570},
  abstract     = {Recent trends suggest that neural-network-inspired word embedding models outperform traditional count-based distributional models on word similarity and analogy detection tasks. We reveal that much of the performance gains of word embeddings are due to certain system design choices and hyperparameter optimizations, rather than the embedding algorithms themselves. Furthermore, we show that these modifications can be transferred to traditional distributional models, yielding similar gains. In contrast to prior reports, we observe mostly local or insignificant performance differences between the methods, with no global advantage to any single approach over the others.},
  file         = {:pdf-files/Levy2015 - Improving Distributional Similarity with Lessons Learned from Word Embeddings.pdf:PDF},
  groups       = {Word Embedding},
  owner        = {flo},
  timestamp    = {2018.06.08},
}

@Article{Eslami2018,
  author       = {Eslami, S. M. Ali and Jimenez Rezende, Danilo and Besse, Frederic and Viola, Fabio and Morcos, Ari S. and Garnelo, Marta and Ruderman, Avraham and Rusu, Andrei A. and Danihelka, Ivo and Gregor, Karol and Reichert, David P. and Buesing, Lars and Weber, Theophane and Vinyals, Oriol and Rosenbaum, Dan and Rabinowitz, Neil and King, Helen and Hillier, Chloe and Botvinick, Matt and Wierstra, Daan and Kavukcuoglu, Koray and Hassabis, Demis},
  title        = {Neural scene representation and rendering},
  journaltitle = {Science},
  date         = {2018},
  volume       = {360},
  number       = {6394},
  pages        = {1204--1210},
  issn         = {0036-8075},
  doi          = {10.1126/science.aar6170},
  eprint       = {http://science.sciencemag.org/content/360/6394/1204.full.pdf},
  url          = {http://science.sciencemag.org/content/360/6394/1204},
  abstract     = {To train a computer to {\textquotedblleft}recognize{\textquotedblright} elements of a scene supplied by its visual sensors, computer scientists typically use millions of images painstakingly labeled by humans. Eslami et al. developed an artificial vision system, dubbed the Generative Query Network (GQN), that has no need for such labeled data. Instead, the GQN first uses images taken from different viewpoints and creates an abstract description of the scene, learning its essentials. Next, on the basis of this representation, the network predicts what the scene would look like from a new, arbitrary viewpoint.Science, this issue p. 1204Scene representation{\textemdash}the process of converting visual sensory data into concise descriptions{\textemdash}is a requirement for intelligent behavior. Recent work has shown that neural networks excel at this task when provided with large, labeled datasets. However, removing the reliance on human labeling remains an important open problem. To this end, we introduce the Generative Query Network (GQN), a framework within which machines learn to represent scenes using only their own sensors. The GQN takes as input images of a scene taken from different viewpoints, constructs an internal representation, and uses this representation to predict the appearance of that scene from previously unobserved viewpoints. The GQN demonstrates representation learning without human labels or domain knowledge, paving the way toward machines that autonomously learn to understand the world around them.},
  file         = {:pdf-files/Eslami2018 - Neural Scene Representation and Rendering.pdf:PDF},
  groups       = {Deep Neural Networks},
  owner        = {flo},
  publisher    = {American Association for the Advancement of Science},
  timestamp    = {2018.06.15},
}

@Article{Hunsberger2016,
  author       = {Eric Hunsberger and Chris Eliasmith},
  title        = {Training Spiking Deep Networks for Neuromorphic Hardware},
  journaltitle = {Computing Research Repository (CoRR)},
  date         = {2016},
  volume       = {abs/1611.05141},
  eprint       = {1611.05141},
  eprinttype   = {arXiv},
  url          = {http://arxiv.org/abs/1611.05141},
  file         = {:pdf-files/Hunsberger2016 - Training Spiking Deep Networks for Neuromorphic Hardware.pdf:PDF},
  groups       = {Spiking Neural Networks},
  owner        = {flo},
  timestamp    = {2018.06.18},
}

@Article{Rasmussen2019,
  author    = {Rasmussen, Daniel},
  title     = {NengoDL: Combining Deep Learning and Neuromorphic Modelling Methods},
  doi       = {10.1007/s12021-019-09424-z},
  issn      = {1559-0089},
  url       = {https://doi.org/10.1007/s12021-019-09424-z},
  abstract  = {NengoDL is a software framework designed to combine the strengths of neuromorphic modelling and deep learning. NengoDL allows users to construct biologically detailed neural models, intermix those models with deep learning elements (such as convolutional networks), and then efficiently simulate those models in an easy-to-use, unified framework. In addition, NengoDL allows users to apply deep learning training methods to optimize the parameters of biological neural models. In this paper we present basic usage examples, benchmarking, and details on the key implementation elements of NengoDL. More details can be found at https://www.nengo.ai/nengo-dl.},
  day       = {10},
  file      = {:pdf-files/Rasmussen2018 - NengoDL_ Combining Deep Learning and Neuromorphic Modelling Methods.pdf:PDF},
  groups    = {Deep Neural Networks},
  journal   = {Neuroinformatics},
  keywords  = {Computer Science - Neural and Evolutionary Computing, Computer Science - Artificial Intelligence},
  month     = {Apr},
  owner     = {flo},
  timestamp = {2018.06.22},
  year      = {2019},
}

@InProceedings{Verleysen2005,
  author    = {Verleysen, Michel and Fran{\c{c}}ois, Damien},
  title     = {The Curse of Dimensionality in Data Mining and Time Series Prediction},
  booktitle = {Computational Intelligence and Bioinspired Systems},
  date      = {2005},
  editor    = {Cabestany, Joan and Prieto, Alberto and Sandoval, Francisco},
  publisher = {Springer Berlin Heidelberg},
  location  = {Berlin, Heidelberg},
  isbn      = {978-3-540-32106-4},
  pages     = {758--770},
  abstract  = {Modern data analysis tools have to work on high-dimensional data, whose components are not independently distributed. High-dimensional spaces show surprising, counter-intuitive geometrical properties that have a large influence on the performances of data analysis tools. Among these properties, the concentration of the norm phenomenon results in the fact that Euclidean norms and Gaussian kernels, both commonly used in models, become inappropriate in high-dimensional spaces. This papers presents alternative distance measures and kernels, together with geometrical methods to decrease the dimension of the space. The methodology is applied to a typical time series prediction example.},
  file      = {:pdf-files/Verleysen2005 - The Curse of Dimensionality in Data Mining and Time Series Prediction.pdf:PDF},
  groups    = {Machine Learning},
  owner     = {flo},
  timestamp = {2018.06.22},
}

@InProceedings{Bonnin2012,
  author    = {S. Bonnin and F. Kummert and J. Schm{\"u}dderich},
  title     = {A Generic Concept of a System for Predicting Driving Behaviors},
  booktitle = {2012 15th International IEEE Conference on Intelligent Transportation Systems},
  date      = {2012},
  pages     = {1803--1808},
  doi       = {10.1109/ITSC.2012.6338695},
  abstract  = {Today, many vehicles are equipped with Advanced Driver Assistance Systems (ADAS) to warn the driver about the potential danger of a scene, but in some situations the warning is not early enough to avoid an accident. A solution for preparing the driver and giving him the time to react to such dangerous events is to predict the behavior of other traffic participants. This paper describes a method to predict the behavior of the surrounding vehicles by a classification approach. However, the behavior alternatives strongly depend on the scenario faced by the target vehicle. Where most of the state-of-the-art approaches focus on a single scenario, the concept presented in this paper aims at a generic solution, allowing for behavior prediction for a large amount of different scenes. The idea of the method is to categorize scenes into a hierarchy from the most generic ones in the top nodes to the most specific ones in the leaves. Every node of the hierarchy is a scene containing a set of classifiers to predict the possible behaviors. GPS and digital maps provide the static information about the infrastructure, which is used to determine the nodes fitting to the current situation. As a first step this paper shows accurate prediction of traffic participants behavior in highway entrance situations for a prediction horizon of up to 3 seconds.},
  file      = {:pdf-files/Bonnin2012 - A Generic Concept of a System for Predicting Driving Behaviors.pdf:PDF},
  groups    = {Behaviour analysis},
  issn      = {2153-0009},
  keywords  = {Global Positioning System;automated highways;behavioural sciences computing;cartography;driver information systems;natural scenes;road accidents;road safety;GPS;advanced driver assistance system;digital map;driving behavior prediction;generic classifier;highway entrance situation;node fitting;road accident;scene;traffic participant;Computational modeling;Context;Merging;Predictive models;Road transportation;Vectors;Vehicles},
  owner     = {flo},
  timestamp = {2018.06.22},
}

@InProceedings{Bonnin2014,
  author    = {S. Bonnin and T. H. Weisswange and F. Kummert and J. Schmuedderich},
  title     = {Pedestrian crossing prediction using multiple context-based models},
  booktitle = {17th International IEEE Conference on Intelligent Transportation Systems (ITSC)},
  date      = {2014},
  pages     = {378--385},
  doi       = {10.1109/ITSC.2014.6957720},
  abstract  = {In inner-city, most vehicle-pedestrian collisions occur when a pedestrian is crossing the road and the driver does not see or pay attention to him. Current ADAS (advanced driver assistance systems) warn the driver or apply the brakes shortly before the collision, but in some situations the collision cannot be fully avoided because most systems react only when the pedestrian is already in front of the vehicle. To fully avoid a collision, a driver should be warned earlier. Behavior prediction is a solution that can be used to warn a driver before the pedestrian starts crossing. In this paper, we propose a generic context based model to predict crossing behaviors of pedestrians in inner-city. We will show that our model provides accurate prediction at an early time. However, there are specific locations such as zebra crossings, where based on expert driving experience, one would expect that a prediction can be done even earlier. Therefore, we have developed an additional specific model fitted to the context of zebra crossings. The experiments show that this model produces both, better and earlier predictions in this specific context. Because our goal is to build a generic crossing prediction system, we finally apply the framework of the `Context Model Tree' to combine the two models. We demonstrate that this multi-model system is well suited to provide early predictions for realistic data, including both, generic inner-city situations and zebra crossings.},
  file      = {:pdf-files/Bonnin2014 - Pedestrian Crossing Prediction Using Multiple Context Based Models.pdf:PDF},
  groups    = {Behaviour analysis},
  issn      = {2153-0009},
  keywords  = {behavioural sciences;collision avoidance;driver information systems;pedestrians;road vehicles;trees (mathematics);ADAS;advanced driver assistance systems;behavior prediction;collision avoidance;context model tree;context-based models;crossing behaviors;crossing prediction system;generic inner-city situation;multimodel system;pedestrian crossing prediction;vehicle-pedestrian collision;zebra crossings;Computational modeling;Context;Context modeling;Predictive models;Roads;Trajectory;Vehicles},
  owner     = {flo},
  timestamp = {2018.06.22},
}

@InProceedings{Luo2018,
  author    = {Luo, Wenjie and Yang, Bin and Urtasun, Raquel},
  title     = {Fast and Furious: Real Time End-to-End 3D Detection, Tracking and Motion Forecasting With a Single Convolutional Net},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  date      = {2018},
  file      = {:pdf-files/Luo2018 - Fast and Furious_ Real Time End to End 3D Detection, Tracking and Motion Forecasting with a Single Convolutional Net.pdf:PDF},
  groups    = {Deep Neural Networks, Autonomous Driving},
  owner     = {flo},
  timestamp = {2018.06.25},
}

@Article{Wahle2012,
  author       = {Wahle, Manuel and Widdows, Dominic and Herskovic, Jorge R. and Bernstam, Elmer V. and Cohen, Trevor},
  title        = {Deterministic Binary Vectors for Efficient Automated Indexing of MEDLINE/PubMed Abstracts},
  journaltitle = {AMIA Annual Symposium Proceedings},
  date         = {2012},
  volume       = {2012},
  number       = {PMC3540485},
  pages        = {940--949},
  issn         = {1942-597X},
  url          = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3540485/},
  abstract     = {The need to maintain accessibility of the biomedical literature has led to development of methods to assist human indexers by recommending index terms for newly encountered articles. Given the rapid expansion of this literature, it is essential that these methods be scalable. Document vector representations are commonly used for automated indexing, and Random Indexing (RI) provides the means to generate them efficiently. However, RI is difficult to implement in real-world indexing systems, as (1) efficient nearest-neighbor search requires retaining all document vectors in RAM, and (2) it is necessary to maintain a store of randomly generated term vectors to index future documents. Motivated by these concerns, this paper documents the development and evaluation of a deterministic binary variant of RI. The increased capacity demonstrated by binary vectors has implications for information retrieval, and the elimination of the need to retain term vectors facilitates distributed implementations, enhancing the scalability of RI.},
  comment      = {amia_2012_symp_0940[PII]
23304369[pmid]},
  database     = {PMC},
  file         = {:pdf-files/Wahle2012 - Deterministic Binary Vectors for Efficient Automated Indexing of MEDLINE_PubMed Abstracts.pdf:PDF},
  groups       = {Vector Symbolic Architectures},
  owner        = {flo},
  publisher    = {American Medical Informatics Association},
  timestamp    = {2018.07.03},
}

@InProceedings{Peemen2011,
  author       = {Peemen, Maurice and Mesman, Bart and Corporaal, Henk},
  title        = {Speed Sign Detection and Recognition by Convolutional Neural Networks},
  date         = {2011},
  file         = {:pdf-files/Peemen2011 - Speed Sign Detection and Recognition by Convolutional Neural Networks.pdf:PDF},
  groups       = {Deep Neural Networks},
  journaltitle = {International Automotive Congress},
  owner        = {flo},
  timestamp    = {2018.07.06},
}

@Article{Rast2018,
  author       = {A. D. Rast and S. V. Adams and S. Davidson and S. Davies and M. Hopkins and A. Rowley and A. B. Stokes and T. Wennekers and S. Furber and A. Cangelosi},
  title        = {Behavioral Learning in a Cognitive Neuromorphic Robot: An Integrative Approach},
  journaltitle = {IEEE Transactions on Neural Networks and Learning Systems},
  date         = {2018},
  pages        = {1--13},
  issn         = {2162-237X},
  doi          = {10.1109/TNNLS.2018.2816518},
  abstract     = {We present here a learning system using the iCub humanoid robot and the SpiNNaker neuromorphic chip to solve the real-world task of object-specific attention. Integrating spiking neural networks with robots introduces considerable complexity for questionable benefit if the objective is simply task performance. But, we suggest, in a cognitive robotics context, where the goal is understanding how to compute, such an approach may yield useful insights to neural architecture as well as learned behavior, especially if dedicated neural hardware is available. Recent advances in cognitive robotics and neuromorphic processing now make such systems possible. Using a scalable, structured, modular approach, we build a spiking neural network where the effects and impact of learning can be predicted and tested, and the network can be scaled or extended to new tasks automatically. We introduce several enhancements to a basic network and show how they can be used to direct performance toward behaviorally relevant goals. Results show that using a simple classical spike-timing-dependent plasticity (STDP) rule on selected connections, we can get the robot (and network) to progress from poor task-specific performance to good performance. Behaviorally relevant STDP appears to contribute strongly to positive learning: ``do this' but less to negative learning: "don't do that." In addition, we observe that the effect of structural enhancements tends to be cumulative. The overall system suggests that it is by being able to exploit combinations of effects, rather than any one effect or property in isolation, that spiking networks can achieve compelling, task-relevant behavior.},
  file         = {:pdf-files/Rast2018 - Behavioral Learning in a Cognitive Neuromorphic Robot_ an Integrative Approach.pdf:PDF},
  groups       = {SpiNNaker, Neuromorphic Robotics},
  keywords     = {Biological system modeling;Brain modeling;Hardware;Neuromorphics;Robot sensing systems;Task analysis;Cognitive;learning;multiscale;neuromorphic;robotics;spike-timing-dependent plasticity (STDP)},
  owner        = {flo},
  timestamp    = {2018.07.13},
}

@Article{Mikolov2013a,
  author       = {Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
  title        = {Efficient Estimation of Word Representations in Vector Space},
  journaltitle = {Computing Research Repository (CoRR)},
  date         = {2013},
  volume       = {abs/1301.3781},
  url          = {http://arxiv.org/abs/1301.3781},
  file         = {:pdf-files/Mikolov2013a - Efficient Estimation of Word Representations in Vector Space.pdf:PDF},
  groups       = {Word Embedding},
  owner        = {flo},
  timestamp    = {2018.08.04},
}

@Article{Goldberg2014,
  author       = {Yoav Goldberg and Omer Levy},
  title        = {word2vec Explained: deriving Mikolov et al.'s negative-sampling word-embedding method},
  journaltitle = {Computing Research Repository (CoRR)},
  date         = {2014},
  url          = {http://arxiv.org/abs/1402.3722},
  file         = {:pdf-files/Goldberg2014 - Word2vec Explained_ Deriving Mikolov Et Al.'s Negative Sampling Word Embedding Method.pdf:PDF},
  groups       = {Word Embedding},
  owner        = {flo},
  timestamp    = {2018.08.04},
}

@InProceedings{Mikolov2013b,
  author    = {Mikolov, Tomas and Yih, Scott Wen-tau and Zweig, Geoffrey},
  title     = {Linguistic Regularities in Continuous Space Word Representations},
  booktitle = {Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT-2013)},
  date      = {2013},
  publisher = {Association for Computational Linguistics},
  url       = {https://www.microsoft.com/en-us/research/publication/linguistic-regularities-in-continuous-space-word-representations},
  file      = {:pdf-files/Mikolov2013b - Linguistic Regularities in Continuous Space Word Representations.pdf:PDF},
  groups    = {Word Embedding},
  owner     = {flo},
  timestamp = {2018.08.07},
}

@Article{Clark2013,
  author       = {Clark, Andy},
  title        = {Whatever next? Predictive brains, situated agents, and the future of cognitive science},
  journal      = {Behavioral and Brain Sciences},
  journaltitle = {Behavioral and Brain Sciences},
  year         = {2013},
  date         = {2013},
  volume       = {36},
  number       = {03},
  pages        = {181--204},
  doi          = {10.1017/s0140525x12000477},
  file         = {:pdf-files/Clark2013 - Whatever Next_ Predictive Brains, Situated Agents, and the Future of Cognitive Science.pdf:PDF},
  owner        = {flo},
  publisher    = {Cambridge University Press ({CUP})},
  timestamp    = {2018.08.10},
}

@Article{Garnelo2016,
  author       = {Marta Garnelo and Kai Arulkumaran and Murray Shanahan},
  title        = {Towards Deep Symbolic Reinforcement Learning},
  journaltitle = {Computing Research Repository (CoRR)},
  date         = {2016},
  volume       = {abs/1609.05518},
  eprinttype   = {arXiv},
  url          = {http://arxiv.org/abs/1609.05518},
  file         = {:pdf-files/Garnelo2016 - Towards Deep Symbolic Reinforcement Learning.pdf:PDF},
  groups       = {ReinforcementLearning},
  owner        = {flo},
  timestamp    = {2018.08.13},
}

@Book{Chollet2017,
  author    = {Chollet, Francois},
  title     = {Deep Learning with Python},
  date      = {2017},
  edition   = {1st},
  publisher = {Manning Publications Co.},
  location  = {Greenwich, CT, USA},
  isbn      = {1617294438, 9781617294433},
  file      = {:pdf-files/Chollet2017 - Deep Learning with Python.pdf:PDF},
  groups    = {Deep Neural Networks},
  owner     = {flo},
  timestamp = {2018.08.13},
}

@Article{Marcus2018,
  author       = {Gary Marcus},
  title        = {Deep Learning: {A} Critical Appraisal},
  journaltitle = {Computing Research Repository (CoRR)},
  date         = {2018},
  volume       = {abs/1801.00631},
  eprinttype   = {arXiv},
  url          = {http://arxiv.org/abs/1801.00631},
  file         = {:pdf-files/Marcus2018 - Deep Learning_ a Critical Appraisal.pdf:PDF},
  groups       = {Deep Neural Networks},
  owner        = {flo},
  timestamp    = {2018.08.13},
}

@Article{Rasmussen2011,
  author       = {Daniel Rasmussen and Chris Eliasmith},
  title        = {A Neural Model of Rule Generation in Inductive Reasoning},
  journal      = {Topics in Cognitive Science},
  journaltitle = {Topics in Cognitive Science},
  date         = {2011},
  volume       = {3},
  number       = {1},
  pages        = {140--153},
  doi          = {10.1111/j.1756-8765.2010.01127.x},
  abstract     = {Inductive reasoning is a fundamental and complex aspect of human intelligence. In particular, how do subjects, given a set of particular examples, generate general descriptions of the rules governing that set? We present a biologically plausible method for accomplishing this task and implement it in a spiking neuron model. We demonstrate the success of this model by applying it to the problem domain of Raven's Progressive Matrices, a widely used tool in the field of intelligence testing. The model is able to generate the rules necessary to correctly solve Raven's items, as well as recreate many of the experimental effects observed in human subjects.},
  file         = {:pdf-files/Rasmussen2011 - A Neural Model of Rule Generation in Inductive Reasoning.pdf:PDF},
  groups       = {Vector Symbolic Architectures},
  owner        = {flo},
  publisher    = {Wiley},
  timestamp    = {2018.08.13},
}

@InProceedings{Bing2018,
  author    = {Bing, Zhenshan and Meschede, Claus and Huang, Kai and Chen, Guang and R\"{o}hrbein, Florian and Akl, Mahmoud and Knoll, Alois},
  title     = {End to End Learning of Spiking Neural Network based on R-STDP for a Lane Keeping Vehicle},
  booktitle = {2018 IEEE International Conference on Robotics and Automation (ICRA)},
  date      = {2018},
  file      = {:pdf-files/Bing2018 - End to End Learning of Spiking Neural Network Based on R STDP for a Lane Keeping Vehicle.pdf:PDF},
  groups    = {Spiking Neural Networks},
  owner     = {flo},
  timestamp = {2018.09.28},
}

@Article{Summers-Stay2018,
  author       = {{Summers-Stay}, D. and {Sutor}, P. and {Li}, D.},
  title        = {{Representing Sets as Summed Semantic Vectors}},
  journal      = {ArXiv e-prints},
  journaltitle = {ArXiv e-prints},
  date         = {2018},
  eprint       = {1809.08823},
  eprinttype   = {arXiv},
  file         = {:pdf-files/Summers-Stay2018 - Representing Sets As Summed Semantic Vectors.pdf:PDF},
  groups       = {Vector Symbolic Architectures},
  keywords     = {Computer Science - Artificial Intelligence},
  owner        = {flo},
  timestamp    = {2018.09.28},
}

@Article{Hochreiter1997,
  author       = {Hochreiter, Sepp and Schmidhuber, Jürgen},
  date         = {1997},
  journaltitle = {Neural Computation},
  title        = {Long Short-Term Memory},
  doi          = {10.1162/neco.1997.9.8.1735},
  eprint       = {https://doi.org/10.1162/neco.1997.9.8.1735},
  number       = {8},
  pages        = {1735--1780},
  volume       = {9},
  abstract     = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
  file         = {:pdf-files/Hochreiter1997 - Long Short Term Memory.pdf:PDF},
  groups       = {Neural Networks, Machine Learning, Seq2Seq},
  journal      = {Neural Computation},
  owner        = {flo},
  publisher    = {{MIT} Press - Journals},
  timestamp    = {2018.10.02},
  year         = {1997},
}

@InCollection{Thagard2012,
  author    = {Paul Thagard},
  title     = {Cognitive Architectures},
  booktitle = {The Cambridge Handbook of Cognitive Science},
  date      = {2012},
  editor    = {Keith Frankish and William Ramsey},
  publisher = {Cambridge University Press},
  pages     = {50--70},
  file      = {:pdf-files/Thagard2012 - Cognitive Architectures.pdf:PDF},
  groups    = {Vector Symbolic Architectures},
  owner     = {flo},
  timestamp = {2018.10.08},
}

@Article{Mahmood2018,
  author       = {{Rupam Mahmood}, A. and {Korenkevych}, D. and {Vasan}, G. and {Ma}, W. and {Bergstra}, J.},
  title        = {{Benchmarking Reinforcement Learning Algorithms on Real-World Robots}},
  journaltitle = {ArXiv e-prints},
  date         = {2018},
  eprint       = {1809.07731},
  eprinttype   = {arXiv},
  file         = {:pdf-files/Mahmood2018 - Benchmarking Reinforcement Learning Algorithms on Real World Robots.pdf:PDF},
  groups       = {ReinforcementLearning},
  keywords     = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Robotics, Statistics - Machine Learning},
  owner        = {flo},
  timestamp    = {2018.10.22},
}

@Article{Bruce2018,
  author        = {Jake Bruce and Niko Sünderhauf and Piotr Mirowski and Raia Hadsell and Michael Milford},
  title         = {Learning Deployable Navigation Policies at Kilometer Scale from a Single Traversal},
  journaltitle  = {ArXiv e-prints},
  year          = {2018},
  date          = {2018-07-11},
  eid           = {arXiv:1807.05211},
  pages         = {arXiv:1807.05211},
  eprint        = {http://arxiv.org/abs/1807.05211v1},
  eprintclass   = {cs.RO},
  eprinttype    = {arXiv},
  abstract      = {Model-free reinforcement learning has recently been shown to be effective at learning navigation policies from complex image input. However, these algorithms tend to require large amounts of interaction with the environment, which can be prohibitively costly to obtain on robots in the real world. We present an approach for efficiently learning goal-directed navigation policies on a mobile robot, from only a single coverage traversal of recorded data. The navigation agent learns an effective policy over a diverse action space in a large heterogeneous environment consisting of more than 2km of travel, through buildings and outdoor regions that collectively exhibit large variations in visual appearance, self-similarity, and connectivity. We compare pretrained visual encoders that enable precomputation of visual embeddings to achieve a throughput of tens of thousands of transitions per second at training time on a commodity desktop computer, allowing agents to learn from millions of trajectories of experience in a matter of hours. We propose multiple forms of computationally efficient stochastic augmentation to enable the learned policy to generalise beyond these precomputed embeddings, and demonstrate successful deployment of the learned policy on the real robot without fine tuning, despite environmental appearance differences at test time. The dataset and code required to reproduce these results and apply the technique to other datasets and robots is made publicly available at rl-navigation.github.io/deployable.},
  archiveprefix = {arXiv},
  file          = {:pdf-files/Bruce2018 - Learning Deployable Navigation Policies at Kilometer Scale from a Single Traversal.pdf:PDF},
  groups        = {ReinforcementLearning},
  keywords      = {Computer Science - Robotics},
  owner         = {flo},
  timestamp     = {2018.12.04},
}

@Article{Lee2018,
  author        = {Robert Lee and Serena Mou and Vibhavari Dasagi and Jake Bruce and Jürgen Leitner and Niko Sünderhauf},
  title         = {{Zero-shot Sim-to-Real Transfer with Modular Priors}},
  journaltitle  = {ArXiv e-prints},
  year          = {2018},
  date          = {2018-09-20},
  eid           = {arXiv:1809.07480},
  pages         = {arXiv:1809.07480},
  eprint        = {http://arxiv.org/abs/1809.07480v1},
  eprintclass   = {cs.LG},
  eprinttype    = {arXiv},
  abstract      = {Current end-to-end Reinforcement Learning (RL) approaches are severely limited by restrictively large search spaces and are prone to overfitting to their training environment. This is because in end-to-end RL perception, decision-making and low-level control are all being learned jointly from very sparse reward signals, with little capability of incorporating prior knowledge or existing algorithms. In this work, we propose a novel framework that effectively decouples RL for high-level decision making from low-level perception and control. This allows us to transfer a learned policy from a highly abstract simulation to a real robot without requiring any transfer learning. We therefore coin our approach zero-shot sim-to-real transfer. We successfully demonstrate our approach on the robot manipulation task of object sorting. A key component of our approach is a deep sets encoder that enables us to reinforcement learn the high-level policy based on the variable-length output of a pre-trained object detector, instead of learning from raw pixels. We show that this method can learn effective policies within mere minutes of highly simplified simulation. The learned policies can be directly deployed on a robot without further training, and generalize to variations of the task unseen during training.},
  archiveprefix = {arXiv},
  file          = {:pdf-files/Lee2018 - Zero Shot Sim to Real Transfer with Modular Priors.pdf:PDF},
  groups        = {ReinforcementLearning},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning},
  owner         = {flo},
  primaryclass  = {cs.LG},
  timestamp     = {2018.12.04},
}

@InProceedings{Cheng2018,
  author    = {Cheng, Hao and Sester, Monika},
  title     = {Mixed Traffic Trajectory Prediction Using LSTM--Based Models in Shared Space},
  booktitle = {Geospatial Technologies for All},
  date      = {2018},
  editor    = {Mansourian, Ali and Pilesj{\"o}, Petter and Harrie, Lars and van Lammeren, Ron},
  publisher = {Springer International Publishing},
  location  = {Cham},
  isbn      = {978-3-319-78208-9},
  pages     = {309--325},
  abstract  = {Real--world behaviors of human road users in a non-regulated space (shared space) are complex. Firstly, there is no explicit regulation in such an area. Users self-organize to share the space. They are more likely to use as little energy as possible to reach their destinations in the shortest possible way, and try to avoid any potential collision. Secondly, different types of users (pedestrians, cyclists, and vehicles) behave differently. For example, pedestrians are more flexible to change their speed and trajectory, while cyclists and vehicles are more or less limited by their travel device---abrupt changes might lead to danger. While there are established models to describe the behavior of individual humans (e.g. Social Force model), due to the heterogeneity of transport modes and diversity of environments, hand-crafted models have difficulties in handling complicated interactions in mixed traffic. To this end, this paper proposes using a Long Short--Term Memory (LSTM) recurrent neural networks based deep learning approach to model user behaviors. It encodes user position coordinates, sight of view, and interactions between different types of neighboring users as spatio--temporal features to predict future trajectories with collision avoidance. The real--world data--driven method can be trained with pre-defined neural networks to circumvent complex manual design and calibration. The results show that ViewType-LSTM, which mimics how a human sees and reacts to different transport modes can well predict mixed traffic trajectories in a shared space at least in the next 3 s, and is also robust in complicated situations.},
  file      = {:pdf-files/Cheng2018 - Mixed Traffic Trajectory Prediction Using LSTM Based Models in Shared Space.pdf:PDF},
  groups    = {Behaviour analysis},
  owner     = {flo},
  timestamp = {2018.12.04},
}

@InProceedings{Deo2018,
  author    = {Nachiket Deo and Mohan M. Trivedi},
  title     = {Multi-Modal Trajectory Prediction of Surrounding Vehicles with Maneuver based LSTMs},
  booktitle = {2018 {IEEE} Intelligent Vehicles Symposium ({IV})},
  year      = {2018},
  date      = {2018},
  publisher = {{IEEE}},
  pages     = {1179--1184},
  doi       = {10.1109/ivs.2018.8500493},
  abstract  = {To safely and efficiently navigate through complex traffic scenarios, autonomous vehicles need to have the ability to predict the future motion of surrounding vehicles. Multiple interacting agents, the multi-modal nature of driver behavior, and the inherent uncertainty involved in the task make motion prediction of surrounding vehicles a challenging problem. In this paper, we present an LSTM model for interaction aware motion prediction of surrounding vehicles on freeways. Our model assigns confidence values to maneuvers being performed by vehicles and outputs a multi-modal distribution over future motion based on them. We compare our approach with the prior art for vehicle motion prediction on the publicly available NGSIM US-101 and I-80 datasets. Our results show an improvement in terms of RMS values of prediction error. We also present an ablative analysis of the components of our proposed model and analyze the predictions made by the model in complex traffic scenarios.},
  file      = {:pdf-files/Deo2018 - Multi Modal Trajectory Prediction of Surrounding Vehicles with Maneuver Based LSTMs.pdf:PDF},
  groups    = {Behaviour analysis},
  issn      = {1931-0587},
  keywords  = {driver information systems;road traffic;road vehicles;traffic engineering computing;surrounding vehicles;complex traffic scenarios;autonomous vehicles;interaction aware motion prediction;multimodal distribution;vehicle motion prediction;multi-modal trajectory prediction;maneuver based LSTM;NGSIM US-101 dataset;I-80 datasets;Trajectory;Predictive models;Traffic control;History;Hidden Markov models;Decoding;Vehicles},
  owner     = {flo},
  timestamp = {2018.12.04},
}

@Article{Deo2018a,
  author        = {Nachiket Deo and Mohan M. Trivedi},
  title         = {Convolutional Social Pooling for Vehicle Trajectory Prediction},
  journal       = {CoRR},
  journaltitle  = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, 2018, pp. 1468-1476},
  year          = {2018},
  date          = {2018-05-15},
  volume        = {abs/1805.06771},
  eprint        = {http://arxiv.org/abs/1805.06771v1},
  eprintclass   = {cs.CV},
  eprinttype    = {arXiv},
  url           = {http://arxiv.org/abs/1805.06771},
  abstract      = {Forecasting the motion of surrounding vehicles is a critical ability for an autonomous vehicle deployed in complex traffic. Motion of all vehicles in a scene is governed by the traffic context, i.e., the motion and relative spatial configuration of neighboring vehicles. In this paper we propose an LSTM encoder-decoder model that uses convolutional social pooling as an improvement to social pooling layers for robustly learning interdependencies in vehicle motion. Additionally, our model outputs a multi-modal predictive distribution over future trajectories based on maneuver classes. We evaluate our model using the publicly available NGSIM US-101 and I-80 datasets. Our results show improvement over the state of the art in terms of RMS values of prediction error and negative log-likelihoods of true future trajectories under the model's predictive distribution. We also present a qualitative analysis of the model's predicted distributions for various traffic scenarios.},
  archiveprefix = {arXiv},
  file          = {:pdf-files/Deo2018a - Convolutional Social Pooling for Vehicle Trajectory Prediction.pdf:PDF},
  groups        = {Behaviour analysis},
  keywords      = {cs.CV},
  owner         = {flo},
  timestamp     = {2018.12.04},
}

@Article{Sha2017,
  author        = {Shital Shah and Debadeepta Dey and Chris Lovett and Ashish Kapoor},
  title         = {{AirSim: High-Fidelity Visual and Physical Simulation for Autonomous Vehicles}},
  journaltitle  = {ArXiv e-prints},
  year          = {2017},
  date          = {2017-05-15},
  eid           = {arXiv:1705.05065},
  pages         = {arXiv:1705.05065},
  eprint        = {http://arxiv.org/abs/1705.05065v2},
  eprintclass   = {cs.RO},
  eprinttype    = {arXiv},
  abstract      = {Developing and testing algorithms for autonomous vehicles in real world is an expensive and time consuming process. Also, in order to utilize recent advances in machine intelligence and deep learning we need to collect a large amount of annotated training data in a variety of conditions and environments. We present a new simulator built on Unreal Engine that offers physically and visually realistic simulations for both of these goals. Our simulator includes a physics engine that can operate at a high frequency for real-time hardware-in-the-loop (HITL) simulations with support for popular protocols (e.g. MavLink). The simulator is designed from the ground up to be extensible to accommodate new types of vehicles, hardware platforms and software protocols. In addition, the modular design enables various components to be easily usable independently in other projects. We demonstrate the simulator by first implementing a quadrotor as an autonomous vehicle and then experimentally comparing the software components with real-world flights.},
  archiveprefix = {arXiv},
  file          = {:pdf-files/Sha2017 - AirSim_ High Fidelity Visual and Physical Simulation for Autonomous Vehicles.pdf:PDF},
  groups        = {Simulators},
  keywords      = {Computer Science - Robotics, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Systems and Control},
  owner         = {flo},
  primaryclass  = {cs.RO},
  timestamp     = {2018.12.04},
}

@Article{Kuefler2017,
  author        = {Alex Kuefler and Jeremy Morton and Tim Wheeler and Mykel Kochenderfer},
  title         = {{Imitating Driver Behavior with Generative Adversarial Networks}},
  journaltitle  = {arXiv e-prints},
  year          = {2017},
  date          = {2017-01-24},
  eid           = {arXiv:1701.06699},
  pages         = {arXiv:1701.06699},
  eprint        = {http://arxiv.org/abs/1701.06699v1},
  eprintclass   = {cs.AI},
  eprinttype    = {arXiv},
  abstract      = {The ability to accurately predict and simulate human driving behavior is critical for the development of intelligent transportation systems. Traditional modeling methods have employed simple parametric models and behavioral cloning. This paper adopts a method for overcoming the problem of cascading errors inherent in prior approaches, resulting in realistic behavior that is robust to trajectory perturbations. We extend Generative Adversarial Imitation Learning to the training of recurrent policies, and we demonstrate that our model outperforms rule-based controllers and maximum likelihood models in realistic highway simulations. Our model both reproduces emergent behavior of human drivers, such as lane change rate, while maintaining realistic control over long time horizons.},
  archiveprefix = {arXiv},
  file          = {:pdf-files/Kuefler2017 - Imitating Driver Behavior with Generative Adversarial Networks.pdf:PDF},
  groups        = {Behaviour analysis},
  keywords      = {Computer Science - Artificial Intelligence},
  owner         = {flo},
  primaryclass  = {cs.AI},
  timestamp     = {2018.12.10},
}

@Online{NGSIM-US101,
  author    = {James Colyar and John Halkias},
  title     = {US Highway 101 Dataset},
  date      = {2018-12-10},
  url       = {https://www.fhwa.dot.gov/publications/research/operations/07030/index.cfm},
  urldate   = {2018-04-03},
  groups    = {Datasets},
  owner     = {flo},
  timestamp = {2018.12.10},
  year      = {2017},
}

@Article{Chen2018,
  author       = {Guang Chen and Hu Cao and Muhammad Aafaque and Jieneng Chen and Canbo Ye and Florian R{\"o}hrbein and J{\"o}rg Conradt and Kai Chen and Zhenshan Bing and Xingbo Liu and Gereon Hinz and Walter Stechele and Alois Knoll},
  title        = {Neuromorphic Vision Based Multivehicle Detection and Tracking for Intelligent Transportation System},
  journaltitle = {Journal of Advanced Transportation},
  date         = {2018},
  volume       = {2018},
  pages        = {13},
  doi          = {10.1155/2018/4815383},
  file         = {:pdf-files/Chen2018 - Neuromorphic Vision Based Multivehicle Detection and Tracking for Intelligent Transportation System.pdf:PDF},
  groups       = {Neuromorphic Vision},
  owner        = {flo},
  publisher    = {Hindawi Limited},
  timestamp    = {2018.12.14},
}

@Article{Chen2018a,
  author        = {Tian Qi Chen and Yulia Rubanova and Jesse Bettencourt and David K. Duvenaud},
  title         = {Neural Ordinary Differential Equations},
  journaltitle  = {CoRR},
  year          = {2018},
  date          = {2018-06-19},
  volume        = {abs/1806.07366},
  eprint        = {1806.07366},
  eprintclass   = {cs.LG},
  eprinttype    = {arXiv},
  url           = {http://arxiv.org/abs/1806.07366},
  abstract      = {We introduce a new family of deep neural network models. Instead of specifying a discrete sequence of hidden layers, we parameterize the derivative of the hidden state using a neural network. The output of the network is computed using a black-box differential equation solver. These continuous-depth models have constant memory cost, adapt their evaluation strategy to each input, and can explicitly trade numerical precision for speed. We demonstrate these properties in continuous-depth residual networks and continuous-time latent variable models. We also construct continuous normalizing flows, a generative model that can train by maximum likelihood, without partitioning or ordering the data dimensions. For training, we show how to scalably backpropagate through any ODE solver, without access to its internal operations. This allows end-to-end training of ODEs within larger models.},
  archiveprefix = {arXiv},
  file          = {:pdf-files/Chen2018a - Neural Ordinary Differential Equations.pdf:PDF},
  groups        = {Neural Networks},
  keywords      = {cs.LG, cs.AI, stat.ML},
  owner         = {flo},
  timestamp     = {2018.12.14},
}

@Article{Blouw2018,
  author        = {Peter Blouw and Xuan Choo and Eric Hunsberger and Chris Eliasmith},
  title         = {{Benchmarking Keyword Spotting Efficiency on Neuromorphic Hardware}},
  journaltitle  = {arXiv e-prints},
  date          = {2018-12-04},
  eid           = {arXiv:1812.01739},
  pages         = {arXiv:1812.01739},
  eprint        = {1812.01739},
  eprintclass   = {cs.LG},
  eprinttype    = {arXiv},
  abstract      = {Using Intel's Loihi neuromorphic research chip and ABR's Nengo Deep Learning toolkit, we analyze the inference speed, dynamic power consumption, and energy cost per inference of a two-layer neural network keyword spotter trained to recognize a single phrase. We perform comparative analyses of this keyword spotter running on more conventional hardware devices including a CPU, a GPU, Nvidia's Jetson TX1, and the Movidius Neural Compute Stick. Our results indicate that for this inference application, Loihi outperforms all of these alternatives on an energy cost per inference basis while maintaining near-equivalent inference accuracy. Furthermore, an analysis of tradeoffs between network size, inference speed, and energy cost indicates that Loihi's comparative advantage over other low-power computing devices improves for larger networks.},
  archiveprefix = {arXiv},
  file          = {:pdf-files/Blouw2018 - Benchmarking Keyword Spotting Efficiency on Neuromorphic Hardware.pdf:PDF},
  groups        = {Loihi},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning},
  owner         = {flo},
  primaryclass  = {cs.LG},
  timestamp     = {2018.12.14},
  year          = {2018},
}

@Article{Lin2014,
  author        = {Tsung-Yi Lin and Michael Maire and Serge Belongie and Lubomir Bourdev and Ross Girshick and James Hays and Pietro Perona and Deva Ramanan and C. Lawrence Zitnick and Piotr Dollár},
  title         = {Microsoft COCO: Common Objects in Context},
  journaltitle  = {arXiv e-prints},
  year          = {2014},
  date          = {2014-05-01},
  eid           = {arXiv:1405.0312},
  pages         = {arXiv:1405.0312},
  eprint        = {http://arxiv.org/abs/1405.0312v3},
  eprintclass   = {cs.CV},
  eprinttype    = {arXiv},
  abstract      = {We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.},
  archiveprefix = {arXiv},
  file          = {:pdf-files/Lin2014 - Microsoft COCO_ Common Objects in Context.pdf:PDF},
  groups        = {Datasets},
  keywords      = {Computer Science - Computer Vision and Pattern Recognition},
  owner         = {flo},
  primaryclass  = {cs.CV},
  timestamp     = {2018.12.22},
}

@TechReport{He2017,
  author    = {He, Zhengbing},
  title     = {Research based on high-fidelity NGSIM vehicle trajectory datasets: A review},
  year      = {2017},
  date      = {2017},
  doi       = {10.13140/RG.2.2.11429.60643},
  file      = {:pdf-files/He2017 - Research Based on High Fidelity NGSIM Vehicle Trajectory Datasets_ a Review.pdf:PDF},
  groups    = {Datasets},
  owner     = {flo},
  timestamp = {2018.12.28},
}

@Article{Knight2018,
  author       = {James C. Knight and Thomas Nowotny},
  title        = {{GPUs} Outperform Current {HPC} and Neuromorphic Solutions in Terms of Speed and Energy When Simulating a Highly-Connected Cortical Model},
  journaltitle = {Frontiers in Neuroscience},
  date         = {2018},
  volume       = {12},
  pages        = {941},
  issn         = {1662-453X},
  doi          = {10.3389/fnins.2018.00941},
  abstract     = {While neuromorphic systems may be the ultimate platform for deploying spiking neural networks (SNNs), their distributed nature and optimisation for specific types of models makes them unwieldy tools for developing them.
Instead, SNN models tend to be developed and simulated on computers or clusters of computers with standard Von Neumann CPU architectures.
Over the last decade, as well as becoming a common fixture in many workstations, NVIDIA GPU accelerators have entered the High Performance Computing field and are now used in 50 of the Top 10 super computing sites worldwide.
In this paper we use our GeNN code generator to re-implement two neo-cortex-inspired, circuit-scale, point neuron network models on GPU hardware.
We verify the correctness of our GPU simulations against prior results obtained with NEST running on traditional HPC hardware and compare the performance with respect to speed and energy consumption against published data from CPU-based HPC and neuromorphic hardware.
A full-scale model of a cortical column can be simulated at speeds approaching  real-time using a single NVIDIA Tesla V100 accelerator - faster than is currently possible using a CPU based cluster or the SpiNNaker neuromorphic system.
In addition, we find that, across a range of GPU systems, the energy to solution as well as the energy per synaptic event of the microcircuit simulation is as much as  lower than either on SpiNNaker or in CPU-based simulations.
Besides performance in terms of speed and energy consumption of the simulation, efficient initialisation of models is also a crucial concern, particularly in a research context where repeated runs and parameter-space exploration are required. 
Therefore, we also introduce in this paper some of the novel parallel initialisation methods implemented in the latest version of GeNN and demonstrate how they can enable further speed and energy advantages.},
  file         = {:pdf-files/Knight2018 - GPUs Outperform Current HPC and Neuromorphic Solutions in Terms of Speed and Energy When Simulating a Highly Connected Cortical Model.pdf:PDF},
  groups       = {Neuromorphic Hardware},
  owner        = {flo},
  publisher    = {Frontiers Media {SA}},
  timestamp    = {2019.01.12},
}

@PhdThesis{Waniek2018,
  author      = {Nikolai Waniek},
  title       = {Locally distributed spatial navigation in a scale-space model for grid cells},
  institution = {Technical University of Munich},
  date        = {2018},
  url         = {https://rochus.net/pdf/waniek2018diss.pdf},
  urldate     = {2019-01-19},
  file        = {:pdf-files/Waniek2018 - Locally Distributed Spatial Navigation in a Scale Space Model for Grid Cells.pdf:PDF},
  owner       = {flo},
  timestamp   = {2019.01.19},
}

@Article{Steyer2018,
  author       = {Sascha Steyer and Georg Tanzmeister and Dirk Wollherr},
  title        = {Grid-Based Environment Estimation Using Evidential Mapping and Particle Tracking},
  journaltitle = {{IEEE} Transactions on Intelligent Vehicles},
  date         = {2018},
  volume       = {3},
  number       = {3},
  pages        = {384--396},
  issn         = {2379-8904},
  doi          = {10.1109/TIV.2018.2843130},
  abstract     = {Modeling and estimating the current local environment by processing sensor measurement data is essential for intelligent vehicles. Static obstacles, dynamic objects, and free space have to be appropriately represented, classified, and filtered. Occupancy grids, known for mapping static environments, provide a common low-level representation using occupancy probabilities with an implicit data association through the discrete grid structure. Extending this idea toward dynamic environments with moving objects requires a static/dynamic classification of measured occupancy and a tracking of the dynamic state of grid cells. In this paper, we propose a new dynamic grid mapping approach. An evidential representation using the Dempster-Shafer framework is used to model hypotheses for static occupancy, dynamic occupancy, free space, and their combined hypotheses. These hypotheses are consistently estimated and accumulated in a dynamic grid map by an adapted evidential filtering, allowing one to distinguish static and dynamic occupancy. The evidential grid mapping is combined with a low-level particle filter tracking that is used to estimate cell velocity distributions and predict dynamic occupancy of the grid map. Static occupancy is directly modeled in the grid map without requiring particles, increasing efficiency, and improving the static/dynamic classification due to the persistent map accumulation. Experimental results with real sensor data show the effectiveness of the proposed approach in challenging scenarios with occlusions and dense traffic.},
  file         = {:pdf-files/Steyer2018 - Grid Based Environment Estimation Using Evidential Mapping and Particle Tracking.pdf:PDF},
  groups       = {Autonomous Driving, Environment Model},
  keywords     = {Vehicle dynamics;Estimation;Atmospheric measurements;Particle measurements;Particle tracking;Robot sensing systems;Robustness;Autonomous vehicles;dynamic occupancy grids;environment perception;mapping;object detection;tracking},
  owner        = {flo},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  timestamp    = {2019.01.21},
}

@InProceedings{Mirus2019,
  author    = {Florian Mirus and Peter Blouw and Terrence C. Stewart and J\"org Conradt},
  title     = {Predicting vehicle behaviour using LSTMs and a vector power representation for spatial positions},
  booktitle = {27th European Symposium on Artificial Neural Networks, {ESANN} 2019, Bruges, Belgium},
  date      = {2019},
  pages     = {113--118},
  abstract  = {Predicting future vehicle behaviour is an essential task to enable safe and situation-aware automated driving. In this paper, we propose to encapsulate spatial information of multiple objects in a semantic vector-representation. Assuming that future vehicle motion is influenced not only by past positions but also by the behaviour of other traffic participants, we use this representation as input for a Long Short-Term Memory (LSTM) network for sequence to sequence prediction of vehicle positions. We train and evaluate our system on real-world driving data collected mainly on highways in southern Germany and compare it to other models for reference.},
  owner     = {flo},
  timestamp = {2019.01.28},
  year      = {2019},
}

@Article{Mirus2019b,
  author    = {Mirus, Florian and Blouw, Peter and Stewart, Terrence C. and Conradt, Jörg},
  title     = {An Investigation of Vehicle Behavior Prediction Using a Vector Power Representation to Encode Spatial Positions of Multiple Objects and Neural Networks},
  doi       = {10.3389/fnbot.2019.00084},
  issn      = {1662-5218},
  pages     = {84},
  url       = {https://www.frontiersin.org/article/10.3389/fnbot.2019.00084},
  volume    = {13},
  abstract  = {Predicting future behavior and positions of other traffic participants from observations is a key problem that needs to be solved by human drivers and automated vehicles alike to safely navigate their environment and to reach their desired goal. In this paper, we expand on previous work on an automotive environment model based on vector symbolic architectures (VSAs). We investigate a vector-representation to encapsulate spatial information of multiple objects based on a convolutive power encoding. Assuming that future positions of vehicles are influenced not only by their own past positions and dynamics (e.g., velocity and acceleration) but also by the behavior of the other traffic participants in the vehicle's surroundings, our motivation is 3-fold: we hypothesize that our structured vector-representation will be able to capture these relations and mutual influence between multiple traffic participants. Furthermore, the dimension of the encoding vectors remains fixed while being independent of the number of other vehicles encoded in addition to the target vehicle. Finally, a VSA-based encoding allows us to combine symbol-like processing with the advantages of neural network learning. In this work, we use our vector representation as input for a long short-term memory (LSTM) network for sequence to sequence prediction of vehicle positions. In an extensive evaluation, we compare this approach to other LSTM-based benchmark systems using alternative data encoding schemes, simple feed-forward neural networks as well as a simple linear prediction model for reference. We analyze advantages and drawbacks of the presented methods and identify specific driving situations where our approach performs best. We use characteristics specifying such situations as a foundation for an online-learning mixture-of-experts prototype, which chooses at run time between several available predictors depending on the current driving situation to achieve the best possible forecast.},
  journal   = {Frontiers in Neurorobotics},
  month     = {oct},
  owner     = {flo},
  publisher = {Frontiers Media {SA}},
  timestamp = {2018.03.29},
  year      = {2019},
}

@InProceedings{Mirus2019a,
  author    = {Florian Mirus and Benjamin Zorn and J\"org Conradt},
  title     = {Short-term trajectory planning using reinforcement learning within a neuromorphic control architecture},
  booktitle = {27th European Symposium on Artificial Neural Networks, {ESANN} 2019, Bruges, Belgium},
  date      = {2019},
  pages     = {649--654},
  abstract  = {In this paper, we present a first step towards neuromorphic vehicle control. We propose a modular and hierarchical system architecture entirely implemented in a spiking neuron substrate, which allows for adjustment of individual components trough either supervised or reinforcement learning as well as future deployment on dedicated neuromorphic hardware. In a sample instantiation, we investigate automated training of a neuromorphic trajectory selection module using reinforcement learning to demonstrate the general feasibility of our approach. We evaluate our system using the open-source race car simulator TORCS.},
  owner     = {flo},
  timestamp = {2019.01.28},
  year      = {2019},
}

@Article{Biyik2018,
  author        = {{B{\i}y{\i}k}, Erdem and {Lazar}, Daniel and {Pedarsani}, Ramtin and {Sadigh}, Dorsa},
  title         = {{Altruistic Autonomy: Beating Congestion on Shared Roads}},
  journaltitle  = {arXiv e-prints},
  year          = {2018},
  date          = {2018-10-29},
  eid           = {arXiv:1810.11978},
  pages         = {arXiv:1810.11978},
  eprint        = {http://arxiv.org/abs/1810.11978v1},
  eprintclass   = {math.OC},
  eprinttype    = {arXiv},
  abstract      = {Traffic congestion has large economic and social costs. The introduction of autonomous vehicles can potentially reduce this congestion, both by increasing network throughput and by enabling a social planner to incentivize users of autonomous vehicles to take longer routes that can alleviate congestion on more direct roads. We formalize the effects of altruistic autonomy on roads shared between human drivers and autonomous vehicles. In this work, we develop a formal model of road congestion on shared roads based on the fundamental diagram of traffic. We consider a network of parallel roads and provide algorithms that compute optimal equilibria that are robust to additional unforeseen demand. We further plan for optimal routings when users have varying degrees of altruism. We find that even with arbitrarily small altruism, total latency can be unboundedly better than without altruism, and that the best selfish equilibrium can be unboundedly better than the worst selfish equilibrium. We validate our theoretical results through microscopic traffic simulations and show average latency decrease of a factor of 4 from worst-case selfish equilibrium to the optimal equilibrium when autonomous vehicles are altruistic.},
  archiveprefix = {arXiv},
  file          = {:pdf-files/Biyik2018 - Altruistic Autonomy_ Beating Congestion on Shared Roads.pdf:PDF},
  groups        = {Autonomous Driving},
  keywords      = {Mathematics - Optimization and Control, Computer Science - Robotics},
  owner         = {flo},
  timestamp     = {2019.01.30},
}

@Article{BrainRobots2016,
  title        = {Booklet $\vert$ Brain-inspired intelligent robotics: The intersection of robotics and neuroscience sciences},
  journaltitle = {Science},
  date         = {2016},
  editor       = {,},
  volume       = {354},
  number       = {6318},
  pages        = {14452--1445},
  issn         = {0036-8075},
  doi          = {10.1126/science.354.6318.1445-b},
  eprint       = {http://science.sciencemag.org/content},
  url          = {http://science.sciencemag.org/content/354/6318/1445.2},
  file         = {:pdf-files/BrainRobots2016 - Booklet $$ Brain Inspired Intelligent Robotics_ the Intersection of Robotics and Neuroscience Sciences.pdf:PDF},
  owner        = {flo},
  publisher    = {American Association for the Advancement of Science},
  timestamp    = {2019.01.31},
}

@Article{Dikov2019,
  author       = {{Dikov}, Georgi and {van der Smagt}, Patrick and {Bayer}, Justin},
  title        = {{Bayesian Learning of Neural Network Architectures}},
  journaltitle = {arXiv e-prints},
  date         = {2019},
  eid          = {arXiv:1901.04436},
  pages        = {arXiv:1901.04436},
  eprint       = {1901.04436},
  eprintclass  = {stat.ML},
  eprinttype   = {arXiv},
  file         = {:pdf-files/Dikov2019 - Bayesian Learning of Neural Network Architectures.pdf:PDF},
  groups       = {Deep Neural Networks},
  keywords     = {Statistics - Machine Learning, Computer Science - Machine Learning},
  owner        = {flo},
  timestamp    = {2019.02.01},
}

@Article{Hoi2018,
  author       = {Steven C. H. Hoi and Doyen Sahoo and Jing Lu and Peilin Zhao},
  title        = {Online Learning: {A} Comprehensive Survey},
  journaltitle = {CoRR},
  date         = {2018-02-08},
  volume       = {abs/1802.02871},
  eprint       = {1802.02871},
  eprintclass  = {cs.LG},
  eprinttype   = {arXiv},
  url          = {http://arxiv.org/abs/1802.02871},
  abstract     = {Online learning represents an important family of machine learning algorithms, in which a learner attempts to resolve an online prediction (or any type of decision-making) task by learning a model/hypothesis from a sequence of data instances one at a time. The goal of online learning is to ensure that the online learner would make a sequence of accurate predictions (or correct decisions) given the knowledge of correct answers to previous prediction or learning tasks and possibly additional information. This is in contrast to many traditional batch learning or offline machine learning algorithms that are often designed to train a model in batch from a given collection of training data instances. This survey aims to provide a comprehensive survey of the online machine learning literatures through a systematic review of basic ideas and key principles and a proper categorization of different algorithms and techniques. Generally speaking, according to the learning type and the forms of feedback information, the existing online learning works can be classified into three major categories: (i) supervised online learning where full feedback information is always available, (ii) online learning with limited feedback, and (iii) unsupervised online learning where there is no feedback available. Due to space limitation, the survey will be mainly focused on the first category, but also briefly cover some basics of the other two categories. Finally, we also discuss some open issues and attempt to shed light on potential future research directions in this field.},
  file         = {:pdf-files/Hoi2018 - Online Learning_ a Comprehensive Survey.pdf:PDF},
  groups       = {Online learning},
  keywords     = {cs.LG},
  owner        = {flo},
  timestamp    = {2019.02.07},
}

@Article{McMahan2017,
  author       = {H. Brendan McMahan},
  title        = {A survey of Algorithms and Analysis for Adaptive Online Learning},
  journaltitle = {Journal of Machine Learning Research},
  date         = {2017},
  volume       = {18},
  number       = {90},
  pages        = {1--50},
  url          = {http://jmlr.org/papers/v18/14-428.html},
  abstract     = {We present tools for the analysis of Follow-The-Regularized- Leader (FTRL), Dual Averaging, and Mirror Descent algorithms when the regularizer (equivalently, prox-function or learning rate schedule) is chosen adaptively based on the data. Adaptivity can be used to prove regret bounds that hold on every round, and also allows for data-dependent regret bounds as in AdaGrad-style algorithms (e.g., Online Gradient Descent with adaptive per-coordinate learning rates). We present results from a large number of prior works in a unified manner, using a modular and tight analysis that isolates the key arguments in easily re-usable lemmas. This approach strengthens previously known FTRL analysis techniques to produce bounds as tight as those achieved by potential functions or primal-dual analysis. Further, we prove a general and exact equivalence between adaptive Mirror Descent algorithms and a corresponding FTRL update, which allows us to analyze Mirror Descent algorithms in the same framework. The key to bridging the gap between Dural Averaging and Mirror Descent algorithms lies in an analysis of the FTRL-Proximal algorithm family. Our regret bounds are proved in the most general form, holding for arbitrary norms and non- smooth regularizers with time-varying weight.},
  file         = {:pdf-files/McMahan2017 - A Survey of Algorithms and Analysis for Adaptive Online Learning.pdf:PDF},
  groups       = {Online learning},
  owner        = {flo},
  timestamp    = {2019.02.07},
}

@Article{Feng2019,
  author    = {Feng, Di and Haase-Sch{\"u}tz, Christian and Hertlein, Heinz and Duffhau\ss{}, Fabian and Gl{\"a}ser, Claudius and Wiesbeck, Werner},
  title     = {Deep Multi-modal Object Detection and Semantic Segmentation for Autonomous Driving: Datasets, Methods, and Challenges},
  year      = {2019},
  date      = {2019},
  language  = {en},
  doi       = {10.13140/RG.2.2.10246.01606},
  file      = {:pdf-files/Feng2019 - Deep Multi Modal Object Detection and Semantic Segmentation for Autonomous Driving_ Datasets, Methods, and Challenges.pdf:PDF},
  groups    = {Deep Neural Networks, Object Recognition, Autonomous Driving},
  owner     = {flo},
  publisher = {Unpublished},
  timestamp = {2019.02.21},
}

@Article{Goldhammer2018,
  author        = {Michael Goldhammer and Sebastian K{\"{o}}hler and Stefan Zernetsch and Konrad Doll and Bernhard Sick and Klaus Dietmayer},
  title         = {Intentions of Vulnerable Road Users - Detection and Forecasting by Means of Machine Learning},
  journaltitle  = {CoRR},
  year          = {2018},
  date          = {2018-03-09},
  volume        = {abs/1803.03577},
  eprint        = {1803.03577},
  eprintclass   = {cs.CV},
  eprinttype    = {arXiv},
  url           = {http://arxiv.org/abs/1803.03577},
  abstract      = {Avoiding collisions with vulnerable road users (VRUs) using sensor-based early recognition of critical situations is one of the manifold opportunities provided by the current development in the field of intelligent vehicles. As especially pedestrians and cyclists are very agile and have a variety of movement options, modeling their behavior in traffic scenes is a challenging task. In this article we propose movement models based on machine learning methods, in particular artificial neural networks, in order to classify the current motion state and to predict the future trajectory of VRUs. Both model types are also combined to enable the application of specifically trained motion predictors based on a continuously updated pseudo probabilistic state classification. Furthermore, the architecture is used to evaluate motion-specific physical models for starting and stopping and video-based pedestrian motion classification. A comprehensive dataset consisting of 1068 pedestrian and 494 cyclist scenes acquired at an urban intersection is used for optimization, training, and evaluation of the different models. The results show substantial higher classification rates and the ability to earlier recognize motion state changes with the machine learning approaches compared to interacting multiple model (IMM) Kalman Filtering. The trajectory prediction quality is also improved for all kinds of test scenes, especially when starting and stopping motions are included. Here, 37\% and 41\% lower position errors were achieved on average, respectively.},
  archiveprefix = {arXiv},
  comment       = {Data set available at https://www.h-ab.de/ueber-uns/organisation/labor/kooperative-automatisierte-verkehrssysteme/trajectory-dataset/},
  file          = {:pdf-files/Goldhammer2018 - Intentions of Vulnerable Road Users Detection and Forecasting by Means of Machine Learning.pdf:PDF},
  groups        = {Behaviour analysis},
  keywords      = {cs.CV},
  owner         = {flo},
  timestamp     = {Mon, 13 Aug 2018 16:48:52 +0200},
}

@Article{Ma2018,
  author        = {{Ma}, Yuexin and {Zhu}, Xinge and {Zhang}, Sibo and {Yang}, Ruigang and {Wang}, Wenping and {Manocha}, Dinesh},
  title         = {{TrafficPredict: Trajectory Prediction for Heterogeneous Traffic-Agents}},
  journaltitle  = {arXiv e-prints},
  year          = {2018},
  date          = {2018-11-06},
  eid           = {arXiv:1811.02146},
  pages         = {arXiv:1811.02146},
  eprint        = {1811.02146},
  eprintclass   = {cs.CV},
  eprinttype    = {arXiv},
  abstract      = {To safely and efficiently navigate in complex urban traffic, autonomous vehicles must make responsible predictions in relation to surrounding traffic-agents (vehicles, bicycles, pedestrians, etc.). A challenging and critical task is to explore the movement patterns of different traffic-agents and predict their future trajectories accurately to help the autonomous vehicle make reasonable navigation decision. To solve this problem, we propose a long short-term memory-based (LSTM-based) realtime traffic prediction algorithm, TrafficPredict. Our approach uses an instance layer to learn instances' movements and interactions and has a category layer to learn the similarities of instances belonging to the same type to refine the prediction. In order to evaluate its performance, we collected trajectory datasets in a large city consisting of varying conditions and traffic densities. The dataset includes many challenging scenarios where vehicles, bicycles, and pedestrians move among one another. We evaluate the performance of TrafficPredict on our new dataset and highlight its higher accuracy for trajectory prediction by comparing with prior prediction methods.},
  archiveprefix = {arXiv},
  file          = {:pdf-files/Ma2018 - TrafficPredict_ Trajectory Prediction for Heterogeneous Traffic Agents.pdf:PDF},
  groups        = {Behaviour analysis},
  keywords      = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
  owner         = {flo},
  primaryclass  = {cs.CV},
  timestamp     = {2019.03.08},
}

@Article{Hohm2014,
  author       = {Hohm, Andree and Lotz, Felix and Fochler, Oliver and L\"uke, Stefan and Winner, Hermann},
  title        = {Automated Driving in Real Traffic: from Current Technical Approaches towards Architectural Perspectives},
  journaltitle = {SAE Technical Papers},
  date         = {2014},
  volume       = {1},
  doi          = {10.4271/2014-01-0159},
  booktitle    = {{SAE} Technical Paper Series},
  file         = {:pdf-files/Hohm2014 - Automated Driving in Real Traffic_ from Current Technical Approaches Towards Architectural Perspectives.pdf:PDF},
  groups       = {Environment Model},
  owner        = {flo},
  publisher    = {{SAE} International},
  timestamp    = {2019.03.08},
}

@InProceedings{Huang2018,
  author    = {Huang, Xinyu and Cheng, Xinjing and Geng, Qichuan and Cao, Binbin and Zhou, Dingfu and Wang, Peng and Lin, Yuanqing and Yang, Ruigang},
  title     = {The ApolloScape Dataset for Autonomous Driving},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
  date      = {2018},
  pages     = {954--960},
  file      = {:pdf-files/Huang2018 - The ApolloScape Dataset for Autonomous Driving.pdf:PDF},
  groups    = {Datasets},
  owner     = {flo},
  timestamp = {2019.03.10},
}

@Article{Gordon1993,
  author       = {N. J. {Gordon} and D. J. {Salmond} and A. F. M. {Smith}},
  title        = {Novel approach to nonlinear/non-Gaussian Bayesian state estimation},
  journaltitle = {{IEE} Proceedings F Radar and Signal Processing},
  date         = {1993},
  volume       = {140},
  number       = {2},
  pages        = {107--113},
  issn         = {0956-375X},
  doi          = {10.1049/ip-f-2.1993.0015},
  abstract     = {An algorithm, the bootstrap filter, is proposed for implementing recursive Bayesian filters. The required density of the state vector is represented as a set of random samples, which are updated and propagated by the algorithm. The method is not restricted by assumptions of linearity or Gaussian noise: it may be applied to any state transition or measurement model. A simulation example of the bearings only tracking problem is presented. This simulation includes schemes for improving the efficiency of the basic algorithm. For this example, the performance of the bootstrap filter is greatly superior to the standard extended Kalman filter.<<ETX>>},
  comment      = {Particle filter reference},
  file         = {:pdf-files/Gordon1993 - Novel Approach to Nonlinear_non Gaussian Bayesian State Estimation.pdf:PDF},
  groups       = {Robotics},
  keywords     = {Bayes methods;filtering and prediction theory;Kalman filters;state estimation;tracking;State estimation;state transition model;state vector density;nonlinear Bayesian state estimation;nonGaussian Bayesian state estimation;algorithm;bootstrap filter;recursive Bayesian filters;random samples;Gaussian noise;measurement model;simulation;bearings only tracking problem;extended Kalman filter;Bayes procedures;Filtering;Kalman filtering;Tracking;Prediction methods},
  owner        = {flo},
  publisher    = {Institution of Engineering and Technology ({IET})},
  timestamp    = {2019.03.21},
}

@Article{Althoff_2011,
  author       = {Matthias Althoff and Alexander Mergel},
  title        = {Comparison of Markov Chain Abstraction and Monte Carlo Simulation for the Safety Assessment of Autonomous Cars},
  journaltitle = {IEEE Transactions on Intelligent Transportation Systems},
  date         = {2011},
  volume       = {12},
  number       = {4},
  pages        = {1237--1247},
  issn         = {1524-9050},
  doi          = {10.1109/TITS.2011.2157342},
  abstract     = {The probabilistic prediction of road traffic scenarios is addressed. One result is a probabilistic occupancy of traffic participants, and the other result is the collision risk for autonomous vehicles when executing a planned maneuver. The probabilistic occupancy of surrounding traffic participants helps to plan the maneuver of an autonomous vehicle, whereas the computed collision risk helps to decide if a planned maneuver should be executed. Two methods for the probabilistic prediction are presented and compared: 1) Markov chain abstraction and 2) Monte Carlo simulation. The performance of both methods is evaluated with respect to the prediction of the probabilistic occupancy and the collision risk. For each comparison test, we use the same models that generate the probabilistic behavior of traffic participants, where the generation of these data is not compared with real-world data. However, the results independently show the behavior generation that Markov chains are preferred for the probabilistic occupancy, whereas Monte Carlo simulation is clearly preferred for determining the collision risk.},
  file         = {:pdf-files/Althoff_2011 - Comparison of Markov Chain Abstraction and Monte Carlo Simulation for the Safety Assessment of Autonomous Cars.pdf:PDF},
  groups       = {Behaviour analysis},
  journal      = {{IEEE} Transactions on Intelligent Transportation Systems},
  keywords     = {automated highways;automobiles;collision avoidance;Markov processes;mobile robots;Monte Carlo methods;probability;road traffic;probabilistic prediction;road traffic;probabilistic occupancy;collision risk;autonomous vehicles;planned maneuver;Markov chain abstraction;Monte Carlo simulation;autonomous cars;Markov processes;Probabilistic logic;Computational modeling;Vehicle safety;Monte Carlo methods;Autonomous cars;behavior prediction;crash probability;Markov chains;Monte Carlo simulation;probabilistic occupancy;safety assessment;threat level},
  owner        = {flo},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  timestamp    = {2019.03.21},
}

@Article{Kalman1960,
  author       = {Kalman, R. E.},
  title        = {A New Approach to Linear Filtering and Prediction Problems},
  journaltitle = {Journal of Basic Engineering},
  date         = {1960},
  volume       = {82},
  number       = {1},
  pages        = {35--45},
  issn         = {0098-2202},
  doi          = {10.1115/1.3662552},
  abstract     = {The classical filtering and prediction problem is re-examined using the Bode-Shannon representation of random processes and the a" state-transition" method of analysis of dynamic systems. New results are: (1) The formulation and methods of solution of the problem apply without modification to stationary and nonstationary statistics and to growing-memory and infinite-memory filters. (2) A nonlinear difference (or differential) equation is derived for the covariance matrix of the optimal estimation error. From the solution of this equation the co-efficients of the difference (or differential) equation of the optimal linear filter are obtained without further calculations. (3) The filtering problem is shown to be the dual of the noise-free regulator problem. The new method developed here is applied to two well-known problems, confirming and extending earlier results. The discussion is largely self-contained and proceeds from first principles; basic concepts of the theory of random processes are reviewed in the Appendix.},
  comment      = {10.1115/1.3662552},
  file         = {:pdf-files/Kalman1960 - A New Approach to Linear Filtering and Prediction Problems.pdf:PDF},
  groups       = {Robotics},
  owner        = {flo},
  publisher    = {{ASME} International},
  timestamp    = {2019.03.21},
}

@InCollection{Neil2016,
  author    = {Neil, Daniel and Pfeiffer, Michael and Liu, Shih-Chii},
  title     = {Phased {LSTM}: Accelerating Recurrent Network Training for Long or Event-based Sequences},
  booktitle = {Advances in Neural Information Processing Systems 29},
  date      = {2016},
  editor    = {D. D. Lee and M. Sugiyama and U. V. Luxburg and I. Guyon and R. Garnett},
  publisher = {Curran Associates, Inc.},
  pages     = {3882--3890},
  url       = {http://papers.nips.cc/paper/6310-phased-lstm-accelerating-recurrent-network-training-for-long-or-event-based-sequences.pdf},
  file      = {:pdf-files/Neil2016 - Phased LSTM_ Accelerating Recurrent Network Training for Long or Event Based Sequences.pdf:PDF},
  groups    = {Neural Networks, Neuromorphic Computing},
  owner     = {flo},
  timestamp = {2019.03.26},
}

@Article{Damiani2009,
  author       = {Sergio Damiani and Enrica Deregibus and Luisa Andreone},
  title        = {Driver-vehicle interfaces and interaction: where are they going?},
  journaltitle = {European Transport Research Review},
  date         = {2009-05-01},
  volume       = {1},
  number       = {2},
  pages        = {87--96},
  issn         = {1866-8887},
  doi          = {10.1007/s12544-009-0009-2},
  abstract     = {The car was born around a century ago and its evolution has been incredibly fast, both in technology and in style. We have to move through different social and cultural evolutions to arrive to the present state of the art. The technical and social acceleration of the 20th century is well visible looking at the different worldwide research programs. Nowadays digital content and ubiquitous computing are changing us and our life style. New concepts involving the full society are emerging and the term ``personal mobility'' becomes more and more used together with ``co-operative driving'' and ``environmental compatibility''.},
  day          = {01},
  file         = {:pdf-files/Damiani2009 - Driver Vehicle Interfaces and Interaction_ Where Are They Going_.pdf:PDF},
  groups       = {Autonomous Driving},
  owner        = {flo},
  publisher    = {Springer Nature},
  timestamp    = {2019.03.27},
}

@InProceedings{Tian2010,
  author    = {X. {Tian} and Y. {Bar-Shalom}},
  title     = {On algorithms for asynchronous Track-to-Track Fusion},
  booktitle = {2010 13th International Conference on Information Fusion},
  date      = {2010},
  publisher = {{IEEE}},
  pages     = {1--8},
  doi       = {10.1109/ICIF.2010.5711956},
  abstract  = {This paper discusses three algorithms for the problem of asynchronous Track-to-Track Fusion (AT2TF) with track delays, where the information configuration of T2TF with partial information feedback (AT2TFpf) is used. This is the most practical configuration for AT2TF with time delays, since communication delays make full information feedback very complicated. The first algorithm is the optimal memoryless AT2TF under the Linear Gaussian (LG) assumption (denoted as AT2TFpfwoMopt), which is also the linear minimum mean square error (LMMSE) fuser without the Gaussian assumption. The second is the Information Matrix Fusion for asynchronous T2TF (denoted as AT2TFpfIMF), which is an extension of the synchronous IMF algorithm. Both algorithms are novel. The third is an approximate AT2TF algorithm proposed by Novoselsky (denoted as AT2TFpfAppr). Among the three algorithms, only the first one theoretically guarantees the consistency of the fuser. The latter two algorithms involve certain degrees of heuristics. Simulation results show that, for the scenarios considered, AT2TFpfIMF is also consistent and has similar level of tracking accuracy as AT2TFpfwoMopt. On the other hand, AT2TFpfAppr has consistency problems. Further more, due to the simplicity of AT2TFpfIMF compared to AT2TFpfwoMopt, it is an appealing candidate for practical applications.},
  file      = {:pdf-files/Tian2010 - On Algorithms for Asynchronous Track to Track Fusion.pdf:PDF},
  groups    = {Autonomous Driving},
  keywords  = {Gaussian processes;matrix algebra;mean square error methods;sensor fusion;target tracking;asynchronous track-to-track fusion;time delays;communication delays;linear Gaussian assumption;linear minimum mean square error fuser;optimal memoryless AT2TF;information matrix fusion;Target tracking;Approximation algorithms;Delay;Delay effects;Noise;Covariance matrix;Accuracy;Tracking;Asynchronous Track-to-Track fusion},
  owner     = {flo},
  timestamp = {2019.03.28},
}

@Article{Aeberhard2012,
  author       = {Michael Aeberhard and Stefan Schlichtharle and Nico Kaempchen and Torsten Bertram},
  title        = {Track-to-Track Fusion With Asynchronous Sensors Using Information Matrix Fusion for Surround Environment Perception},
  journaltitle = {{IEEE} Transactions on Intelligent Transportation Systems},
  date         = {2012},
  volume       = {13},
  number       = {4},
  pages        = {1717--1726},
  issn         = {1524-9050},
  doi          = {10.1109/TITS.2012.2202229},
  abstract     = {Driver-assistance systems and automated driving applications in the future will require reliable and flexible surround environment perception. Sensor data fusion is typically used to increase reliability and the observable field of view. In this paper, a novel approach to track-to-track fusion in a high-level sensor data fusion architecture for automotive surround environment perception using information matrix fusion (IMF) is presented. It is shown that IMF produces the same good accuracy in state estimation as a low-level centralized Kalman filter, which is widely known to be the most accurate method of fusion. Additionally, as opposed to state-of-the-art track-to-track fusion algorithms, the presented approach guarantees a globally maintained track over time as an object passes in and out of the field of view of several sensors, as required in surround environment perception. As opposed to the often-used cascaded Kalman filter for track-to-track fusion, it is shown that the IMF algorithm has a smaller error and maintains consistency in the state estimation. The proposed approach using IMF is compared with other track-to-track fusion algorithms in simulation and is shown to perform well using real sensor data in a prototype vehicle with a 12-sensor configuration for surround environment perception in highly automated driving applications.},
  file         = {:pdf-files/Aeberhard2012 - Track to Track Fusion with Asynchronous Sensors Using Information Matrix Fusion for Surround Environment Perception.pdf:PDF},
  groups       = {Autonomous Driving},
  keywords     = {driver information systems;Kalman filters;sensor fusion;state estimation;track-to-track fusion agorithm;asynchronous sensors;information matrix fusion;driver-assistance systems;automated driving applications;high-level sensor data fusion architecture;automotive surround environment perception;state estimation;low-level centralized Kalman filter;IMF algorithm;12-sensor configuration;Sensor fusion;Data integration;Algorithm design and analysis;Covariance matrix;Asynchronous sensors;driver-assistance systems;environment perception;information matrix fusion (IMF);multisensor fusion;track-to-track fusion},
  owner        = {flo},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  timestamp    = {2019.03.28},
}

@Article{Davis1993,
  author       = {Randall Davis and Randall Davis and Peter Szolovits},
  date         = {1993-03-15},
  journaltitle = {AI Magazine},
  title        = {What is Knowledge Representation?},
  doi          = {10.1609/aimag.v14i1.1029},
  number       = {1},
  pages        = {17--33},
  url          = {https://www.aaai.org/ojs/index.php/aimagazine/article/view/1029},
  volume       = {14},
  abstract     = {Although knowledge representation is one of the central and, in some ways, most familiar concepts in AI, the most fundamental question about it -- What is it? -- has rarely been answered directly. Numerous papers have lobbied for one or another variety of representation, other papers have argued for various properties a representation should have, and still others have focused on properties that are important to the notion of representation in general. In this article, we go back to basics to address the question directly. We believe that the answer can best be understood in terms of five important and distinctly different roles that a representation plays, each of which places different and, at times, conflicting demands on the properties a representation should have. We argue that keeping in mind all five of these roles provides a usefully broad perspective that sheds light on some longstanding disputes and can invigorate both research and practice in the field.},
  file         = {:pdf-files/Davis1993 - What Is Knowledge Representation_.pdf:PDF},
  groups       = {Machine Learning},
  journal      = {AI Magazine},
  owner        = {flo},
  timestamp    = {2019.03.29},
  year         = {1993},
}

@Article{Tenorth2010,
  author       = {Moritz Tenorth and Dominik Jain and Michael Beetz},
  title        = {{Knowledge Representation for Cognitive Robots}},
  journaltitle = {K{\"u}nstliche Intelligenz},
  date         = {2010},
  volume       = {24},
  number       = {3},
  pages        = {233--240},
  file         = {:pdf-files/Tenorth2010 - Knowledge Representation for Cognitive Robots.pdf:PDF},
  groups       = {Machine Learning},
  owner        = {flo},
  publisher    = {Springer},
  timestamp    = {2019.03.29},
}

@InProceedings{Vassev2012,
  author    = {E. {Vassev} and M. {Hinchey}},
  title     = {Knowledge Representation for Cognitive Robotic Systems},
  booktitle = {2012 {IEEE} 15th International Symposium on Object/Component/Service-Oriented Real-Time Distributed Computing Workshops},
  date      = {2012},
  publisher = {{IEEE}},
  pages     = {156--163},
  doi       = {10.1109/ISORCW.2012.36},
  abstract  = {Cognitive robotics are autonomous systems capable of artificial reasoning. Such systems can be achieved with a logical approach, but still AI struggles to connect the abstract logic with real-world meanings. Knowledge representation and reasoning help to resolve this problem and to establish the vital connection between knowledge, perception, and action of a robot. Cognitive robots must use their knowledge against the perception of their world and generate appropriate actions in that world in compliance with some goals and beliefs. This paper presents an approach to multi-tier knowledge representation for cognitive robots, where ontologies are integrated with rules and Bayesian networks. The approach allows for efficient and comprehensive knowledge structuring and awareness based on logical and statistical reasoning.},
  file      = {:pdf-files/Vassev2012 - Knowledge Representation for Cognitive Robotic Systems.pdf:PDF},
  groups    = {Machine Learning},
  keywords  = {belief networks;cognitive systems;inference mechanisms;intelligent robots;knowledge representation;statistical analysis;cognitive robotic systems;autonomous systems;artificial reasoning;abstract logic;logical approach;real-world meanings;multitier knowledge representation;Bayesian networks;comprehensive knowledge structuring;statistical reasoning;logical reasoning;Cognition;Ontologies;Cognitive robotics;Context;knowledge representation;reasoning;robotics},
  owner     = {flo},
  timestamp = {2019.03.29},
}

@InProceedings{Mirus2019c,
  author    = {Mirus, Florian and Stewart, Terrence C. and Eliasmith, Chris and Conradt, J{\"o}rg},
  booktitle = {Artificial Neural Networks and Machine Learning -- ICANN 2019: Image Processing},
  title     = {A Mixture-of-Experts Model for Vehicle Prediction Using an Online Learning Approach},
  doi       = {10.1007/978-3-030-30508-6_37},
  editor    = {Tetko, Igor V. and K{\r{u}}rkov{\'a}, V{\v{e}}ra and Karpov, Pavel and Theis, Fabian},
  isbn      = {978-3-030-30508-6},
  pages     = {456--471},
  publisher = {Springer International Publishing},
  series    = {Lecture Notes in Computer Science},
  volume    = {11729},
  abstract  = {Predicting future motion of other vehicles or, more generally, the development of traffic situations, is an essential step towards secure, context-aware automated driving. On the one hand, human drivers are able to anticipate driving situations continuously based on the currently perceived behavior of other traffic participants while incorporating prior experience. On the other hand, the most successful data-driven prediction models are typically trained on large amounts of recorded data before deployment achieving remarkable results. In this paper, we present a mixture-of-experts online learning model encapsulating both ideas. Our system learns at run time to choose between several models, which have been previously trained offline, based on the current situational context. We show that our model is able to improve over the offline models already after a short ramp-up phase. We evaluate our system on real world driving data.},
  owner     = {flo},
  timestamp = {2019.01.28},
  year      = {2019},
}

@InCollection{Schoener2008,
  author     = {Gregor Sch{\"o}ner},
  title      = {Dynamical Systems Approaches to Cognition},
  booktitle  = {The Cambridge Handbook of Computational Psychology},
  date       = {2008},
  editor     = {Ron Sun},
  series     = {Cambridge Handbooks in Psychology},
  publisher  = {Cambridge University Press},
  pages      = {101--126},
  doi        = {10.1017/CBO9780511816772.007},
  collection = {Cambridge Handbooks in Psychology},
  file       = {:pdf-files/Schoener2008 - Dynamical Systems Approaches to Cognition.pdf:PDF},
  groups     = {Neural Modelling, Dynamicism, Connectionism},
  owner      = {flo},
  place      = {Cambridge},
  timestamp  = {2019.04.01},
}

@Book{Fodor1975,
  author    = {Jerry A. Fodor},
  title     = {The Language of Thought},
  date      = {1975},
  series    = {Language and thought series},
  publisher = {Harvard University Press},
  isbn      = {9780674510302},
  groups    = {Neural Modelling, Symbolic approaches},
  lccn      = {75004843},
  owner     = {flo},
  timestamp = {2019.04.02},
}

@InCollection{Newell1976,
  author    = {Newell, Allen and Simon, H. A.},
  title     = {GPS: A Program That Simulates Human Thought},
  booktitle = {Computers and Thought},
  date      = {1976},
  editor    = {Feigenbaum, Edward A. and Feldman, Julian},
  publisher = {MIT Press},
  location  = {Cambridge, MA, USA},
  isbn      = {0-262-56092-5},
  pages     = {279--293},
  url       = {http://dl.acm.org/citation.cfm?id=216408.216432},
  acmid     = {216432},
  file      = {:pdf-files/Newell1976 - GPS_ a Program That Simulates Human Thought.pdf:PDF},
  groups    = {Neural Modelling},
  numpages  = {15},
  owner     = {flo},
  timestamp = {2019.04.02},
}

@Article{Anderson1996,
  author       = {John R. Anderson},
  title        = {{ACT}: A simple theory of complex cognition},
  journal      = {American Psychologist},
  journaltitle = {American Psychologist},
  date         = {1996},
  volume       = {51},
  number       = {4},
  pages        = {355--365},
  doi          = {10.1037/0003-066x.51.4.355},
  abstract     = {In the Adaptive Character of Thought (ACT-R) theory, complex cognition arises from an interaction of procedural and declarative knowledge. Procedural knowledge is represented in units called production rules, and declarative knowledge is represented in units called chunks. The individual units are created by simple encodings of objects in the environment (chunks) or simple encodings of transformations in the environment (production rules). A great many such knowledge units underlie human cognition. From this large database, the appropriate units are selected for a particular context by activation processes that are tuned to the statistical structure of the environment. According to the ACT-R theory, the power of human cognition depends on the amount of knowledge encoded and the effective deployment of the encoded knowledge. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file         = {:pdf-files/Anderson1996 - ACT_ a Simple Theory of Complex Cognition.pdf:PDF},
  groups       = {Neural Modelling, Symbolic approaches},
  keywords     = {*Cognitive Processes, *Human Information Storage, Theory Formulation},
  location     = {US},
  owner        = {flo},
  publisher    = {American Psychological Association ({APA})},
  refid        = {1996-04055-022},
  timestamp    = {2019.04.02},
}

@Book{Rumelhart1986a,
  title     = {Parallel Distributed Processing: Explorations in the Microstructure of Cognition, Vol. 1: Foundations},
  date      = {1986},
  editor    = {Rumelhart, David E. and McClelland, James L.},
  publisher = {MIT Press},
  location  = {Cambridge, MA, USA},
  isbn      = {0-262-68053-X},
  groups    = {Neural Modelling},
  owner     = {flo},
  source    = {softcover, \$21.95},
  timestamp = {2019.04.02},
}

@Book{Minsky1986,
  author    = {Marvin Minsky},
  title     = {The Society of Mind},
  date      = {1986},
  publisher = {Simon and Schuster, Inc.},
  location  = {New York, NY, USA},
  isbn      = {0-671-60740-5},
  file      = {:pdf-files/Minsky1986 - The Society of Mind.pdf:PDF},
  groups    = {Neural Modelling, Connectionism},
  owner     = {flo},
  timestamp = {2019.04.02},
}

@Article{Kieras1997,
  author       = {Davis E. Kieras and Davis E. Meyer},
  title        = {An Overview of the {EPIC} Architecture for Cognition and Performance With Application to Human-Computer Interaction},
  journaltitle = {Human-Computer Interaction},
  date         = {1997},
  volume       = {12},
  number       = {4},
  pages        = {391--438},
  issn         = {0737-0024},
  doi          = {10.1207/s15327051hci1204_4},
  acmid        = {1462983},
  file         = {:pdf-files/Kieras1997 - An Overview of the EPIC Architecture for Cognition and Performance with Application to Human Computer Interaction.pdf:PDF},
  groups       = {Neural Modelling, Symbolic approaches},
  issue_date   = {December 1997},
  location     = {Hillsdale, NJ, USA},
  numpages     = {48},
  owner        = {flo},
  publisher    = {L. Erlbaum Associates Inc.},
  timestamp    = {2019.04.02},
}

@Article{Laird1987,
  author       = {John E. Laird and Allen Newell and Paul S. Rosenbloom},
  title        = {SOAR: An architecture for general intelligence},
  journaltitle = {Artificial Intelligence},
  date         = {1987},
  volume       = {33},
  number       = {1},
  pages        = {1--64},
  issn         = {0004-3702},
  doi          = {10.1016/0004-3702(87)90050-6},
  url          = {http://www.sciencedirect.com/science/article/pii/0004370287900506},
  abstract     = {The ultimate goal of work in cognitive architecture is to provide the foundation for a system capable of general intelligent behavior. That is, the goal is to provide the underlying structure that would enable a system to perform the full range of cognitive tasks, employ the full range of problem solving methods and representations appropriate for the tasks, and learn about all aspects of the tasks and its performance on them. In this article we present SOAR, an implemented proposal for such an architecture. We describe its organizational principles, the system as currently implemented, and demonstrations of its capabilities.},
  file         = {:pdf-files/Laird1987 - SOAR_ an Architecture for General Intelligence.pdf:PDF},
  groups       = {Neural Modelling, Symbolic approaches},
  owner        = {flo},
  publisher    = {Elsevier {BV}},
  timestamp    = {2019.04.02},
}

@Article{Anderson1983,
  author       = {John R. Anderson},
  title        = {A spreading activation theory of memory},
  journaltitle = {Journal of Verbal Learning and Verbal Behavior},
  date         = {1983},
  volume       = {22},
  number       = {3},
  pages        = {261--295},
  issn         = {0022-5371},
  doi          = {10.1016/s0022-5371(83)90201-3},
  abstract     = {According to the activation theory (ACT) of memory, information is encoded in an all-or-none manner into cognitive units, and the strength of these units increases with practice and decays with delay. The essential process to memory performance is the retrieval operation. It is proposed that the cognitive units form an interconnected network and that retrieval is performed by spreading activation throughout the network. Level of activation in the network determines rate and probability of recall. With these assumptions in place, the author's (1976) ACT theory is shown to predict interference results in memory, judgments of associative relatedness, impact of extensive practice on memory, the differences between recognition and recall, effects of elaborative processing, and effects of reconstructive recall. (101 ref) (PsycINFO Database Record (c) 2017 APA, all rights reserved)},
  file         = {:pdf-files/Anderson1983 - A Spreading Activation Theory of Memory.pdf:PDF},
  groups       = {Neural Modelling, Symbolic approaches},
  keywords     = {*Memory, Theory Formulation},
  location     = {Netherlands},
  owner        = {flo},
  publisher    = {Elsevier Science},
  timestamp    = {2019.04.02},
}

@Online{Webber2016,
  author    = {Francisco E. De Sousa Webber},
  title     = {Semantic Folding},
  date      = {2016},
  url       = {http://www.cortical.io/static/downloads/semantic-folding-theory-white-paper.pdf},
  urldate   = {2019-04-03},
  file      = {:pdf-files/Webber2016 - Semantic Folding.pdf:PDF},
  groups    = {Numenta etc},
  owner     = {flo},
  timestamp = {2019.04.03},
}

@Article{Ahmad2015,
  author        = {Subutai Ahmad and Jeff Hawkins},
  title         = {{Properties of Sparse Distributed Representations and their Application to Hierarchical Temporal Memory}},
  journaltitle  = {arXiv e-prints},
  year          = {2015},
  date          = {2015-03-25},
  eid           = {arXiv:1503.07469},
  pages         = {arXiv:1503.07469},
  eprint        = {http://arxiv.org/abs/1503.07469v1},
  eprintclass   = {q-bio.NC},
  eprinttype    = {arXiv},
  abstract      = {Empirical evidence demonstrates that every region of the neocortex represents information using sparse activity patterns. This paper examines Sparse Distributed Representations (SDRs), the primary information representation strategy in Hierarchical Temporal Memory (HTM) systems and the neocortex. We derive a number of properties that are core to scaling, robustness, and generalization. We use the theory to provide practical guidelines and illustrate the power of SDRs as the basis of HTM. Our goal is to help create a unified mathematical and practical framework for SDRs as it relates to cortical function.},
  archiveprefix = {arXiv},
  file          = {:pdf-files/Subutai2015 - Properties of Sparse Distributed Representations and Their Application to Hierarchical Temporal Memory.pdf:PDF},
  groups        = {Numenta etc},
  keywords      = {Quantitative Biology - Neurons and Cognition, Computer Science - Artificial Intelligence},
  owner         = {flo},
  timestamp     = {2019.04.03},
}

@Article{Ahmad2019,
  author        = {Subutai Ahmad and Luiz Scheinkman},
  title         = {{How Can We Be So Dense? The Benefits of Using Highly Sparse Representations}},
  journaltitle  = {arXiv e-prints},
  year          = {2019},
  date          = {2019-03-27},
  eid           = {arXiv:1903.11257},
  pages         = {arXiv:1903.11257},
  eprint        = {http://arxiv.org/abs/1903.11257v2},
  eprintclass   = {cs.LG},
  eprinttype    = {arXiv},
  abstract      = {Most artificial networks today rely on dense representations, whereas biological networks rely on sparse representations. In this paper we show how sparse representations can be more robust to noise and interference, as long as the underlying dimensionality is sufficiently high. A key intuition that we develop is that the ratio of the operable volume around a sparse vector divided by the volume of the representational space decreases exponentially with dimensionality. We then analyze computationally efficient sparse networks containing both sparse weights and activations. Simulations on MNIST and the Google Speech Command Dataset show that such networks demonstrate significantly improved robustness and stability compared to dense networks, while maintaining competitive accuracy. We discuss the potential benefits of sparsity on accuracy, noise robustness, hyperparameter tuning, learning speed, computational efficiency, and power requirements.},
  archiveprefix = {arXiv},
  file          = {:pdf-files/Subutai2019 - How Can We Be so Dense_ the Benefits of Using Highly Sparse Representations.pdf:PDF},
  groups        = {Numenta etc},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning},
  owner         = {flo},
  primaryclass  = {cs.LG},
  timestamp     = {2019.04.03},
}

@Article{Cui2017,
  author       = {Yuwei Cui and Subutai Ahmad and Jeff Hawkins},
  title        = {The {HTM} Spatial Pooler - A Neocortical Algorithm for Online Sparse Distributed Coding},
  journaltitle = {Frontiers in Computational Neuroscience},
  date         = {2017},
  volume       = {11},
  pages        = {111},
  issn         = {1662-5188},
  doi          = {10.3389/fncom.2017.00111},
  abstract     = {Hierarchical temporal memory (HTM) provides a theoretical framework that models several key computational principles of the neocortex. In this paper we analyze an important component of HTM, the HTM spatial pooler (SP). The SP models how neurons learn feedforward connections and form efficient representations of the input. It converts arbitrary binary input patterns into sparse distributed representations (SDRs) using a combination of competitive Hebbian learning rules and homeostatic excitability control. We describe a number of key properties of the spatial pooler, including fast adaptation to changing input statistics, improved noise robustness through learning, efficient use of cells and robustness to cell death. In order to quantify these properties we develop a set of metrics that can be directly computed from the spatial pooler outputs. We show how the properties are met using these metrics and targeted artificial simulations. We then demonstrate the value of the spatial pooler in a complete end-to-end real-world HTM system. We discuss the relationship with neuroscience and previous studies of sparse coding. The HTM spatial pooler represents a neurally inspired algorithm for learning sparse representations from noisy data streams in an online fashion.},
  file         = {:pdf-files/Cui2017 - The HTM Spatial Pooler a Neocortical Algorithm for Online Sparse Distributed Coding.pdf:PDF},
  groups       = {Numenta etc},
  owner        = {flo},
  publisher    = {Frontiers Media {SA}},
  timestamp    = {2019.04.03},
}

@Article{Ahmad2017,
  author       = {Subutai Ahmad and Alexander Lavin and Scott Purdy and Zuha Agha},
  title        = {Unsupervised real-time anomaly detection for streaming data},
  journaltitle = {Neurocomputing},
  date         = {2017},
  volume       = {262},
  pages        = {134--147},
  note         = {Online Real-Time Learning Strategies for Data Streams},
  issn         = {0925-2312},
  doi          = {10.1016/j.neucom.2017.04.070},
  url          = {http://www.sciencedirect.com/science/article/pii/S0925231217309864},
  abstract     = {We are seeing an enormous increase in the availability of streaming, time-series data. Largely driven by the rise of connected real-time data sources, this data presents technical challenges and opportunities. One fundamental capability for streaming analytics is to model each stream in an unsupervised fashion and detect unusual, anomalous behaviors in real-time. Early anomaly detection is valuable, yet it can be difficult to execute reliably in practice. Application constraints require systems to process data in real-time, not batches. Streaming data inherently exhibits concept drift, favoring algorithms that learn continuously. Furthermore, the massive number of independent streams in practice requires that anomaly detectors be fully automated. In this paper we propose a novel anomaly detection algorithm that meets these constraints. The technique is based on an online sequence memory algorithm called Hierarchical Temporal Memory (HTM). We also present results using the Numenta Anomaly Benchmark (NAB), a benchmark containing real-world data streams with labeled anomalies. The benchmark, the first of its kind, provides a controlled open-source environment for testing anomaly detection algorithms on streaming data. We present results and analysis for a wide range of algorithms on this benchmark, and discuss future challenges for the emerging field of streaming analytics.},
  file         = {:pdf-files/Ahmad2017 - Unsupervised Real Time Anomaly Detection for Streaming Data.pdf:PDF},
  groups       = {Numenta etc},
  keywords     = {Anomaly detection, Hierarchical Temporal Memory, Streaming data, Unsupervised learning, Concept drift, Benchmark dataset},
  owner        = {flo},
  publisher    = {Elsevier {BV}},
  timestamp    = {2019.04.03},
}

@InProceedings{Hallac2018,
  author    = {David Hallac and Suvrat Bhooshan and Michael Chen and Kacem Abida and Rok Sosic and Jure Leskovec},
  title     = {Drive2Vec: Multiscale State-Space Embedding of Vehicular Sensor Data},
  booktitle = {21st International Conference on Intelligent Transportation Systems ({ITSC})},
  year      = {2018},
  publisher = {{IEEE}},
  pages     = {3233--3238},
  doi       = {10.1109/ITSC.2018.8569550},
  file      = {:pdf-files/Hallac2018 - Drive2Vec_ Multiscale State Space Embedding of Vehicular Sensor Data.pdf:PDF},
  groups    = {Word Embedding},
  keywords  = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Statistics - Machine Learning},
  owner     = {flo},
  timestamp = {2019.03.07},
}

@Online{Numenta,
  author    = {Numenta},
  title     = {Numenta webpage},
  url       = {https://numenta.com/},
  urldate   = {2019-04-03},
  groups    = {Numenta etc},
  owner     = {flo},
  timestamp = {2019.04.03},
}

@Online{Cortialio,
  author    = {Cortical.io},
  title     = {Cortical.io webpage},
  url       = {https://www.cortical.io/},
  urldate   = {2019-04-03},
  groups    = {Numenta etc},
  owner     = {flo},
  timestamp = {2019.04.03},
}

@InProceedings{Dagostino2013,
  author    = {Claire D{\textquotesingle}Agostino and Alexandre Saidi and Gilles Scouarnec and Liming Chen},
  title     = {Learning-based driving events classification},
  booktitle = {16th International IEEE Conference on Intelligent Transportation Systems (ITSC 2013)},
  date      = {2013},
  publisher = {{IEEE}},
  pages     = {1778--1783},
  doi       = {10.1109/ITSC.2013.6728486},
  abstract  = {Drivers typically depict different behavior with respect to various driving events. The modeling of their behavior enables an accurate estimation of fuel consumption during the truck design process and is also helpful for ADAS in order to give relevant advices. In this paper, we propose a learning-based approach to the automatic recognition of driving events, e.g., roundabouts or stops, which impact the driver behavior. We first synthesize and categorize meaningful driving events and then study a set of features potentially sensitive to the driver behavior. These features were experimented on real truck driver data using two machine-learning techniques, i.e., decision tree and linear logic regression, to evaluate their relevance and ability to recognize driving events.},
  groups    = {Situation/Context analysis},
  issn      = {2153-0009},
  keywords  = {decision trees;design;driver information systems;formal logic;learning (artificial intelligence);regression analysis;learning-based driving events classification;fuel consumption;truck design process;ADAS;machine learning;decision tree;linear logic regression;Vehicles;Roads;Acceleration;Logistics;Decision trees;Fuels;Context},
  owner     = {flo},
  timestamp = {2019.04.03},
}

@InProceedings{Sermanet2011,
  author    = {Pierre Sermanet and Yann LeCun},
  title     = {Traffic sign recognition with multi-scale Convolutional Networks},
  booktitle = {The 2011 International Joint Conference on Neural Networks},
  date      = {2011},
  publisher = {{IEEE}},
  pages     = {2809--2813},
  doi       = {10.1109/IJCNN.2011.6033589},
  file      = {:pdf-files/Sermanet2011 - Traffic Sign Recognition with Multi Scale Convolutional Networks.pdf:PDF},
  groups    = {Object Recognition},
  issn      = {2161-4407},
  owner     = {flo},
  timestamp = {2019.04.04},
}

@InProceedings{Long2015,
  author    = {Jonathan Long and Evan Shelhamer and Trevor Darrell},
  title     = {Fully convolutional networks for semantic segmentation},
  booktitle = {2015 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
  date      = {2015},
  publisher = {{IEEE}},
  pages     = {3431--3440},
  doi       = {10.1109/CVPR.2015.7298965},
  file      = {:pdf-files/Long2015 - Fully Convolutional Networks for Semantic Segmentation.pdf:PDF},
  groups    = {Object Recognition},
  issn      = {1063-6919},
  keywords  = {image classification;image segmentation;inference mechanisms;learning (artificial intelligence);fully convolutional networks;semantic segmentation;visual models;pixels-to-pixels;inference;learning;contemporary classification networks;PASCAL VOC;NYUDv2;SIFT flow;Semantics;Training;Convolution;Image segmentation;Computer architecture;Deconvolution;Adaptation models},
  owner     = {flo},
  timestamp = {2019.04.04},
}

@Article{Chen2018b,
  author       = {L. {Chen} and G. {Papandreou} and I. {Kokkinos} and K. {Murphy} and A. L. {Yuille}},
  title        = {{DeepLab}: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected {CRFs}},
  journal      = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year         = {2018},
  date         = {2018},
  volume       = {40},
  number       = {4},
  pages        = {834--848},
  issn         = {0162-8828},
  doi          = {10.1109/TPAMI.2017.2699184},
  abstract     = {In this work we address the task of semantic image segmentation with Deep Learning and make three main contributions that are experimentally shown to have substantial practical merit. First, we highlight convolution with upsampled filters, or `atrous convolution', as a powerful tool in dense prediction tasks. Atrous convolution allows us to explicitly control the resolution at which feature responses are computed within Deep Convolutional Neural Networks. It also allows us to effectively enlarge the field of view of filters to incorporate larger context without increasing the number of parameters or the amount of computation. Second, we propose atrous spatial pyramid pooling (ASPP) to robustly segment objects at multiple scales. ASPP probes an incoming convolutional feature layer with filters at multiple sampling rates and effective fields-of-views, thus capturing objects as well as image context at multiple scales. Third, we improve the localization of object boundaries by combining methods from DCNNs and probabilistic graphical models. The commonly deployed combination of max-pooling and downsampling in DCNNs achieves invariance but has a toll on localization accuracy. We overcome this by combining the responses at the final DCNN layer with a fully connected Conditional Random Field (CRF), which is shown both qualitatively and quantitatively to improve localization performance. Our proposed “DeepLab” system sets the new state-of-art at the PASCAL VOC-2012 semantic image segmentation task, reaching 79.7 percent mIOU in the test set, and advances the results on three other datasets: PASCAL-Context, PASCAL-Person-Part, and Cityscapes. All of our code is made publicly available online.},
  file         = {:pdf-files/Chen2018 - DeepLab_ Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs.pdf:PDF},
  groups       = {Deep Neural Networks},
  keywords     = {convolution;feature extraction;feedforward neural nets;image segmentation;learning (artificial intelligence);random processes;highlight convolution;atrous convolution;Deep Convolutional Neural Networks;atrous spatial pyramid pooling;image context;fully connected Conditional Random Field;PASCAL VOC-2012 semantic image segmentation task;deep convolutional nets;Deep Learning;DeepLab;semantic image segmentation;probabilistic graphical models;Convolution;Image segmentation;Semantics;Image resolution;Computational modeling;Neural networks;Context;Convolutional neural networks;semantic segmentation;atrous convolution;conditional random fields},
  owner        = {flo},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  timestamp    = {2019.04.04},
}

@Article{Li2017,
  author       = {Xiaofei Li and Lingxi Li and Fabian Flohr and Jianqiang Wang and Hui Xiong and Morys Bernhard and Shuyue Pan and Dariu M. Gavrila and Keqiang Li},
  title        = {A Unified Framework for Concurrent Pedestrian and Cyclist Detection},
  journaltitle = {{IEEE} Transactions on Intelligent Transportation Systems},
  date         = {2017},
  volume       = {18},
  number       = {2},
  pages        = {269--281},
  issn         = {1524-9050},
  doi          = {10.1109/TITS.2016.2567418},
  abstract     = {Extensive research interest has been focused on protecting vulnerable road users in recent years, particularly pedestrians and cyclists, due to their attributes of vulnerability. However, comparatively little effort has been spent on detecting pedestrian and cyclist together, particularly when it concerns quantitative performance analysis on large datasets. In this paper, we present a unified framework for concurrent pedestrian and cyclist detection, which includes a novel detection proposal method (termed UB-MPR) to output a set of object candidates, a discriminative deep model based on Fast R-CNN for classification and localization, and a specific postprocessing step to further improve detection performance. Experiments are performed on a new pedestrian and cyclist dataset containing 30 490 annotated pedestrian and 26 771 cyclist instances in over 50 000 images, recorded from a moving vehicle in the urban traffic of Beijing. Experimental results indicate that the proposed method outperforms other state-of-the-art methods significantly.},
  file         = {:pdf-files/Li2017 - A Unified Framework for Concurrent Pedestrian and Cyclist Detection.pdf:PDF},
  groups       = {Object Recognition},
  keywords     = {driver information systems;least squares approximations;object detection;pedestrians;road safety;concurrent pedestrian detection;cyclist detection;vulnerable road user protection;quantitative performance analysis;UB-MPR;fast R-CNN;urban traffic;Beijing;Proposals;Detectors;Feature extraction;Vehicles;Benchmark testing;Roads;Multiple potential regions;pedestrian and cyclist detection;R-CNN;upper body detection},
  owner        = {flo},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  timestamp    = {2019.04.04},
}

@Article{Chandola2009,
  author       = {Varun Chandola and Arindam Banerjee and Vipin Kumar},
  title        = {Anomaly Detection: A Survey},
  journaltitle = {{ACM} Computing Surveys},
  date         = {2009},
  volume       = {41},
  number       = {3},
  pages        = {1--58},
  issn         = {0360-0300},
  doi          = {10.1145/1541880.1541882},
  articleno    = {15},
  file         = {:pdf-files/Chandola2009 - Anomaly Detection_ a Survey.pdf:PDF},
  groups       = {Anomaly detection},
  issue_date   = {July 2009},
  keywords     = {Anomaly detection, outlier detection},
  location     = {New York, NY, USA},
  numpages     = {58},
  owner        = {flo},
  publisher    = {Association for Computing Machinery ({ACM})},
  timestamp    = {2019.04.05},
}

@Article{Hodge2004,
  author       = {Victoria Hodge and Jim Austin},
  title        = {A Survey of Outlier Detection Methodologies},
  journaltitle = {Artificial Intelligence Review},
  date         = {2004-10-01},
  volume       = {22},
  number       = {2},
  pages        = {85--126},
  issn         = {1573-7462},
  doi          = {10.1023/b:aire.0000045502.10941.a9},
  abstract     = {Outlier detection has been used for centuries to detect and, where appropriate, remove anomalous observations from data. Outliers arise due to mechanical faults, changes in system behaviour, fraudulent behaviour, human error, instrument error or simply through natural deviations in populations. Their detection can identify system faults and fraud before they escalate with potentially catastrophic consequences. It can identify errors and remove their contaminating effect on the data set and as such to purify the data for processing. The original outlier detection methods were arbitrary but now, principled and systematic techniques are used, drawn from the full gamut of Computer Science and Statistics. In this paper, we introduce a survey of contemporary techniques for outlier detection. We identify their respective motivations and distinguish their advantages and disadvantages in a comparative review.},
  day          = {01},
  file         = {:pdf-files/Hodge2004 - A Survey of Outlier Detection Methodologies.pdf:PDF},
  groups       = {Anomaly detection},
  owner        = {flo},
  publisher    = {Springer Nature},
  timestamp    = {2019.04.05},
}

@Article{Zhao2019,
  author       = {Zhao, Yue and Nasrullah, Zain and Li, Zheng},
  title        = {{PyOD}: A Python Toolbox for Scalable Outlier Detection},
  journaltitle = {ArXiv e-prints},
  date         = {2019},
  url          = {https://arxiv.org/abs/1901.01588},
  comment      = {Code is here: https://github.com/yzhao062/Pyod},
  file         = {:pdf-files/Zhao2019 - PyOD_ a Python Toolbox for Scalable Outlier Detection.pdf:PDF},
  groups       = {Anomaly detection},
  owner        = {flo},
  timestamp    = {2019.04.05},
}

@InProceedings{Lundgren2014,
  author    = {Malin Lundgren and Erik Stenborg and Lennart Svensson and Lars Hammarstrand},
  title     = {Vehicle self-localization using off-the-shelf sensors and a detailed map},
  booktitle = {2014 {IEEE} Intelligent Vehicles Symposium Proceedings},
  year      = {2014},
  publisher = {{IEEE}},
  pages     = {522--528},
  doi       = {10.1109/IVS.2014.6856524},
  abstract  = {In the research on autonomous vehicles, self-localization is an important problem to solve. In this paper we present a localization algorithm based on a map and a set of off-the-shelf sensors, with the purpose of evaluating this low-cost solution with respect to localization performance. The used test vehicle is equipped with a Global Positioning System receiver, a gyroscope, wheel speed sensors, a camera providing information about lane markings, and a radar detecting landmarks along the road. Evaluation shows that the localization result is within or close to the requirements for autonomous driving when lane markers and good radar landmarks are present. However, it also indicates that the solution is not robust enough to handle situations when one of these information sources is absent.},
  file      = {:pdf-files/70607840.pdf:PDF},
  groups    = {Autonomous Driving, Localization},
  issn      = {1931-0587},
  keywords  = {automobiles;Global Positioning System;mobile robots;position control;sensors;vehicle self-localization;off-the-shelf sensors;localization algorithm;global positioning system receiver;gyroscope;wheel speed sensors;autonomous vehicles;Sensors;Vehicles;Roads;Cameras;Radar;Noise measurement;Global Positioning System},
  owner     = {flo},
  timestamp = {2019.04.08},
}

@Article{Pedregosa2011,
  author       = {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V. and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P. and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  title        = {Scikit-learn: Machine Learning in {P}ython},
  journaltitle = {Journal of Machine Learning Research},
  date         = {2011},
  volume       = {12},
  pages        = {2825--2830},
  comment      = {reference for the scikit-Learn python library},
  file         = {:pdf-files/Pedregosa2011 - Scikit Learn_ Machine Learning in Python.pdf:PDF},
  groups       = {Machine Learning},
  owner        = {flo},
  timestamp    = {2019.04.08},
}

@Article{Chen2019,
  author       = {Guang Chen and Hu Cao and Canbo Ye and Zhenyan Zhang and Xingbo Liu and Xuhui Mo and Zhongnan Qu and J{\"o}rg Conradt and Florian R{\"o}hrbein and Alois Knoll},
  title        = {Multi-Cue Event Information Fusion for Pedestrian Detection With Neuromorphic Vision Sensors},
  journaltitle = {Frontiers in Neurorobotics},
  date         = {2019},
  volume       = {13},
  pages        = {10},
  issn         = {1662-5218},
  doi          = {10.3389/fnbot.2019.00010},
  abstract     = {Neuromorphic vision sensors are bio-inspired cameras that naturally capture the dynamics of a scene with unlit-low latency, filtering out redundant information with low power consumption. Few works are addressing the object detection with this sensor. In this work, we propose to develop pedestrian detectors that unlock the potential of the event data by leveraging multi-cue information and different fusion strategies. To make the best out of the event data, we introduce three different event-stream encoding methods based on Frequency, Surface of Active Event (SAE) and Leaky Integrate-and-Fire (LIF). We further integrate them into the state-of-the-art neural network architectures with two fusion approaches: the channel-level fusion of the raw feature space and decision-level fusion with the probability assignments. We present a qualitative and quantitative explanation why different encoding methods are chosen to evaluate the pedestrian detection and which method performs the best. We demonstrate the advantages of the decision-level fusion via leveraging multi-cue event information and show that our approach performs well on a self-annotated event-based pedestrian dataset with 8736 event frames.},
  file         = {:pdf-files/Chen2019 - Multi Cue Event Information Fusion for Pedestrian Detection with Neuromorphic Vision Sensors.pdf:PDF},
  groups       = {Neuromorphic Vision},
  owner        = {flo},
  publisher    = {Frontiers Media {SA}},
  timestamp    = {2019.04.12},
}

@Book{Aggarwal2013,
  author    = {Charu C. Aggarwal},
  title     = {Outlier Analysis},
  date      = {2013},
  publisher = {Springer New York},
  doi       = {10.1007/978-1-4614-6396-2},
  groups    = {Anomaly detection},
  owner     = {flo},
  timestamp = {2019.04.15},
}

@InProceedings{Kriegel2008,
  author    = {Hans-Peter Kriegel and Matthias Schubert and Arthur Zimek},
  title     = {Angle-based Outlier Detection in High-dimensional Data},
  booktitle = {Proceeding of the 14th {ACM} {SIGKDD} international conference on Knowledge discovery and data mining - {KDD} 08},
  date      = {2008},
  series    = {KDD '08},
  publisher = {{ACM} Press},
  location  = {Las Vegas, Nevada, USA},
  isbn      = {978-1-60558-193-4},
  pages     = {444--452},
  doi       = {10.1145/1401890.1401946},
  acmid     = {1401946},
  address   = {New York, NY, USA},
  file      = {:pdf-files/Kriegel2008 - Angle Based Outlier Detection in High Dimensional Data.pdf:PDF},
  groups    = {Anomaly detection},
  keywords  = {angle-based, high-dimensional, outlier detection},
  numpages  = {9},
  owner     = {flo},
  timestamp = {2019.04.15},
}

@Article{Liu2018,
  author       = {Yezheng Liu and Zhe Li and Chong Zhou and Yuanchun Jiang and Jianshan Sun and Meng Wang and Xiangnan He},
  title        = {Generative Adversarial Active Learning for Unsupervised Outlier Detection},
  journaltitle = {CoRR},
  date         = {2018},
  volume       = {abs/1809.10816},
  eprint       = {1809.10816},
  eprinttype   = {arXiv},
  url          = {http://arxiv.org/abs/1809.10816},
  file         = {:pdf-files/Liu2018 - Generative Adversarial Active Learning for Unsupervised Outlier Detection.pdf:PDF},
  groups       = {Anomaly detection},
  owner        = {flo},
  timestamp    = {2019.04.15},
}

@Article{Gallego2019,
  author        = {Guillermo Gallego and Tobi Delbr{\"{u}}ck and Garrick Orchard and Chiara Bartolozzi and Brian Taba and Andrea Censi and Stefan Leutenegger and Andrew J. Davison and J{\"{o}}rg Conradt and Kostas Daniilidis and Davide Scaramuzza},
  title         = {Event-based Vision: {A} Survey},
  journaltitle  = {CoRR},
  year          = {2019},
  date          = {2019-04-17},
  volume        = {abs/1904.08405},
  eprint        = {http://arxiv.org/abs/1904.08405v1},
  eprintclass   = {cs.CV},
  eprinttype    = {arXiv},
  url           = {http://arxiv.org/abs/1904.08405},
  abstract      = {Event cameras are bio-inspired sensors that work radically different from traditional cameras. Instead of capturing images at a fixed rate, they measure per-pixel brightness changes asynchronously. This results in a stream of events, which encode the time, location and sign of the brightness changes. Event cameras posses outstanding properties compared to traditional cameras: very high dynamic range (140 dB vs. 60 dB), high temporal resolution (in the order of microseconds), low power consumption, and do not suffer from motion blur. Hence, event cameras have a large potential for robotics and computer vision in challenging scenarios for traditional cameras, such as high speed and high dynamic range. However, novel methods are required to process the unconventional output of these sensors in order to unlock their potential. This paper provides a comprehensive overview of the emerging field of event-based vision, with a focus on the applications and the algorithms developed to unlock the outstanding properties of event cameras. We present event cameras from their working principle, the actual sensors that are available and the tasks that they have been used for, from low-level vision (feature detection and tracking, optic flow, etc.) to high-level vision (reconstruction, segmentation, recognition). We also discuss the techniques developed to process events, including learning-based techniques, as well as specialized processors for these novel sensors, such as spiking neural networks. Additionally, we highlight the challenges that remain to be tackled and the opportunities that lie ahead in the search for a more efficient, bio-inspired way for machines to perceive and interact with the world.},
  archiveprefix = {arXiv},
  file          = {:pdf-files/Gallego2019 - Event Based Vision_ a Survey.pdf:PDF},
  groups        = {Neuromorphic Vision},
  keywords      = {cs.CV, cs.AI, cs.LG, cs.RO},
  owner         = {flo},
  timestamp     = {2019.05.03},
}

@Article{Losing2018,
  author       = {Viktor Losing and Barbara Hammer and Heiko Wersing},
  title        = {Incremental on-line learning: A review and comparison of state of the art algorithms},
  journal      = {Neurocomputing},
  journaltitle = {Neurocomputing},
  date         = {2018},
  volume       = {275},
  pages        = {1261--1274},
  doi          = {10.1016/j.neucom.2017.06.084},
  file         = {:pdf-files/Losing2018 - Incremental on Line Learning_ a Review and Comparison of State of the Art Algorithms.pdf:PDF},
  groups       = {Online learning},
  owner        = {flo},
  publisher    = {Elsevier {BV}},
  timestamp    = {2019.05.23},
}

@InProceedings{Losing2017,
  author    = {Viktor Losing and Barbara Hammer and Heiko Wersing},
  title     = {Personalized maneuver prediction at intersections},
  booktitle = {2017 {IEEE} 20th International Conference on Intelligent Transportation Systems ({ITSC})},
  date      = {2017},
  publisher = {{IEEE}},
  pages     = {1--6},
  doi       = {10.1109/ITSC.2017.8317760},
  abstract  = {We investigate a new approach towards maneuver prediction that is based on personalization and incremental learning. The prediction accuracy is continuously improved by incorporating only the individual driving history. The study is based on a collection of commuting drivers who recorded their daily routes with a standard smart phone and GPS receiver. Prediction target is the expected maneuver on the next intersection with three classes: stop, turn, or go straight. We show that a personalized prediction based on at least one experience of a certain intersection already improves the prediction performance over an average prediction model trained on all test driver commute routes. This performance gain increases further with more personal training data.},
  file      = {:pdf-files/Losing2017 - Personalized Maneuver Prediction at Intersections.pdf:PDF},
  groups    = {Online learning},
  issn      = {2153-0017},
  keywords  = {driver information systems;Global Positioning System;learning (artificial intelligence);smart phones;individual driving history;stop class;turn class;go straight class;personal training data;test driver commute routes;average prediction model;personalized prediction;expected maneuver;prediction target;GPS receiver;standard smart phone;daily routes;prediction accuracy;incremental learning;personalization;intersection;personalized maneuver prediction;Global Positioning System;Predictive models;Adaptation models;Training data;Automobiles;Conferences},
  owner     = {flo},
  timestamp = {2019.05.23},
}

@Article{Polychronopoulos2007,
  author       = {Aris Polychronopoulos and Manolis Tsogas and Angelos Amditis and Luisa Andreone},
  title        = {Sensor Fusion for Predicting Vehicles' Path for Collision Avoidance Systems},
  journaltitle = {{IEEE} Transactions on Intelligent Transportation Systems},
  date         = {2007},
  volume       = {8},
  number       = {3},
  pages        = {549--562},
  doi          = {10.1109/TITS.2007.903439},
  file         = {:pdf-files/Polychronopoulos2007 - Sensor Fusion for Predicting Vehicles' Path for Collision Avoidance Systems.pdf:PDF},
  groups       = {Behaviour analysis},
  owner        = {flo},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
  timestamp    = {2019.05.23},
}

@InProceedings{Taieb2014,
  author    = {Souhaib Ben Taieb and Rob Hyndman},
  title     = {Boosting multi-step autoregressive forecasts},
  booktitle = {Proceedings of the 31st International Conference on Machine Learning},
  date      = {2014},
  editor    = {Eric P. Xing and Tony Jebara},
  volume    = {32},
  series    = {Proceedings of Machine Learning Research},
  number    = {1},
  publisher = {PMLR},
  location  = {Bejing, China},
  pages     = {109--117},
  url       = {http://proceedings.mlr.press/v32/taieb14.html},
  abstract  = {Multi-step forecasts can be produced recursively by iterating a one-step model, or directly using a specific model for each horizon. Choosing between these two strategies is not an easy task since it involves a trade-off between bias and estimation variance over the forecast horizon. Using a nonlinear machine learning model makes the tradeoff even more difficult. To address this issue, we propose a new forecasting strategy which boosts traditional recursive linear forecasts with a direct strategy using a boosting autoregression procedure at each horizon. First, we investigate the performance of the proposed strategy in terms of bias and variance decomposition of the error using simulated time series. Then, we evaluate the proposed strategy on real-world time series from two forecasting competitions. Overall, we obtain excellent performance with respect to the standard forecasting strategies.},
  file      = {:pdf-files/Taieb2014 - Boosting Multi Step Autoregressive Forecasts.pdf:PDF},
  groups    = {Boosting},
  timestamp = {2019.05.23},
}

@Article{Gomes2017,
  author       = {Heitor Murilo Gomes and Jean Paul Barddal and Fabr{\'{\i}}cio Enembreck and Albert Bifet},
  title        = {A Survey on Ensemble Learning for Data Stream Classification},
  journal      = {ACM Computing Surveys},
  journaltitle = {ACM Computing Surveys},
  date         = {2017},
  volume       = {50},
  number       = {2},
  pages        = {1--36},
  doi          = {10.1145/3054925},
  file         = {:pdf-files/Gomes2017 - A Survey on Ensemble Learning for Data Stream Classification.pdf:PDF},
  groups       = {Online learning},
  owner        = {flo},
  publisher    = {Association for Computing Machinery ({ACM})},
  timestamp    = {2019.05.24},
}

@InBook{Chen2017,
  author    = {Jinghui Chen and Saket Sathe and Charu Aggarwal and Deepak Turaga},
  title     = {Outlier Detection with Autoencoder Ensembles},
  booktitle = {Proceedings of the 2017 {SIAM} International Conference on Data Mining},
  date      = {2017},
  publisher = {Society for Industrial and Applied Mathematics},
  pages     = {90--98},
  doi       = {10.1137/1.9781611974973.11},
  eprint    = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611974973.11},
  file      = {:pdf-files/Chen2017 - Outlier Detection with Autoencoder Ensembles.pdf:PDF},
  groups    = {Anomaly detection},
  owner     = {flo},
  timestamp = {2019.05.28},
}

@InProceedings{Maye2011,
  author    = {J. Maye and R. Triebel and L. Spinello and R. Siegwart},
  title     = {Bayesian On-line Learning of Driving Behaviors},
  booktitle = {Proc. of The International Conference in Robotics and Automation (ICRA)},
  date      = {2011},
  file      = {:pdf-files/Maye2011 - Bayesian on Line Learning of Driving Behaviors.pdf:PDF},
  groups    = {Online learning},
  owner     = {flo},
  timestamp = {2019.06.12},
}

@InProceedings{Komer2019,
  author    = {Brent Komer and Terrence C. Stewart and Aaron R. Voelker and Chris Eliasmith},
  title     = {A neural representation of continuous space using fractional binding},
  booktitle = {41st Annual Meeting of the Cognitive Science Society},
  date      = {2019},
  publisher = {Cognitive Science Society},
  location  = {Montreal, QC},
  abstract  = {We present a novel method for constructing neurally implemented spatial representations that we show to be useful for building models of spatial cognition. This method represents continuous (i.e.,~real-valued) spaces using neurons, and identifies a set of operations for manipulating these representations.
    Specifically, we use "fractional binding" to construct "spatial semantic pointers" (SSPs) that we use to generate and manipulate representations of spatial maps encoding the positions of objects.  We show how these representations can be transformed to  answer queries about the location and identities of objects, move the relative or global position of items, and answer queries about regions of space, among other things.  We demonstrate that the neural implementation in spiking networks of SSPs have similar accuracy and capacity as the mathematical ideal.},
  file      = {:pdf-files/Komer2019 - A Neural Representation of Continuous Space Using Fractional Binding.pdf:PDF},
  groups    = {Vector Symbolic Architectures},
  owner     = {flo},
  timestamp = {2019.06.14},
}

@Article{Miller1956,
  author       = {George A. Miller},
  title        = {The magical number seven, plus or minus two: some limits on our capacity for processing information},
  journaltitle = {Psychological Review},
  date         = {1956},
  volume       = {63},
  number       = {2},
  pages        = {81--97},
  doi          = {10.1037/h0043158},
  file         = {:pdf-files/Miller1956 - The Magical Number Seven, Plus or Minus Two_ Some Limits on Our Capacity for Processing Information.pdf:PDF},
  groups       = {Biology},
  owner        = {flo},
  publisher    = {American Psychological Association ({APA})},
  timestamp    = {2019.06.16},
}

@MastersThesis{Darius2018,
  author      = {Robert Darius},
  title       = {Learning a visual-semantic vector vocabulary for automotive environment modelling},
  institution = {Technical University of Munich},
  date        = {2018},
  file        = {:pdf-files/Darius2018 - Learning a Visual Semantic Vector Vocabulary for Automotive Environment Modelling.pdf:PDF},
  owner       = {flo},
  timestamp   = {2019.06.17},
}

@PhdThesis{Farahini2016,
  author      = {Nasim Farahini},
  title       = {SiLago: Enabling System Level Automation Methodology to Design Custom High-Performance Computing Platforms : Toward Next Generation Hardware Synthesis Methodologies},
  institution = {Royal Institute of Technology (KTH), School of Information and Communication Technology},
  date        = {2016},
  location    = {Stockholm},
  file        = {:pdf-files/Farahini2016 - SiLago_ Enabling System Level Automation Methodology to Design Custom High Performance Computing Platforms _ toward Next Generation Hardware Synthesis Methodologies.pdf:PDF},
  groups      = {Neuromorphic Hardware},
  owner       = {flo},
  timestamp   = {2019.06.18},
}

@Article{Brooks1986,
  author       = {Rodney Brooks},
  title        = {A robust layered control system for a mobile robot},
  journaltitle = {{IEEE} Journal on Robotics and Automation},
  date         = {1986},
  volume       = {2},
  number       = {1},
  pages        = {14--23},
  issn         = {0882-4967},
  doi          = {10.1109/JRA.1986.1087032},
  abstract     = {A new architecture for controlling mobile robots is described. Layers of control system are built to let the robot operate at increasing levels of competence. Layers are made up of asynchronous modules that communicate over low-bandwidth channels. Each module is an instance of a fairly simple computational machine. Higher-level layers can subsume the roles of lower levels by suppressing their outputs. However, lower levels continue to function as higher levels are added. The result is a robust and flexible robot control system. The system has been used to control a mobile robot wandering around unconstrained laboratory areas and computer machine rooms. Eventually it is intended to control a robot that wanders the office areas of our laboratory, building maps of its surroundings using an onboard arm to perform simple tasks.},
  file         = {:pdf-files/Brooks1986 - A Robust Layered Control System for a Mobile Robot.pdf:PDF},
  groups       = {Robotics},
  keywords     = {Hierarchical systems;Robots, locomotion;Robustness;Robust control;Control systems;Mobile robots;Robot control;Acoustic sensors;Boundary conditions;Robot sensing systems;Robotics and automation;Infrared sensors;Laboratories},
  publisher    = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@InProceedings{Calabrese2019,
  author    = {Calabrese, Enrico and Taverni, Gemma and Awai Easthope, Christopher and Skriabine, Sophie and Corradi, Federico and Longinotti, Luca and Eng, Kynan and Delbruck, Tobi},
  title     = {DHP19: Dynamic Vision Sensor 3D Human Pose Dataset},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
  date      = {2019},
  url       = {https://sites.google.com/view/dhp19/home},
  file      = {:pdf-files/Calabrese2019 - DHP19_ Dynamic Vision Sensor 3D Human Pose Dataset.pdf:PDF},
  groups    = {Neuromorphic Vision},
  owner     = {flo},
  timestamp = {2019.06.24},
}

@Article{Beattie2016,
  author       = {Charles Beattie and Joel Z. Leibo and Denis Teplyashin and Tom Ward and Marcus Wainwright and Heinrich K{\"{u}}ttler and Andrew Lefrancq and Simon Green and V{\'{\i}}ctor Vald{\'{e}}s and Amir Sadik and Julian Schrittwieser and Keith Anderson and Sarah York and Max Cant and Adam Cain and Adrian Bolton and Stephen Gaffney and Helen King and Demis Hassabis and Shane Legg and Stig Petersen},
  title        = {DeepMind Lab},
  journaltitle = {CoRR},
  date         = {2016},
  volume       = {abs/1612.03801},
  eprint       = {1612.03801},
  eprinttype   = {arXiv},
  url          = {http://arxiv.org/abs/1612.03801},
  file         = {:pdf-files/Beattie2016 - DeepMind Lab.pdf:PDF},
  groups       = {Simulators},
  owner        = {flo},
  timestamp    = {2019.07.01},
}

@InProceedings{Strigl2010,
  author    = {Daniel Strigl and Klaus Kofler and Stefan Podlipnig},
  title     = {Performance and Scalability of GPU-Based Convolutional Neural Networks},
  booktitle = {2010 18th Euromicro Conference on Parallel, Distributed and Network-based Processing},
  year      = {2010},
  date      = {2010},
  publisher = {{IEEE}},
  pages     = {317--324},
  doi       = {10.1109/PDP.2010.43},
  abstract  = {In this paper we present the implementation of a framework for accelerating training and classification of arbitrary Convolutional Neural Networks (CNNs) on the GPU. CNNs are a derivative of standard Multilayer Perceptron (MLP) neural networks optimized for two-dimensional pattern recognition problems such as Optical Character Recognition (OCR) or face detection. We describe the basic parts of a CNN and demonstrate the performance and scalability improvement that can be achieved by shifting the computation-intensive tasks of a CNN to the GPU. Depending on the network topology training and classification on the GPU performs 2 to 24 times faster than on the CPU. Furthermore, the GPU version scales much better than the CPU implementation with respect to the network size.},
  file      = {:pdf-files/Strigl2010 - Performance and Scalability of GPU Based Convolutional Neural Networks.pdf:PDF},
  groups    = {GPUAcceleration},
  issn      = {1066-6192},
  keywords  = {computer graphic equipment;coprocessors;learning (artificial intelligence);multilayer perceptrons;GPU-based convolutional neural networks;multilayer perceptron neural networks;two-dimensional pattern recognition problems;optical character recognition;face detection;network topology training;network topology classification;Scalability;Neural networks;Cellular neural networks;Optical character recognition software;Acceleration;Multilayer perceptrons;Multi-layer neural network;Pattern recognition;Optical computing;Optical fiber networks;machine learning;convolutional neural networks;GPGPU;CUDA;performance;scalability},
  owner     = {flo},
  timestamp = {2019.07.01},
}

@InProceedings{Shi2016,
  author    = {Shaohuai Shi and Qiang Wang and Pengfei Xu and Xiaowen Chu},
  title     = {Benchmarking State-of-the-Art Deep Learning Software Tools},
  booktitle = {2016 7th International Conference on Cloud Computing and Big Data ({CCBD})},
  year      = {2016},
  date      = {2016},
  publisher = {{IEEE}},
  pages     = {99--104},
  doi       = {10.1109/CCBD.2016.029},
  abstract  = {Deep learning has been shown as a successful machine learning method for a variety of tasks, and its popularity results in numerous open-source deep learning software tools coming to public. Training a deep network is usually a very time-consuming process. To address the huge computational challenge in deep learning, many tools exploit hardware features such as multi-core CPUs and many-core GPUs to shorten the training and inference time. However, different tools exhibit different features and running performance when they train different types of deep networks on different hardware platforms, making it difficult for end users to select an appropriate pair of software and hardware. In this paper, we present our attempt to benchmark several state-of-the-art GPU-accelerated deep learning software tools, including Caffe, CNTK, TensorFlow, and Torch. We focus on evaluating the running time performance (i.e., speed) of these tools with three popular types of neural networks on two representative CPU platforms and three representative GPU platforms. Our contribution is two-fold. First, for end users of deep learning software tools, our benchmarking results can serve as a reference to selecting appropriate hardware platforms and software tools. Second, for developers of deep learning software tools, our in-depth analysis points out possible future directions to further optimize the running performance.},
  file      = {:pdf-files/Shi2016 - Benchmarking State of the Art Deep Learning Software Tools.pdf:PDF},
  groups    = {Software and Tools},
  keywords  = {benchmark testing;feedforward neural nets;graphics processing units;learning (artificial intelligence);microprocessor chips;performance evaluation;recurrent neural nets;software tools;open-source deep learning software tool benchmarking;machine learning method;deep network training;hardware platforms;GPU-accelerated deep learning software tools;Caffe;CNTK;TensorFlow;Torch;running time performance evaluation;CPU platform;Tools;Machine learning;Neural networks;Benchmark testing;Graphics processing units;Instruction sets;Training;Deep Learning;GPU;Feed-forward Neural Networks;Convolutional Neural Networks;Recurrent Neural Networks},
  owner     = {flo},
  timestamp = {2019.07.01},
}

@Article{Hand2015,
  author       = {{Han}, Song and {Mao}, Huizi and {Dally}, William J.},
  title        = {{Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding}},
  journaltitle = {arXiv e-prints},
  date         = {2015},
  eid          = {arXiv:1510.00149},
  pages        = {arXiv:1510.00149},
  eprint       = {1510.00149},
  eprintclass  = {cs.CV},
  eprinttype   = {arXiv},
  file         = {:pdf-files/Hand2015 - Deep Compression_ Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding.pdf:PDF},
  groups       = {Deep Neural Networks},
  keywords     = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
  owner        = {flo},
  timestamp    = {2019.07.01},
}

@InProceedings{Chang2017,
  author    = {A. X. M. {Chang} and E. {Culurciello}},
  title     = {Hardware accelerators for recurrent neural networks on FPGA},
  booktitle = {2017 IEEE International Symposium on Circuits and Systems (ISCAS)},
  date      = {2017},
  pages     = {1--4},
  doi       = {10.1109/ISCAS.2017.8050816},
  abstract  = {Recurrent Neural Networks (RNNs) have the ability to retain memory and learn from data sequences, which are fundamental for real-time applications. RNN computations offer limited data reuse, which leads to high data traffic. This translates into high off-chip memory bandwidth or large internal storage requirement to achieve high performance. Exploiting parallelism in RNN computations are bounded by this two limiting factors, among other constraints present in embedded systems. Therefore, balance between internally stored data and off-chip memory data transfer is necessary to overlap computation time with data transfer latency. In this paper, we present three hardware accelerators for RNN on Xilinx's Zynq SoC FPGA to present how to overcome challenges involved in developing RNN accelerators. Each design uses different strategies to achieve high performance and scalability. Each co-processor was tested with a character level language model. The latest design called DeepRnn, achieves up to 23 X better performance per power than Tegra X1 development board for this application.},
  file      = {:pdf-files/Chang2017 - Hardware Accelerators for Recurrent Neural Networks on FPGA.pdf:PDF},
  groups    = {Deep Neural Networks},
  issn      = {2379-447X},
  keywords  = {embedded systems;field programmable gate arrays;neural chips;parallel processing;recurrent neural nets;hardware accelerators;recurrent neural networks;RNN parallel computation;embedded system;Xilinx Zynq SoC FPGA;Logic gates;Bandwidth;Hardware;Field programmable gate arrays;Computer architecture;Data transfer;System-on-chip},
  owner     = {flo},
  timestamp = {2019.07.10},
}

@Article{Neckar2019,
  author       = {Alexander Neckar and Sam Fok and Ben V. Benjamin and Terrence C. Stewart and Nick N. Oza and Aaron R. Voelker and Chris Eliasmith and Rajit Manohar and Kwabena Boahen},
  date         = {2019},
  journaltitle = {Proceedings of the IEEE},
  title        = {Braindrop: A Mixed-Signal Neuromorphic Architecture With a Dynamical Systems-Based Programming Model},
  doi          = {10.1109/jproc.2018.2881432},
  issue        = {1},
  number       = {1},
  pages        = {144--164},
  url          = {https://ieeexplore.ieee.org/document/8591981},
  volume       = {107},
  abstract     = {Braindrop is the first neuromorphic system designed to be programmed at a high level of abstraction.
    Previous neuromorphic systems were programmed at the neurosynaptic level and required expert knowledge
    of the hardware to use. In stark contrast, Braindrop's computations are specified as coupled nonlinear
    dynamical systems and synthesized to the hardware by an automated procedure. This procedure not only
    leverages Braindrop's fabric of subthreshold analog circuits as dynamic computational primitives but also
    compensates for their mismatched and temperature-sensitive responses at the network level. Thus, a clean
    abstraction is presented to the user. Fabricated in a 28-nm FDSOI process, Braindrop integrates 4096 neurons
    in $0.65 \text{mm}^2$. Two innovations---sparse encoding through analog spatial convolution and weighted
    spike-rate summation though digital accumulative thinning---cut digital traffic drastically, reducing the
    energy Braindrop consumes per equivalent synaptic operation to 381 fJ for typical network configurations.},
  file         = {:pdf-files/Neckar2019 - Braindrop_ a Mixed Signal Neuromorphic Architecture with a Dynamical Systems Based Programming Model.pdf:PDF},
  groups       = {Neuromorphic Hardware},
  publisher    = {IEEE},
}

@Article{Schuman2017,
  author        = {Catherine D. Schuman and Thomas E. Potok and Robert M. Patton and J. Douglas Birdwell and Mark E. Dean and Garrett S. Rose and James S. Plank},
  title         = {A Survey of Neuromorphic Computing and Neural Networks in Hardware},
  journaltitle  = {Computing Research Repository (CoRR)},
  date          = {2017},
  volume        = {abs/1705.06963},
  eprint        = {1705.06963},
  eprintclass   = {cs.NE},
  eprinttype    = {arxiv},
  abstract      = {Neuromorphic computing has come to refer to a variety of brain-inspired computers, devices, and models that contrast the pervasive von Neumann computer architecture. This biologically inspired approach has created highly connected synthetic neurons and synapses that can be used to model neuroscience theories as well as solve challenging machine learning problems. The promise of the technology is to create a brain-like ability to learn and adapt, but the technical challenges are significant, starting with an accurate neuroscience model of how the brain works, to finding materials and engineering breakthroughs to build devices to support these models, to creating a programming framework so the systems can learn, to creating applications with brain-like capabilities. In this work, we provide a comprehensive survey of the research and motivations for neuromorphic computing over its history. We begin with a 35-year review of the motivations and drivers of neuromorphic computing, then look at the major research areas of the field, which we define as neuro-inspired models, algorithms and learning approaches, hardware and devices, supporting systems, and finally applications. We conclude with a broad discussion on the major research topics that need to be addressed in the coming years to see the promise of neuromorphic computing fulfilled. The goals of this work are to provide an exhaustive review of the research conducted in neuromorphic computing since the inception of the term, and to motivate further work by illuminating gaps in the field where new research is needed.},
  archiveprefix = {arXiv},
  file          = {:pdf-files/Schuman2017 - A Survey of Neuromorphic Computing and Neural Networks in Hardware.pdf:PDF},
  groups        = {Neuromorphic Computing},
  journal       = {CoRR},
  keywords      = {cs.NE},
  year          = {2017},
}

@InProceedings{Elbayad2018,
  author    = {Elbayad, Maha and Besacier, Laurent and Verbeek, Jakob},
  booktitle = {Proceedings of the 22nd Conference on Computational Natural Language Learning},
  date      = {2018-10},
  title     = {Pervasive Attention: 2{D} Convolutional Neural Networks for Sequence-to-Sequence Prediction},
  doi       = {10.18653/v1/K18-1010},
  location  = {Brussels, Belgium},
  pages     = {97--107},
  publisher = {Association for Computational Linguistics},
  abstract  = {Current state-of-the-art machine translation systems are based on encoder-decoder architectures, that first encode the input sequence, and then generate an output sequence based on the input encoding. Both are interfaced with an attention mechanism that recombines a fixed encoding of the source tokens based on the decoder state. We propose an alternative approach which instead relies on a single 2D convolutional neural network across both sequences. Each layer of our network re-codes source tokens on the basis of the output sequence produced so far. Attention-like properties are therefore pervasive throughout the network. Our model yields excellent results, outperforming state-of-the-art encoder-decoder systems, while being conceptually simpler and having fewer parameters.},
  file      = {:pdf-files/Elbayad2018 - Pervasive Attention_ 2D Convolutional Neural Networks for Sequence to Sequence Prediction.pdf:PDF},
  groups    = {Seq2Seq},
  year      = {2018},
}

@Article{Xu2015,
  author       = {{Xu}, Kelvin and {Ba}, Jimmy and {Kiros}, Ryan and {Cho}, Kyunghyun and {Courville}, Aaron and {Salakhutdinov}, Ruslan and {Zemel}, Richard and {Bengio}, Yoshua},
  date         = {2015-02},
  journaltitle = {arXiv e-prints},
  title        = {{Show, Attend and Tell: Neural Image Caption Generation with Visual Attention}},
  eid          = {arXiv:1502.03044},
  eprint       = {1502.03044},
  eprintclass  = {cs.LG},
  eprinttype   = {arXiv},
  pages        = {arXiv:1502.03044},
  file         = {:pdf-files/Xu2015 - Show, Attend and Tell_ Neural Image Caption Generation with Visual Attention.pdf:PDF},
  groups       = {Image Caption Generation},
  keywords     = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@Article{Cao2019,
  author       = {{Cao}, Kaidi and {Wei}, Colin and {Gaidon}, Adrien and {Arechiga}, Nikos and {Ma}, Tengyu},
  date         = {2019-06},
  journaltitle = {arXiv e-prints},
  title        = {{Learning Imbalanced Datasets with Label-Distribution-Aware Margin Loss}},
  eid          = {arXiv:1906.07413},
  eprint       = {1906.07413},
  eprintclass  = {cs.LG},
  eprinttype   = {arXiv},
  pages        = {arXiv:1906.07413},
  file         = {:pdf-files/Cao2019 - Learning Imbalanced Datasets with Label Distribution Aware Margin Loss.pdf:PDF},
  groups       = {Machine Learning},
  keywords     = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
}

@Article{Deng2019,
  author       = {Lei Deng and Yujie Wu and Xing Hu and Ling Liang and Yufei Ding and Guoqi Li and Guangshe Zhao and Peng Li and Yuan Xie},
  date         = {2019},
  journaltitle = {Neural Networks},
  title        = {Rethinking the performance comparison between SNNS and ANNS},
  doi          = {10.1016/j.neunet.2019.09.005},
  issn         = {0893-6080},
  url          = {http://www.sciencedirect.com/science/article/pii/S0893608019302667},
  abstract     = {Artificial neural networks (ANNs), a popular path towards artificial intelligence, have experienced remarkable success via mature models, various benchmarks, open-source datasets, and powerful computing platforms. Spiking neural networks (SNNs), a category of promising models to mimic the neuronal dynamics of the brain, have gained much attention for brain inspired computing and been widely deployed on neuromorphic devices. However, for a long time, there are ongoing debates and skepticisms about the value of SNNs in practical applications. Except for the low power attribute benefit from the spike-driven processing, SNNs usually perform worse than ANNs especially in terms of the application accuracy. Recently, researchers attempt to address this issue by borrowing learning methodologies from ANNs, such as backpropagation, to train high-accuracy SNN models. The rapid progress in this domain continuously produces amazing results with ever-increasing network size, whose growing path seems similar to the development of deep learning. Although these ways endow SNNs the capability to approach the accuracy of ANNs, the natural superiorities of SNNs and the way to outperform ANNs are potentially lost due to the use of ANN-oriented workloads and simplistic evaluation metrics. In this paper, we take the visual recognition task as a case study to answer the questions of “what workloads are ideal for SNNs and how to evaluate SNNs makes sense”. We design a series of contrast tests using different types of datasets (ANN-oriented and SNN-oriented), diverse processing models, signal conversion methods, and learning algorithms. We propose comprehensive metrics on the application accuracy and the cost of memory \& compute to evaluate these models, and conduct extensive experiments. We evidence the fact that on ANN-oriented workloads, SNNs fail to beat their ANN counterparts; while on SNN-oriented workloads, SNNs can fully perform better. We further demonstrate that in SNNs there exists a trade-off between the application accuracy and the execution cost, which will be affected by the simulation time window and firing threshold. Based on these abundant analyses, we recommend the most suitable model for each scenario. To the best of our knowledge, this is the first work using systematical comparisons to explicitly reveal that the straightforward workload porting from ANNs to SNNs is unwise although many works are doing so and a comprehensive evaluation indeed matters. Finally, we highlight the urgent need to build a benchmarking framework for SNNs with broader tasks, datasets, and metrics.},
  file         = {:pdf-files/Deng2019 - Rethinking the Performance Comparison between SNNS and ANNS.pdf:PDF},
  groups       = {Spiking Neural Networks},
  journal      = {Neural Networks},
  keywords     = {Spiking neural networks, Artificial neural networks, Deep learning, Neuromorphic computing, Benchmark},
  month        = {sep},
  publisher    = {Elsevier {BV}},
  year         = {2019},
}

@Article{Barrett2019,
  author       = {Lisa Feldman Barrett and Ralph Adolphs and Stacy Marsella and Aleix M. Martinez and Seth D. Pollak},
  date         = {2019-07},
  journaltitle = {Psychological Science in the Public Interest},
  title        = {Emotional Expressions Reconsidered: Challenges to Inferring Emotion From Human Facial Movements},
  doi          = {10.1177/1529100619832930},
  eprint       = {https://doi.org/10.1177/1529100619832930},
  note         = {PMID: 31313636},
  number       = {1},
  pages        = {1-68},
  volume       = {20},
  abstract     = {It is commonly assumed that a person’s emotional state can be readily inferred from his or her facial movements, typically called emotional expressions or facial expressions. This assumption influences legal judgments, policy decisions, national security protocols, and educational practices; guides the diagnosis and treatment of psychiatric illness, as well as the development of commercial applications; and pervades everyday social interactions as well as research in other scientific fields such as artificial intelligence, neuroscience, and computer vision. In this article, we survey examples of this widespread assumption, which we refer to as the common view, and we then examine the scientific evidence that tests this view, focusing on the six most popular emotion categories used by consumers of emotion research: anger, disgust, fear, happiness, sadness, and surprise. The available scientific evidence suggests that people do sometimes smile when happy, frown when sad, scowl when angry, and so on, as proposed by the common view, more than what would be expected by chance. Yet how people communicate anger, disgust, fear, happiness, sadness, and surprise varies substantially across cultures, situations, and even across people within a single situation. Furthermore, similar configurations of facial movements variably express instances of more than one emotion category. In fact, a given configuration of facial movements, such as a scowl, often communicates something other than an emotional state. Scientists agree that facial movements convey a range of information and are important for social communication, emotional or otherwise. But our review suggests an urgent need for research that examines how people actually move their faces to express emotions and other social information in the variety of contexts that make up everyday life, as well as careful study of the mechanisms by which people perceive instances of emotion in one another. We make specific research recommendations that will yield a more valid picture of how people move their faces to express emotions and how they infer emotional meaning from facial movements in situations of everyday life. This research is crucial to provide consumers of emotion research with the translational information they require.},
  file         = {:pdf-files/Barrett2019 - Emotional Expressions Reconsidered_ Challenges to Inferring Emotion from Human Facial Movements.pdf:PDF},
  groups       = {Machine Learning},
  publisher    = {{SAGE} Publications},
}

@Article{Zhan2019,
  author        = {{Zhan}, Wei and {Sun}, Liting and {Wang}, Di and {Shi}, Haojie and {Clausse}, Aubrey and {Naumann}, Maximilian and {Kummerle}, Julius and {Konigshof}, Hendrik and {Stiller}, Christoph and {de La Fortelle}, Arnaud and {Tomizuka}, Masayoshi},
  date          = {2019-09-30},
  journaltitle  = {arXiv e-prints},
  title         = {{INTERACTION Dataset: An INTERnational, Adversarial and Cooperative moTION Dataset in Interactive Driving Scenarios with Semantic Maps}},
  eid           = {arXiv:1910.03088},
  eprint        = {1910.03088},
  eprintclass   = {cs.RO},
  eprinttype    = {arXiv},
  pages         = {arXiv:1910.03088},
  abstract      = {Behavior-related research areas such as motion prediction/planning, representation/imitation learning, behavior modeling/generation, and algorithm testing, require support from high-quality motion datasets containing interactive driving scenarios with different driving cultures. In this paper, we present an INTERnational, Adversarial and Cooperative moTION dataset (INTERACTION dataset) in interactive driving scenarios with semantic maps. Five features of the dataset are highlighted. 1) The interactive driving scenarios are diverse, including urban/highway/ramp merging and lane changes, roundabouts with yield/stop signs, signalized intersections, intersections with one/two/all-way stops, etc. 2) Motion data from different countries and different continents are collected so that driving preferences and styles in different cultures are naturally included. 3) The driving behavior is highly interactive and complex with adversarial and cooperative motions of various traffic participants. Highly complex behavior such as negotiations, aggressive/irrational decisions and traffic rule violations are densely contained in the dataset, while regular behavior can also be found from cautious car-following, stop, left/right/U-turn to rational lane-change and cycling and pedestrian crossing, etc. 4) The levels of criticality span wide, from regular safe operations to dangerous, near-collision maneuvers. Real collision, although relatively slight, is also included. 5) Maps with complete semantic information are provided with physical layers, reference lines, lanelet connections and traffic rules. The data is recorded from drones and traffic cameras. Statistics of the dataset in terms of number of entities and interaction density are also provided, along with some utilization examples in a variety of behavior-related research areas. The dataset can be downloaded via https://interaction-dataset.com.},
  archiveprefix = {arXiv},
  file          = {:pdf-files/Zhan2019 - INTERACTION Dataset_ an INTERnational, Adversarial and Cooperative MoTION Dataset in Interactive Driving Scenarios with Semantic Maps.pdf:PDF},
  groups        = {Datasets},
  keywords      = {Computer Science - Robotics, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Systems and Control},
  month         = {Sep},
  primaryclass  = {cs.RO},
  year          = {2019},
}

@InProceedings{Ronneberger2015,
  author    = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015},
  date      = {2015},
  title     = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
  doi       = {10.1007/978-3-319-24574-4_28},
  editor    = {Navab, Nassir and Hornegger, Joachim and Wells, William M. and Frangi, Alejandro F.},
  isbn      = {978-3-319-24574-4},
  location  = {Cham},
  pages     = {234--241},
  publisher = {Springer International Publishing},
  url       = {https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/},
  abstract  = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.},
  comment   = {tensorflow implementation available at https://github.com/jakeret/tf_unet},
  file      = {:pdf-files/Ronneberger2015 - U Net_ Convolutional Networks for Biomedical Image Segmentation.pdf:PDF},
  groups    = {Deep Neural Networks},
}

@InCollection{Shrestha2018,
  author    = {Shrestha, Sumit Bam and Orchard, Garrick},
  booktitle = {Advances in Neural Information Processing Systems 31},
  date      = {2018},
  title     = {{SLAYER}: Spike Layer Error Reassignment in Time},
  editor    = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
  pages     = {1419--1428},
  publisher = {Curran Associates, Inc.},
  url       = {http://papers.nips.cc/paper/7415-slayer-spike-layer-error-reassignment-in-time.pdf},
  comment   = {Code available at https://github.com/bamsumit/slayerPytorch},
  file      = {:pdf-files/Shrestha2018 - SLAYER_ Spike Layer Error Reassignment in Time.pdf:PDF},
  groups    = {Spiking Neural Networks},
}

@InProceedings{Piergiovanni2019,
  author    = {Piergiovanni, AJ and Angelova, Anelia and Toshev, Alexander and Ryoo, Michael S.},
  booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
  date      = {2019},
  title     = {Evolving Space-Time Neural Architectures for Videos},
  file      = {:pdf-files/Piergiovanni2019 - Evolving Space Time Neural Architectures for Videos.pdf:PDF},
  groups    = {Deep Neural Networks},
  month     = {October},
  year      = {2019},
}

@Article{Zhang2019,
  author       = {Chuxu Zhang and Dongjin Song and Yuncong Chen and Xinyang Feng and Cristian Lumezanu and Wei Cheng and Jingchao Ni and Bo Zong and Haifeng Chen and Nitesh V. Chawla},
  date         = {2019},
  journaltitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
  title        = {A Deep Neural Network for Unsupervised Anomaly Detection and Diagnosis in Multivariate Time Series Data},
  doi          = {10.1609/aaai.v33i01.33011409},
  pages        = {1409--1416},
  volume       = {33},
  groups       = {Anomaly detection},
  journal      = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
  month        = {jul},
  publisher    = {Association for the Advancement of Artificial Intelligence ({AAAI})},
  year         = {2019},
}

@InProceedings{Yao2019,
  author    = {Yao, Yu and Xu, Mingze and Wang, Yuchen and Crandall, David J and Atkins, Ella M},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  date      = {2019},
  title     = {Unsupervised Traffic Accident Detection in First-Person Videos},
  file      = {:pdf-files/Yao2019 - Unsupervised Traffic Accident Detection in First Person Videos.pdf:PDF},
  groups    = {Anomaly detection},
  year      = {2019},
}

@InCollection{Voelker2019,
  author    = {Voelker, Aaron and Kaji\'{c}, Ivana and Eliasmith, Chris},
  booktitle = {Advances in Neural Information Processing Systems 32},
  date      = {2019},
  title     = {Legendre Memory Units: Continuous-Time Representation in Recurrent Neural Networks},
  editor    = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  pages     = {15544--15553},
  publisher = {Curran Associates, Inc.},
  url       = {http://papers.nips.cc/paper/9689-legendre-memory-units-continuous-time-representation-in-recurrent-neural-networks.pdf},
  file      = {:pdf-files/Voelker2019 - Legendre Memory Units_ Continuous Time Representation in Recurrent Neural Networks.pdf:PDF},
  groups    = {Spiking Neural Networks},
}

@InProceedings{Mirus2020,
  author    = {Florian Mirus and Terrence C. Stewart and J\"org Conradt},
  booktitle = {28th European Symposium on Artificial Neural Networks, {ESANN} 2020, Bruges, Belgium},
  title     = {Detection of abnormal driving situations using distributed representations and unsupervised learning},
  year      = {2020},
  abstract  = {In this paper, we present an anomaly detection system employing an unsupervised learning model trained on the information encapsulated within distributed vector representations of automotive scenes.  Our representations allows us to encode automotive scenes with a varying number of traffic participants in a vector of fixed length. We train a neural network autoencoder in unsupervised fashion to detect anomalies based on this representation. We demonstrate the usefulness of our approach through a quantitative analysis on two real-world data-sets.},
  date      = {2020-10-02},
}

@InProceedings{Mirus2020a,
  author    = {Florian Mirus and Terrence C. Stewart and J\"org Conradt},
  booktitle = {2020 International Joint Conference on Neural Networks ({IJCNN})},
  date      = {2020-07-19},
  title     = {The Importance of Balanced Data Sets: Analyzing a Vehicle Trajectory Prediction Model based on Neural Networks and Distributed Representations},
  doi       = {10.1109/IJCNN48605.2020.9206627},
  pages     = {1--8},
  publisher = {{IEEE}},
  abstract  = {Predicting future behavior of other traffic participants is an essential task that needs to be solved by automated vehicles and human drivers alike to achieve safe and situationaware driving. Modern approaches to vehicles trajectory prediction typically rely on data-driven models like neural networks, in particular LSTMs (Long Short-Term Memorys), achieving promising results. However, the question of optimal composition of the underlying training data has received less attention. In this paper, we expand on previous work on vehicle trajectory prediction based on neural network models employing distributed representations to encode automotive scenes in a semantic vector substrate. We analyze the influence of variations in the training data on the performance of our prediction models. Thereby, we show that the models employing our semantic vector representation outperform the numerical model when trained on an adequate data set and thereby, that the composition of training data in vehicle trajectory prediction is crucial for successful training. We conduct our analysis on challenging real-world driving data.},
  month     = {jul},
  year      = {2020},
}

@InProceedings{Mirus2020b,
  author    = {Florian Mirus and Terrence C. Stewart and J\"org Conradt},
  booktitle = {2020 International Joint Conference on Neural Networks ({IJCNN})},
  date      = {2020-07-19},
  title     = {Analyzing the Capacity of Distributed Vector Representations to Encode Spatial Information},
  doi       = {10.1109/IJCNN48605.2020.9207137},
  pages     = {1--7},
  publisher = {{IEEE}},
  abstract  = {Vector Symbolic Architectures belong to a family of related cognitive modeling approaches that encode symbols and structures in high-dimensional vectors. Similar to human subjects, whose capacity to process and store information or concepts in short-term memory is subject to numerical restrictions, the capacity of information that can be encoded in such vector representations is limited and one way of modeling the numerical restrictions to cognition. In this paper, we analyze these limits regarding information capacity of distributed representations. We focus our analysis on simple superposition and more complex, structured representations involving convolutive powers to encode spatial information. In two experiments, we find upper bounds for the number of concepts that can effectively be stored in a single vector.},
  month     = {jul},
  year      = {2020},
}

@Article{Bai2018,
  author        = {Shaojie Bai and J. Zico Kolter and Vladlen Koltun},
  date          = {2018},
  journaltitle  = {Computing Research Repository (CoRR)},
  title         = {An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling},
  eprint        = {1803.01271},
  eprinttype    = {arxiv},
  volume        = {abs/1803.01271},
  archiveprefix = {arXiv},
  file          = {:pdf-files/Bai2018 - An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling.pdf:PDF},
  groups        = {Seq2Seq},
}

@Article{Neubert2019,
  author       = {Neubert, Peer and Schubert, Stefan and Protzel, Peter},
  date         = {2019},
  journaltitle = {KI - K{\"u}nstliche Intelligenz},
  title        = {An Introduction to Hyperdimensional Computing for Robotics},
  issn         = {1610-1987},
  number       = {4},
  pages        = {319--330},
  url          = {https://doi.org/10.1007/s13218-019-00623-z},
  volume       = {33},
  abstract     = {Hyperdimensional computing combines very high-dimensional vector spaces (e.g. 10,000 dimensional) with a set of carefully designed operators to perform symbolic computations with large numerical vectors. The goal is to exploit their representational power and noise robustness for a broad range of computational tasks. Although there are surprising and impressive results in the literature, the application to practical problems in the area of robotics is so far very limited. In this work, we aim at providing an easy to access introduction to the underlying mathematical concepts and describe the existing computational implementations in form of vector symbolic architectures (VSAs). This is accompanied by references to existing applications of VSAs in the literature. To bridge the gap to practical applications, we describe and experimentally demonstrate the application of VSAs to three different robotic tasks: viewpoint invariant object recognition, place recognition and learning of simple reactive behaviors. The paper closes with a discussion of current limitations and open questions.},
  groups       = {Vector Symbolic Architectures},
  refid        = {Neubert2019},
  year         = {2019},
}

@Article{Schlegel2020,
  author        = {{Schlegel}, Kenny and {Neubert}, Peer and {Protzel}, Peter},
  date          = {2020},
  journaltitle  = {arXiv e-prints},
  title         = {A comparison of {Vector Symbolic Architectures}},
  eid           = {arXiv:2001.11797},
  eprint        = {2001.11797},
  pages         = {arXiv:2001.11797},
  url           = {https://arxiv.org/abs/2001.11797},
  archiveprefix = {arXiv},
  file          = {:pdf-files/2001.11797.pdf:PDF},
  groups        = {Vector Symbolic Architectures},
  keywords      = {Computer Science - Artificial Intelligence},
  month         = jan,
  primaryclass  = {cs.AI},
  year          = {2020},
}

@Comment{jabref-meta: databaseType:biblatex;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:Markings\;2\;1\;\;\;\;;
2 StaticGroup:flo:5\;2\;1\;\;\;\;;
1 StaticGroup:Autonomous Driving\;0\;1\;\;\;\;;
2 StaticGroup:Environment Model\;0\;1\;\;\;\;;
2 StaticGroup:Localization\;0\;1\;\;\;\;;
2 StaticGroup:Object Recognition\;0\;1\;\;\;\;;
2 StaticGroup:Robotics\;0\;1\;\;\;\;;
2 StaticGroup:Behaviour analysis\;0\;1\;\;\;\;;
2 StaticGroup:Situation/Context analysis\;0\;1\;\;\;\;;
2 StaticGroup:Simulators\;0\;1\;\;\;\;;
1 StaticGroup:Biology\;0\;1\;\;\;\;;
1 StaticGroup:Computing and GPU\;0\;1\;\;\;\;;
1 StaticGroup:Machine Learning\;0\;1\;\;\;\;;
2 StaticGroup:Bayesian Networks\;0\;1\;\;\;\;;
2 StaticGroup:Boosting\;0\;1\;\;\;\;;
2 StaticGroup:Datasets\;0\;1\;\;\;\;;
2 StaticGroup:DecisionTrees\;0\;1\;\;\;\;;
2 StaticGroup:Issues\;0\;1\;\;\;\;;
2 StaticGroup:ReinforcementLearning\;0\;1\;\;\;\;;
2 StaticGroup:SVM\;0\;1\;\;\;\;;
2 StaticGroup:Word Embedding\;0\;1\;\;\;\;;
2 StaticGroup:Image Caption Generation\;0\;1\;0xffffffff\;\;\;;
2 StaticGroup:Online learning\;0\;1\;\;\;\;;
2 StaticGroup:Anomaly detection\;0\;1\;\;\;\;;
2 StaticGroup:Seq2Seq\;0\;1\;0xffffffff\;\;\;;
1 StaticGroup:Neuromorphic Computing\;0\;1\;\;\;\;;
2 StaticGroup:Neuromorphic Robotics\;0\;1\;\;\;\;;
2 StaticGroup:Neuromorphic Vision\;0\;1\;\;\;\;;
2 StaticGroup:Projects\;0\;1\;\;\;\;;
1 StaticGroup:Neuromorphic Hardware\;0\;1\;\;\;\;;
2 StaticGroup:Neurogrid\;0\;1\;\;\;\;;
2 StaticGroup:SpiNNaker\;0\;1\;\;\;\;;
2 StaticGroup:TrueNorth\;0\;1\;\;\;\;;
2 StaticGroup:Loihi\;0\;1\;\;\;\;;
2 StaticGroup:GPUAcceleration\;0\;1\;\;\;\;;
1 StaticGroup:Neural Modelling\;0\;1\;\;\;\;;
2 StaticGroup:Bayesian Inference with Spiking Neurons\;0\;1\;\;\;\;;
2 StaticGroup:Nengo\;0\;1\;\;\;\;;
2 StaticGroup:PyNN\;0\;1\;\;\;\;;
2 StaticGroup:Simulators\;0\;1\;\;\;\;;
2 StaticGroup:STDP\;0\;1\;\;\;\;;
1 StaticGroup:Cognitive Modeling\;0\;1\;\;\;\;;
2 StaticGroup:Vector Symbolic Architectures\;0\;1\;\;\;\;;
2 StaticGroup:Symbolic approaches\;0\;1\;\;\;\;;
2 StaticGroup:Connectionism\;0\;1\;\;\;\;;
2 StaticGroup:Dynamicism\;0\;1\;\;\;\;;
2 StaticGroup:Numenta etc\;0\;1\;\;\;\;;
1 StaticGroup:Neural Networks\;0\;1\;\;\;\;;
2 StaticGroup:Deep Neural Networks\;0\;1\;\;\;\;;
2 StaticGroup:Software and Tools\;0\;1\;\;\;\;;
2 StaticGroup:Spiking Neural Networks\;0\;1\;\;\;\;;
1 StaticGroup:Neuroscience\;0\;1\;\;\;\;;
1 StaticGroup:Non-Technical\;0\;1\;\;\;\;;
}

@Comment{jabref-meta: groupsversion:
3;
}
